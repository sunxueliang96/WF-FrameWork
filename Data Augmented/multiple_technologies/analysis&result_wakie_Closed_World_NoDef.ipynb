{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiple_technologies.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyORbICu5XG+qJPhFRS0Ttt9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunxueliang96/WF-FrameWork/blob/master/Data%20Augmented/multiple_technologies/analysis%26result_wakie_Closed_World_NoDef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3WCsIaUTuNV",
        "colab_type": "code",
        "outputId": "46146eee-f62a-4ca4-a634-090dbbea125a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF9tyC-TTxmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cd /content/drive/'My Drive'/datasets/no_paded/open_world/walkiebatch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmrLZ3D0oBGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#datatype_Close = False   #Flase is Open_World, True is Closed World."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPlx2lQou8oO",
        "colab_type": "code",
        "outputId": "cc62de70-8110-44e4-f88d-798b5d684e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/'My Drive'/datasets/no_paded/close_world/walkiebatch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/datasets/no_paded/close_world/walkiebatch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PwIP_Q9n_W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datatype_Close = True   #Flase is Open_World, True is Closed World."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thC1b8glT6p9",
        "colab_type": "code",
        "outputId": "c134407d-2cc0-4c46-bb4d-60b320b3f46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCALLY_CHANGE_historys_CNN_NB_TIMES.pkl\n",
            "LOCALLY_CHANGE_historys_CNN_PERCENT_CHANGED.pkl\n",
            "LOCALLY_CHANGE_historys_DNN_NB_TIMES.pkl\n",
            "LOCALLY_CHANGE_historys_DNN_PERCENT_CHANGED.pkl\n",
            "NOISE_ADDED_historys_CNN_NB_TIMES.pkl\n",
            "NOISE_ADDED_historys_CNN_PERCENT_NOISE.pkl\n",
            "NOISE_ADDED_historys_DNN_NB_TIMES.pkl\n",
            "NOISE_ADDED_historys_DNN_PERCENT_NOISE.pkl\n",
            "RANDOM_DELETE_historys_CNN_NB_TIMES.pkl\n",
            "RANDOM_DELETE_historys_CNN_PERCENT_CHANGED.pkl\n",
            "RANDOM_DELETE_historys_DNN_NB_TIMES.pkl\n",
            "RANDOM_DELETE_historys_DNN_PERCENT_CHANGED.pkl\n",
            "X_walkiebatch.pkl\n",
            "y_walkiebatch.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOpTb4DkT9db",
        "colab_type": "code",
        "outputId": "9a1486f2-5d5a-4308-dbb5-55d5b156f85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "print('loading data...')\n",
        "with open('X_walkiebatch.pkl','rb') as handle:\n",
        "  X = np.array(pickle.load(handle))\n",
        "with open('y_walkiebatch.pkl','rb') as handle:\n",
        "  y = np.array(pickle.load(handle))\n",
        "print('the shape of X',X.shape)\n",
        "print('the shape of y',y.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data...\n",
            "the shape of X (11868,)\n",
            "the shape of y (11868,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnVKARJIuhwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBm0gBfZZ_UG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "import random\n",
        "def fun_noise(X,y,PERCENT_NOISE,TIMES_NOISE): \n",
        "    X = list(X)\n",
        "    y = list(y)\n",
        "    X_sum = []\n",
        "    y_sum = []\n",
        "    #X_sum = X.copy()\n",
        "    #y_sum = y.copy()\n",
        "    #print(\"{} samples has beed add to X_train, {}% of noise for each sample\".format(math.ceil(len(X)*TIMES_NOISE),PERCENT_NOISE))\n",
        "    k=0\n",
        "    for i in range(math.ceil(len(X)*TIMES_NOISE)): #ADDING NOISE from here \n",
        "        if(i in list(range(0,math.ceil(len(X)*TIMES_NOISE),math.ceil(len(X)*TIMES_NOISE)//10))):\n",
        "            print(\"{}0% data has been dealed\".format(k),flush = True)\n",
        "            k +=1\n",
        "        while(True):\n",
        "            p = random.choice(range(len(X)))\n",
        "            if(y[p]!=-1):\n",
        "                break\n",
        "            else:\n",
        "                pass\n",
        "        X_new = X[p].copy()\n",
        "        y_new = y[p]\n",
        "        for n in range(math.ceil(PERCENT_NOISE*len(X_new)/100)):#dealing X_new\n",
        "            noise = random.choice([1,-1])       #noise could only be 1 or -1\n",
        "            pos = random.choice(range(len(X_new)))  #position belong to (0,len(sequence))\n",
        "            X_new.insert(pos,noise)\n",
        "            #print('insert {} at position {} in sequence {} now len of sequence is {}, the tag of sequence is {}'.format(noise,pos,p,len(X_new),y_new)) #for test\n",
        "        X_sum.append(X_new)\n",
        "        y_sum.append(y_new)\n",
        "    return X_sum,y_sum\n",
        "def fun_delete(X,y,PERCENT_DELETE,TIMES_DELETE): \n",
        "    X = list(X)\n",
        "    y = list(y)\n",
        "    X_sum = []\n",
        "    y_sum = []\n",
        "    #X_sum = X.copy()\n",
        "    #y_sum = y.copy()\n",
        "    k = 0\n",
        "    for i in range(math.ceil(len(X)*TIMES_DELETE)): #RANDOM DELETE from here\n",
        "        if(i in list(range(0,math.ceil(len(X)*TIMES_DELETE),math.ceil(len(X)*TIMES_DELETE)//10))):\n",
        "            print(\"{}0% data has been dealed\".format(k),flush = True)\n",
        "            k +=1\n",
        "        while(True):\n",
        "            p = random.choice(range(len(X)))\n",
        "            if(y[p]!=-1):\n",
        "                break\n",
        "            else:\n",
        "                #print('-1 detected')\n",
        "                pass\n",
        "        X_new = X[p].copy()\n",
        "        y_new = y[p]\n",
        "        for n in range(math.ceil(PERCENT_DELETE*len(X_new)/100)):#dealing X_new\n",
        "            pos = random.choice(range(len(X_new)))  #position belong to (0,len(sequence))\n",
        "            del X_new[pos]\n",
        "            #print('insert {} at position {} in sequence {} now len of sequence is {}'.format(noise,pos,p,len(X_new))) #for test\n",
        "        X_sum.append(X_new)\n",
        "        y_sum.append(y_new)\n",
        "    return X_sum,y_sum\n",
        "def fun_shuffle(X,y,PERCENT_CHANGED,TIMES_SHUFFLE): \n",
        "    X = list(X)\n",
        "    y = list(y)\n",
        "    #X_sum = X.copy()\n",
        "    #y_sum = y.copy()\n",
        "    X_sum = []\n",
        "    y_sum = []\n",
        "    k=0\n",
        "    for i in range(math.ceil(len(X)*TIMES_SHUFFLE)):             #LOCALLY CHANGE from here\n",
        "        if(i in list(range(0,math.ceil(len(X)*TIMES_SHUFFLE),math.ceil(len(X)*TIMES_SHUFFLE)//10))):\n",
        "            print(\"{}0% data has been dealed\".format(k),flush = True)\n",
        "            k +=1\n",
        "        while(True):\n",
        "            p = random.choice(range(len(X)))\n",
        "            if(y[p]!=-1):\n",
        "                break\n",
        "            else:\n",
        "                #print('-1 detected')\n",
        "                pass\n",
        "        X_new = X[p].copy()\n",
        "        y_new = y[p]\n",
        "        length = math.ceil(PERCENT_CHANGED*len(X_new)/100)\n",
        "        start = random.choice(range(len(X_new)-length))\n",
        "        temp = X_new[start:start+length]\n",
        "        random.shuffle(temp)\n",
        "        X_new[start:start+length] = temp\n",
        "\n",
        "        X_sum.append(X_new)\n",
        "        y_sum.append(y_new)\n",
        "    return X_sum,y_sum\n",
        "def fun_transplant(X,y,PERCENT_TRANSPLANT,NB_TIMES):        #Magnificate dataset by adding noising randomly\n",
        "    global datatype_Close\n",
        "    X = list(X)\n",
        "    y = list(y)\n",
        "    X_sum = []\n",
        "    y_sum = []\n",
        "    #X_sum = X.copy()\n",
        "    #y_sum = y.copy()\n",
        "    #print(\"{} samples has beed add to X_train, {}% of noise for each sample\".format(math.ceil(len(X)*NB_TIMES),PERCENT_TRANSPLANT))\n",
        "    k=0\n",
        "    print('When the process freezing, please check that datatype_Close has been set correctly')\n",
        "    for i in range(math.ceil(len(X)*NB_TIMES)):\n",
        "        if(i in list(range(0,math.ceil(len(X)*NB_TIMES),math.ceil(len(X)*NB_TIMES)//10))):\n",
        "            print(\"{}0% data has been dealed\".format(k),flush = True)\n",
        "            k +=1\n",
        "        #print(datatype_Close)    \n",
        "        while(datatype_Close):                               # target pos p (sensitive website), pos q (non-sensitive website)\n",
        "            p = random.choice(range(len(X)))\n",
        "            q = random.choice(range(len(X)))\n",
        "            if(p != q):                           # Closed_World\n",
        "                break\n",
        "            else:\n",
        "                #print('-1 detected')\n",
        "                pass\n",
        "        while(not datatype_Close):                               # target pos p (sensitive website), pos q (non-sensitive website)\n",
        "            p = random.choice(range(len(X)))\n",
        "            q = random.choice(range(len(X)))\n",
        "            if(y[p]!=-1 and y[q]==-1):               # open_world\n",
        "                break\n",
        "            else:\n",
        "                #print('-1 detected')\n",
        "                pass\n",
        "        X_new = X[p].copy()\n",
        "        target = X[q].copy()\n",
        "        y_new = y[p]\n",
        "\n",
        "        length_X = math.ceil(PERCENT_TRANSPLANT*len(X_new)/100)\n",
        "        length_target =  math.ceil(PERCENT_TRANSPLANT*len(target)/100)\n",
        "        start_X = random.choice(range(len(X_new)-length_X))\n",
        "        start_target = random.choice(range(len(target)-length_target))\n",
        "        temp = target[start_target:start_target+length_target]\n",
        "        X_new[start_X:start_X+length_X] = temp\n",
        "     \n",
        "        X_sum.append(X_new)\n",
        "        y_sum.append(y_new)\n",
        "    return X_sum,y_sum\n",
        "\n",
        "\n",
        "def fun_mixup(X,y,TIMES_mixup):\n",
        "    global datatype_Close\n",
        "    X = list(X)\n",
        "    y = list(y)\n",
        "    X_sum = []\n",
        "    y_sum = []\n",
        "    #X_sum = X.copy()\n",
        "    #y_sum = y.copy()\n",
        "    #print(\"{} samples has beed add to X_train, {}% of noise for each sample\".format(math.ceil(len(X)*NB_TIMES),PERCENT_TRANSPLANT))\n",
        "    for i in range(math.ceil(len(X)*NB_TIMES)):  \n",
        "        while(datatype_Close):                               # target pos p (sensitive website), pos q (non-sensitive website)\n",
        "            p = random.choice(range(len(X)))\n",
        "            q = random.choice(range(len(X)))\n",
        "            if(p != q):                           # Closed_World\n",
        "                break\n",
        "            else:\n",
        "                #print('-1 detected')\n",
        "                pass\n",
        "        while(not datatype_Close):                               # target pos p (sensitive website), pos q (non-sensitive website)\n",
        "            p = random.choice(range(len(X)))\n",
        "            q = random.choice(range(len(X)))\n",
        "            if(y[p]!=-1 and y[q]==-1):               # open_world\n",
        "                break\n",
        "            else:\n",
        "                #print('-1 detected')\n",
        "                pass\n",
        "        X_new = X[p].copy()\n",
        "        target = X[q].copy()\n",
        "        y_new = y[p]\n",
        "        X_temp = []\n",
        "        for n,t in zip(X_new,target):\n",
        "            temp = n*t\n",
        "            X_temp.append(temp)\n",
        "        X_sum.append(X_temp)\n",
        "        y_sum.append(y_new)\n",
        "    return X_sum,y_sum\n",
        "\n",
        "def random_launch(X,y,NB_tech):\n",
        "    X = list(X)\n",
        "    y = list(y)\n",
        "    #X_sum = X.copy()\n",
        "    #y_sum = y.copy()\n",
        "    X_sum = []\n",
        "    y_sum = []\n",
        "    if (NB_tech==0):\n",
        "        print('adding noise......')\n",
        "        X_new,y_new = fun_noise(X,y,PERCENT_NOISE=40,TIMES_NOISE=3)\n",
        "        X_sum.extend(X_new)\n",
        "        y_sum.extend(y_new)\n",
        "    elif (NB_tech==1):\n",
        "        print('deleting......')\n",
        "        X_new,y_new = fun_delete(X,y,PERCENT_DELETE=40,TIMES_DELETE=3)\n",
        "        X_sum.extend(X_new)\n",
        "        y_sum.extend(y_new)\n",
        "    elif (NB_tech==2):\n",
        "        print('shuffling......')\n",
        "        X_new,y_new = fun_shuffle(X,y,PERCENT_CHANGED=60,TIMES_SHUFFLE=3)\n",
        "        X_sum.extend(X_new)\n",
        "        y_sum.extend(y_new)\n",
        "    elif (NB_tech==3):\n",
        "        print('transplanting......')\n",
        "        X_new,y_new = fun_transplant(X,y,PERCENT_TRANSPLANT=60,NB_TIMES=3)\n",
        "        X_sum.extend(X_new)\n",
        "        y_sum.extend(y_new)\n",
        "    elif (NB_tech==4):\n",
        "        print('mixup......')\n",
        "        X_new,y_new = fun_transplant(X,y,PERCENT_TRANSPLANT=40,NB_TIMES=3)\n",
        "        X_sum.extend(X_new)\n",
        "        y_sum.extend(y_new)\n",
        "    return np.array(X_sum),np.array(y_sum)                        #return two array of X, y \n",
        "\n",
        "NB_TECHS = 5 # set Number of techs here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZpMmHj3Uefl",
        "colab_type": "code",
        "outputId": "a44677ad-9559-4422-82a9-387baf9a2539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from collections import Counter\n",
        "#CLASSES_KNN = 101########################################################################################################################################################################################################\n",
        "#CLASSES_WAKIE = 100########################################################################################################################################################################################################\n",
        "MAXLEN_KNN = 2000\n",
        "MAXLEN_WAKIE =5000\n",
        "\n",
        "maxlen = 5000\n",
        "NB_CLASSES = 0\n",
        "\n",
        "def choose():\n",
        "    global maxlen,NB_CLASSES\n",
        "    print('if padding, the max of length of seq is {}'.format(maxlen))\n",
        "    NB_CLASSES = len(Counter(y).keys())\n",
        "    print('number of classes is {}'.format(NB_CLASSES))\n",
        "\n",
        "choose()################################################################################################################################################################################################################\n",
        "\n",
        "print('Average sequence length: {}'.format(np.mean(list(map(len, X)), dtype=int)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "if padding, the max of length of seq is 5000\n",
            "number of classes is 108\n",
            "Average sequence length: 4471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8U6mqSg-UYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MLP\n",
        "from keras import Sequential\n",
        "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adamax\n",
        "def MLP(input_shape,classes):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=(input_shape,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "def run_MLP(X_train,y_train,X_test,y_test,X_temp,y_temp,BATCH_SIZE,history):\n",
        "    for i in range(NB_EPOCHS):\n",
        "        if (i<=NB_EPOCHS/5):\n",
        "            log = model_MLP.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        elif (NB_EPOCHS/5<i and i%2==1 and i<(NB_EPOCHS*4/5)):\n",
        "            log = model_MLP.fit(X_temp,y_temp,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        elif (NB_EPOCHS/5<i and i%2==0 and i<(NB_EPOCHS*4/5)):\n",
        "            log = model_MLP.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        else:\n",
        "            log = model_MLP.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_gm7tqd4yEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FCN\n",
        "from keras import Sequential\n",
        "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.optimizers import Adamax\n",
        "def DNN(input_shape,classes):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=(input_shape,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    #model.add(GlobalAveragePooling1D()) #parimatier is not defined\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "def run_DNN(X_train,y_train,X_test,y_test,X_temp,y_temp,BATCH_SIZE,history):\n",
        "    for i in range(NB_EPOCHS):\n",
        "        if (i<=NB_EPOCHS/5):\n",
        "            log = model_DNN.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        elif (NB_EPOCHS/5<i and i%2==1 and i<(NB_EPOCHS*4/5)):\n",
        "            log = model_DNN.fit(X_temp,y_temp,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        elif (NB_EPOCHS/5<i and i%2==0 and i<(NB_EPOCHS*4/5)):\n",
        "            log = model_DNN.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        else:\n",
        "            log = model_DNN.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hQ5LZK6sFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CNN\n",
        "from keras import Input,Model,Sequential\n",
        "from keras.layers import Embedding,GlobalAveragePooling1D,Dense,Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.optimizers import Adamax\n",
        "def CNN(input_shape, classes):\n",
        "    model = Sequential()\n",
        "    #Block1\n",
        "    filter_num = ['None',32,64,128,256]\n",
        "    kernel_size = ['None',8,8,8,8]\n",
        "    conv_stride_size = ['None',1,1,1,1]\n",
        "    pool_stride_size = ['None',4,4,4,4]\n",
        "    pool_size = ['None',8,8,8,8]\n",
        "\n",
        "    model.add(Conv1D(filters=filter_num[1], kernel_size=kernel_size[1], input_shape=(input_shape,1),\n",
        "                      strides=conv_stride_size[1], padding='same',\n",
        "                      name='block1_conv1'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(ELU(alpha=1.0, name='block1_adv_act1'))\n",
        "    model.add(Conv1D(filters=filter_num[1], kernel_size=kernel_size[1],\n",
        "                      strides=conv_stride_size[1], padding='same',\n",
        "                      name='block1_conv2'))\n",
        "    model.add(BatchNormalization(axis=-1))\n",
        "    model.add(ELU(alpha=1.0, name='block1_adv_act2'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size[1], strides=pool_stride_size[1],\n",
        "                            padding='same', name='block1_pool'))\n",
        "    model.add(Dropout(0.1, name='block1_dropout'))\n",
        "\n",
        "    model.add(Conv1D(filters=filter_num[2], kernel_size=kernel_size[2],\n",
        "                      strides=conv_stride_size[2], padding='same',\n",
        "                      name='block2_conv1'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='block2_act1'))\n",
        "\n",
        "    model.add(Conv1D(filters=filter_num[2], kernel_size=kernel_size[2],\n",
        "                      strides=conv_stride_size[2], padding='same',\n",
        "                      name='block2_conv2'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='block2_act2'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size[2], strides=pool_stride_size[3],\n",
        "                            padding='same', name='block2_pool'))\n",
        "    model.add(Dropout(0.1, name='block2_dropout'))\n",
        "\n",
        "    model.add(Conv1D(filters=filter_num[3], kernel_size=kernel_size[3],\n",
        "                      strides=conv_stride_size[3], padding='same',\n",
        "                      name='block3_conv1'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='block3_act1'))\n",
        "    model.add(Conv1D(filters=filter_num[3], kernel_size=kernel_size[3],\n",
        "                      strides=conv_stride_size[3], padding='same',\n",
        "                      name='block3_conv2'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='block3_act2'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size[3], strides=pool_stride_size[3],\n",
        "                            padding='same', name='block3_pool'))\n",
        "    model.add(Dropout(0.1, name='block3_dropout'))\n",
        "\n",
        "    model.add(Conv1D(filters=filter_num[4], kernel_size=kernel_size[4],\n",
        "                      strides=conv_stride_size[4], padding='same',\n",
        "                      name='block4_conv1'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='block4_act1'))\n",
        "    model.add(Conv1D(filters=filter_num[4], kernel_size=kernel_size[4],\n",
        "                      strides=conv_stride_size[4], padding='same',\n",
        "                      name='block4_conv2'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='block4_act2'))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size[4], strides=pool_stride_size[4],\n",
        "                            padding='same', name='block4_pool'))\n",
        "    model.add(Dropout(0.1, name='block4_dropout'))\n",
        "\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name='fc1'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='fc1_act'))\n",
        "\n",
        "    model.add(Dropout(0.7, name='fc1_dropout'))\n",
        "\n",
        "    model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name='fc2'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu', name='fc2_act'))\n",
        "\n",
        "    model.add(Dropout(0.5, name='fc2_dropout'))\n",
        "\n",
        "    model.add(Dense(classes, kernel_initializer=glorot_uniform(seed=0), name='fc3'))\n",
        "    model.add(Activation('softmax', name=\"softmax\"))\n",
        "    return model\n",
        "def run_CNN(X_train,y_train,X_test,y_test,X_temp,y_temp,BATCH_SIZE,history):\n",
        "    for i in range(NB_EPOCHS):\n",
        "        if (i<=NB_EPOCHS/5):\n",
        "            log = model_CNN.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        elif (NB_EPOCHS/5<i and i%2==1 and i<(NB_EPOCHS*4/5)):\n",
        "            log = model_CNN.fit(X_temp,y_temp,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        elif (NB_EPOCHS/5<i and i%2==0 and i<(NB_EPOCHS*4/5)):\n",
        "            log = model_CNN.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)\n",
        "        else:\n",
        "            log = model_CNN.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=1,validation_data=(X_test,y_test),verbose=1)\n",
        "            history.recorder(log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuVICfeHwymL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    # Calculates the precision\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    # Calculates the recall\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def fbeta_score(y_true, y_pred, beta=1):\n",
        "    # Calculates the F score, the weighted harmonic mean of precision and recall.\n",
        "    if beta < 0:\n",
        "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
        " \n",
        "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0\n",
        "\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    bb = beta ** 2\n",
        "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
        "    return fbeta_score\n",
        "\n",
        "def fmeasure(y_true, y_pred):\n",
        "    # Calculates the f-measure, the harmonic mean of precision and recall.\n",
        "    return fbeta_score(y_true, y_pred, beta=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1NuHD0d-Z-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class my_history():\n",
        "    def __init__(self):\n",
        "        self.history = {'loss':[],'acc':[],'top_k_categorical_accuracy':[],'precision':[],'recall':[],'fmeasure':[],'val_loss':[],'val_acc':[],'val_top_k_categorical_accuracy':[],'val_precision':[],'val_recall':[],'val_fmeasure':[]}\n",
        "    def recorder(self,history):\n",
        "        self.history['loss'].append(history.history['loss'][0])\n",
        "        self.history['acc'].append(history.history['acc'][0])\n",
        "        self.history['top_k_categorical_accuracy'].append(history.history['top_k_categorical_accuracy'][0])\n",
        "        self.history['precision'].append(history.history['precision'][0])\n",
        "        self.history['recall'].append(history.history['recall'][0])\n",
        "        self.history['fmeasure'].append(history.history['fmeasure'][0])\n",
        "        self.history['val_loss'].append(history.history['val_loss'][0])\n",
        "        self.history['val_acc'].append(history.history['val_acc'][0])\n",
        "        self.history['val_top_k_categorical_accuracy'].append(history.history['val_top_k_categorical_accuracy'][0])\n",
        "        self.history['val_precision'].append(history.history['val_precision'][0])\n",
        "        self.history['val_recall'].append(history.history['val_recall'][0])\n",
        "        self.history['val_fmeasure'].append(history.history['val_fmeasure'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYcnyeHg-bM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d65db319-5afb-43d4-e0d7-4e7c2e684fdd"
      },
      "source": [
        "import gc\n",
        "VALIDATION_SPLIT = 0.3\n",
        "\n",
        "X_train_saved,X_test_saved,y_train_saved,y_test_saved = train_test_split(X,y,test_size=VALIDATION_SPLIT)\n",
        "del X\n",
        "del y\n",
        "print('launching  garbage collect .....')\n",
        "gc.collect()\n",
        "print('garbage collected .....')\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NB_EPOCHS = 100\n",
        "\n",
        "OPTIMIZER = Adamax()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "launching  garbage collect .....\n",
            "garbage collected .....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHpKFUbH-diZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbd4cddd-cab2-4f79-9f81-a94613ecd469"
      },
      "source": [
        "#MLP               ############# test for noise adding  , function :: creat_data############\n",
        "\n",
        "history_MLP = []\n",
        "for i in range(NB_TECHS):\n",
        "    his = my_history()\n",
        "    X_temp,y_temp = random_launch(X_train_saved,y_train_saved,i)\n",
        "    X_temp = sequence.pad_sequences(X_temp, maxlen=maxlen,padding='post',truncating='post')\n",
        "    y_temp = np_utils.to_categorical(y_temp, NB_CLASSES)\n",
        "    X_train = sequence.pad_sequences(X_train_saved, maxlen=maxlen,padding='post',truncating='post')\n",
        "    y_train = np_utils.to_categorical(y_train_saved, NB_CLASSES)\n",
        "    X_test = sequence.pad_sequences(X_test_saved, maxlen=maxlen,padding='post',truncating='post')\n",
        "    y_test = np_utils.to_categorical(y_test_saved, NB_CLASSES)\n",
        "    model_MLP = MLP(maxlen,NB_CLASSES)\n",
        "    #model_MLP.summary()\n",
        "    model_MLP.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy','top_k_categorical_accuracy', precision, recall, fmeasure])\n",
        "    run_MLP(X_train,y_train,X_test,y_test,X_temp,y_temp,BATCH_SIZE,history = his)\n",
        "    history_MLP.append(his)\n",
        "\n",
        "\n",
        "print('the shape of x_train',X_train.shape)\n",
        "print('the shape of y_train',y_train.shape)\n",
        "print('the shape of x_test',X_test.shape)\n",
        "print('the shape of y_test',y_test.shape)\n",
        "\n",
        "print('base_line_now#######################################################################################################################################################################################################')\n",
        "model_MLP_org = MLP(maxlen,NB_CLASSES)\n",
        "model_MLP_org.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy','top_k_categorical_accuracy', precision, recall, fmeasure])\n",
        "history_MLP_org = model_MLP_org.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCHS,validation_data=(X_test,y_test),verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adding noise......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "8307/8307 [==============================] - 10s 1ms/step - loss: 3.6594 - acc: 0.1275 - top_k_categorical_accuracy: 0.3593 - precision: 0.1484 - recall: 0.0061 - fmeasure: 0.0115 - val_loss: 2.9710 - val_acc: 0.2598 - val_top_k_categorical_accuracy: 0.5830 - val_precision: 0.7700 - val_recall: 0.0373 - val_fmeasure: 0.0705\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 2.4073 - acc: 0.4054 - top_k_categorical_accuracy: 0.7147 - precision: 0.7844 - recall: 0.1611 - fmeasure: 0.2582 - val_loss: 2.2012 - val_acc: 0.4757 - val_top_k_categorical_accuracy: 0.7742 - val_precision: 0.8099 - val_recall: 0.2575 - val_fmeasure: 0.3893\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 1.7330 - acc: 0.5772 - top_k_categorical_accuracy: 0.8273 - precision: 0.8224 - recall: 0.3786 - fmeasure: 0.5154 - val_loss: 1.8718 - val_acc: 0.5600 - val_top_k_categorical_accuracy: 0.8208 - val_precision: 0.8118 - val_recall: 0.3743 - val_fmeasure: 0.5108\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 1.3358 - acc: 0.6721 - top_k_categorical_accuracy: 0.8872 - precision: 0.8292 - recall: 0.5298 - fmeasure: 0.6443 - val_loss: 1.5589 - val_acc: 0.6543 - val_top_k_categorical_accuracy: 0.8573 - val_precision: 0.8146 - val_recall: 0.5184 - val_fmeasure: 0.6323\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 1.0879 - acc: 0.7312 - top_k_categorical_accuracy: 0.9140 - precision: 0.8566 - recall: 0.6241 - fmeasure: 0.7208 - val_loss: 1.3973 - val_acc: 0.6835 - val_top_k_categorical_accuracy: 0.8851 - val_precision: 0.7925 - val_recall: 0.5976 - val_fmeasure: 0.6807\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.9171 - acc: 0.7650 - top_k_categorical_accuracy: 0.9332 - precision: 0.8666 - recall: 0.6805 - fmeasure: 0.7617 - val_loss: 1.3258 - val_acc: 0.6883 - val_top_k_categorical_accuracy: 0.8882 - val_precision: 0.8139 - val_recall: 0.5998 - val_fmeasure: 0.6899\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 118us/step - loss: 0.7704 - acc: 0.7955 - top_k_categorical_accuracy: 0.9515 - precision: 0.8785 - recall: 0.7284 - fmeasure: 0.7958 - val_loss: 1.1619 - val_acc: 0.7386 - val_top_k_categorical_accuracy: 0.9085 - val_precision: 0.8528 - val_recall: 0.6599 - val_fmeasure: 0.7429\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 0.6817 - acc: 0.8105 - top_k_categorical_accuracy: 0.9623 - precision: 0.8859 - recall: 0.7515 - fmeasure: 0.8125 - val_loss: 1.2682 - val_acc: 0.7158 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.8034 - val_recall: 0.6563 - val_fmeasure: 0.7219\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.6170 - acc: 0.8226 - top_k_categorical_accuracy: 0.9683 - precision: 0.8906 - recall: 0.7701 - fmeasure: 0.8254 - val_loss: 1.2410 - val_acc: 0.7203 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.8008 - val_recall: 0.6599 - val_fmeasure: 0.7229\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 118us/step - loss: 0.5350 - acc: 0.8474 - top_k_categorical_accuracy: 0.9770 - precision: 0.8999 - recall: 0.8027 - fmeasure: 0.8481 - val_loss: 1.2110 - val_acc: 0.7279 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.8029 - val_recall: 0.6818 - val_fmeasure: 0.7371\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 0.4716 - acc: 0.8572 - top_k_categorical_accuracy: 0.9823 - precision: 0.9004 - recall: 0.8188 - fmeasure: 0.8573 - val_loss: 1.1791 - val_acc: 0.7478 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.8135 - val_recall: 0.7040 - val_fmeasure: 0.7545\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.4082 - acc: 0.8766 - top_k_categorical_accuracy: 0.9888 - precision: 0.9117 - recall: 0.8418 - fmeasure: 0.8750 - val_loss: 1.1930 - val_acc: 0.7554 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.8139 - val_recall: 0.7181 - val_fmeasure: 0.7625\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.3794 - acc: 0.8791 - top_k_categorical_accuracy: 0.9919 - precision: 0.9147 - recall: 0.8457 - fmeasure: 0.8785 - val_loss: 1.3526 - val_acc: 0.7332 - val_top_k_categorical_accuracy: 0.9068 - val_precision: 0.7940 - val_recall: 0.7043 - val_fmeasure: 0.7461\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3418 - acc: 0.8902 - top_k_categorical_accuracy: 0.9931 - precision: 0.9215 - recall: 0.8640 - fmeasure: 0.8916 - val_loss: 1.3314 - val_acc: 0.7338 - val_top_k_categorical_accuracy: 0.9087 - val_precision: 0.7931 - val_recall: 0.6973 - val_fmeasure: 0.7416\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.3278 - acc: 0.8930 - top_k_categorical_accuracy: 0.9951 - precision: 0.9218 - recall: 0.8689 - fmeasure: 0.8944 - val_loss: 1.1785 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.8172 - val_recall: 0.7394 - val_fmeasure: 0.7760\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2765 - acc: 0.9086 - top_k_categorical_accuracy: 0.9977 - precision: 0.9305 - recall: 0.8855 - fmeasure: 0.9073 - val_loss: 1.3018 - val_acc: 0.7391 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.7893 - val_recall: 0.7172 - val_fmeasure: 0.7512\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2721 - acc: 0.9107 - top_k_categorical_accuracy: 0.9976 - precision: 0.9305 - recall: 0.8906 - fmeasure: 0.9099 - val_loss: 1.2882 - val_acc: 0.7487 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.8014 - val_recall: 0.7282 - val_fmeasure: 0.7626\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2454 - acc: 0.9189 - top_k_categorical_accuracy: 0.9978 - precision: 0.9346 - recall: 0.8992 - fmeasure: 0.9164 - val_loss: 1.2965 - val_acc: 0.7518 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.8023 - val_recall: 0.7284 - val_fmeasure: 0.7633\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2383 - acc: 0.9192 - top_k_categorical_accuracy: 0.9984 - precision: 0.9360 - recall: 0.9031 - fmeasure: 0.9191 - val_loss: 1.3195 - val_acc: 0.7588 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7992 - val_recall: 0.7372 - val_fmeasure: 0.7667\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2164 - acc: 0.9281 - top_k_categorical_accuracy: 0.9986 - precision: 0.9434 - recall: 0.9144 - fmeasure: 0.9285 - val_loss: 1.3599 - val_acc: 0.7599 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.7960 - val_recall: 0.7408 - val_fmeasure: 0.7672\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1988 - acc: 0.9334 - top_k_categorical_accuracy: 0.9993 - precision: 0.9462 - recall: 0.9210 - fmeasure: 0.9334 - val_loss: 1.3394 - val_acc: 0.7627 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7951 - val_recall: 0.7445 - val_fmeasure: 0.7688\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 1.9465 - acc: 0.5199 - top_k_categorical_accuracy: 0.7872 - precision: 0.7324 - recall: 0.3572 - fmeasure: 0.4649 - val_loss: 6.6236 - val_acc: 0.0750 - val_top_k_categorical_accuracy: 0.2777 - val_precision: 0.0873 - val_recall: 0.0545 - val_fmeasure: 0.0669\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.8701 - acc: 0.7774 - top_k_categorical_accuracy: 0.9322 - precision: 0.8440 - recall: 0.7134 - fmeasure: 0.7639 - val_loss: 1.1225 - val_acc: 0.7742 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8246 - val_recall: 0.7453 - val_fmeasure: 0.7826\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 1.0530 - acc: 0.7130 - top_k_categorical_accuracy: 0.9216 - precision: 0.8364 - recall: 0.6089 - fmeasure: 0.7002 - val_loss: 6.3333 - val_acc: 0.0991 - val_top_k_categorical_accuracy: 0.3611 - val_precision: 0.1150 - val_recall: 0.0798 - val_fmeasure: 0.0941\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.7329 - acc: 0.8028 - top_k_categorical_accuracy: 0.9524 - precision: 0.8607 - recall: 0.7530 - fmeasure: 0.7996 - val_loss: 1.1280 - val_acc: 0.7843 - val_top_k_categorical_accuracy: 0.9320 - val_precision: 0.8299 - val_recall: 0.7582 - val_fmeasure: 0.7921\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.6978 - acc: 0.7994 - top_k_categorical_accuracy: 0.9624 - precision: 0.8759 - recall: 0.7318 - fmeasure: 0.7951 - val_loss: 6.3665 - val_acc: 0.1112 - val_top_k_categorical_accuracy: 0.4103 - val_precision: 0.1166 - val_recall: 0.0859 - val_fmeasure: 0.0988\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.6660 - acc: 0.8197 - top_k_categorical_accuracy: 0.9623 - precision: 0.8666 - recall: 0.7786 - fmeasure: 0.8186 - val_loss: 1.1610 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.8215 - val_recall: 0.7546 - val_fmeasure: 0.7864\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.4986 - acc: 0.8493 - top_k_categorical_accuracy: 0.9797 - precision: 0.9032 - recall: 0.8030 - fmeasure: 0.8484 - val_loss: 5.9904 - val_acc: 0.1620 - val_top_k_categorical_accuracy: 0.5024 - val_precision: 0.1744 - val_recall: 0.1356 - val_fmeasure: 0.1524\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.6216 - acc: 0.8281 - top_k_categorical_accuracy: 0.9721 - precision: 0.8736 - recall: 0.7904 - fmeasure: 0.8285 - val_loss: 1.1781 - val_acc: 0.7765 - val_top_k_categorical_accuracy: 0.9309 - val_precision: 0.8200 - val_recall: 0.7532 - val_fmeasure: 0.7849\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.3616 - acc: 0.8877 - top_k_categorical_accuracy: 0.9873 - precision: 0.9230 - recall: 0.8553 - fmeasure: 0.8867 - val_loss: 6.7069 - val_acc: 0.1606 - val_top_k_categorical_accuracy: 0.5001 - val_precision: 0.1685 - val_recall: 0.1401 - val_fmeasure: 0.1529\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.5793 - acc: 0.8443 - top_k_categorical_accuracy: 0.9721 - precision: 0.8831 - recall: 0.8138 - fmeasure: 0.8460 - val_loss: 1.2079 - val_acc: 0.7787 - val_top_k_categorical_accuracy: 0.9281 - val_precision: 0.8161 - val_recall: 0.7579 - val_fmeasure: 0.7856\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.2754 - acc: 0.9147 - top_k_categorical_accuracy: 0.9916 - precision: 0.9409 - recall: 0.8893 - fmeasure: 0.9134 - val_loss: 6.1914 - val_acc: 0.1960 - val_top_k_categorical_accuracy: 0.5706 - val_precision: 0.2070 - val_recall: 0.1752 - val_fmeasure: 0.1897\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.5103 - acc: 0.8581 - top_k_categorical_accuracy: 0.9807 - precision: 0.8861 - recall: 0.8313 - fmeasure: 0.8571 - val_loss: 1.3295 - val_acc: 0.7591 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7896 - val_recall: 0.7397 - val_fmeasure: 0.7636\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.2277 - acc: 0.9307 - top_k_categorical_accuracy: 0.9929 - precision: 0.9510 - recall: 0.9113 - fmeasure: 0.9298 - val_loss: 5.5662 - val_acc: 0.2519 - val_top_k_categorical_accuracy: 0.6445 - val_precision: 0.2651 - val_recall: 0.2325 - val_fmeasure: 0.2475\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.5099 - acc: 0.8598 - top_k_categorical_accuracy: 0.9827 - precision: 0.8903 - recall: 0.8303 - fmeasure: 0.8585 - val_loss: 1.2566 - val_acc: 0.7739 - val_top_k_categorical_accuracy: 0.9301 - val_precision: 0.8052 - val_recall: 0.7568 - val_fmeasure: 0.7801\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 100us/step - loss: 0.1807 - acc: 0.9447 - top_k_categorical_accuracy: 0.9950 - precision: 0.9588 - recall: 0.9292 - fmeasure: 0.9433 - val_loss: 5.5685 - val_acc: 0.2758 - val_top_k_categorical_accuracy: 0.6630 - val_precision: 0.2974 - val_recall: 0.2606 - val_fmeasure: 0.2776\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.4907 - acc: 0.8634 - top_k_categorical_accuracy: 0.9824 - precision: 0.8927 - recall: 0.8405 - fmeasure: 0.8653 - val_loss: 1.2989 - val_acc: 0.7765 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8036 - val_recall: 0.7607 - val_fmeasure: 0.7814\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1529 - acc: 0.9549 - top_k_categorical_accuracy: 0.9959 - precision: 0.9651 - recall: 0.9426 - fmeasure: 0.9533 - val_loss: 4.8499 - val_acc: 0.3404 - val_top_k_categorical_accuracy: 0.7186 - val_precision: 0.3561 - val_recall: 0.3182 - val_fmeasure: 0.3359\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.4462 - acc: 0.8697 - top_k_categorical_accuracy: 0.9862 - precision: 0.8949 - recall: 0.8507 - fmeasure: 0.8718 - val_loss: 1.2814 - val_acc: 0.7770 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8093 - val_recall: 0.7579 - val_fmeasure: 0.7826\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1209 - acc: 0.9647 - top_k_categorical_accuracy: 0.9965 - precision: 0.9728 - recall: 0.9549 - fmeasure: 0.9634 - val_loss: 5.3718 - val_acc: 0.3064 - val_top_k_categorical_accuracy: 0.7136 - val_precision: 0.3200 - val_recall: 0.2887 - val_fmeasure: 0.3034\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.4428 - acc: 0.8773 - top_k_categorical_accuracy: 0.9866 - precision: 0.9012 - recall: 0.8576 - fmeasure: 0.8785 - val_loss: 1.2827 - val_acc: 0.7804 - val_top_k_categorical_accuracy: 0.9275 - val_precision: 0.8095 - val_recall: 0.7641 - val_fmeasure: 0.7860\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1054 - acc: 0.9699 - top_k_categorical_accuracy: 0.9970 - precision: 0.9773 - recall: 0.9627 - fmeasure: 0.9695 - val_loss: 5.0281 - val_acc: 0.3575 - val_top_k_categorical_accuracy: 0.7256 - val_precision: 0.3749 - val_recall: 0.3423 - val_fmeasure: 0.3578\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.4266 - acc: 0.8820 - top_k_categorical_accuracy: 0.9886 - precision: 0.9022 - recall: 0.8616 - fmeasure: 0.8812 - val_loss: 1.3063 - val_acc: 0.7647 - val_top_k_categorical_accuracy: 0.9295 - val_precision: 0.8011 - val_recall: 0.7495 - val_fmeasure: 0.7742\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1053 - acc: 0.9703 - top_k_categorical_accuracy: 0.9969 - precision: 0.9772 - recall: 0.9633 - fmeasure: 0.9699 - val_loss: 4.9422 - val_acc: 0.3507 - val_top_k_categorical_accuracy: 0.7439 - val_precision: 0.3666 - val_recall: 0.3353 - val_fmeasure: 0.3501\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3910 - acc: 0.8877 - top_k_categorical_accuracy: 0.9882 - precision: 0.9101 - recall: 0.8705 - fmeasure: 0.8895 - val_loss: 1.2864 - val_acc: 0.7863 - val_top_k_categorical_accuracy: 0.9275 - val_precision: 0.8168 - val_recall: 0.7720 - val_fmeasure: 0.7936\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.0877 - acc: 0.9747 - top_k_categorical_accuracy: 0.9976 - precision: 0.9805 - recall: 0.9693 - fmeasure: 0.9746 - val_loss: 4.5630 - val_acc: 0.3982 - val_top_k_categorical_accuracy: 0.7647 - val_precision: 0.4161 - val_recall: 0.3830 - val_fmeasure: 0.3988\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.4080 - acc: 0.8886 - top_k_categorical_accuracy: 0.9898 - precision: 0.9066 - recall: 0.8723 - fmeasure: 0.8888 - val_loss: 1.3616 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.7958 - val_recall: 0.7504 - val_fmeasure: 0.7722\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0804 - acc: 0.9775 - top_k_categorical_accuracy: 0.9973 - precision: 0.9829 - recall: 0.9733 - fmeasure: 0.9779 - val_loss: 4.3267 - val_acc: 0.4322 - val_top_k_categorical_accuracy: 0.7942 - val_precision: 0.4488 - val_recall: 0.4190 - val_fmeasure: 0.4333\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.3508 - acc: 0.9009 - top_k_categorical_accuracy: 0.9917 - precision: 0.9173 - recall: 0.8867 - fmeasure: 0.9015 - val_loss: 1.3402 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9292 - val_precision: 0.7978 - val_recall: 0.7638 - val_fmeasure: 0.7803\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0722 - acc: 0.9804 - top_k_categorical_accuracy: 0.9981 - precision: 0.9841 - recall: 0.9761 - fmeasure: 0.9799 - val_loss: 4.2132 - val_acc: 0.4443 - val_top_k_categorical_accuracy: 0.7995 - val_precision: 0.4599 - val_recall: 0.4277 - val_fmeasure: 0.4431\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3732 - acc: 0.8917 - top_k_categorical_accuracy: 0.9924 - precision: 0.9103 - recall: 0.8750 - fmeasure: 0.8921 - val_loss: 1.3329 - val_acc: 0.7725 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.8047 - val_recall: 0.7571 - val_fmeasure: 0.7800\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.0732 - acc: 0.9801 - top_k_categorical_accuracy: 0.9977 - precision: 0.9843 - recall: 0.9760 - fmeasure: 0.9799 - val_loss: 4.5507 - val_acc: 0.4165 - val_top_k_categorical_accuracy: 0.7894 - val_precision: 0.4294 - val_recall: 0.4055 - val_fmeasure: 0.4170\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3516 - acc: 0.8983 - top_k_categorical_accuracy: 0.9919 - precision: 0.9132 - recall: 0.8846 - fmeasure: 0.8986 - val_loss: 1.3183 - val_acc: 0.7860 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8102 - val_recall: 0.7664 - val_fmeasure: 0.7875\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0656 - acc: 0.9824 - top_k_categorical_accuracy: 0.9981 - precision: 0.9868 - recall: 0.9790 - fmeasure: 0.9827 - val_loss: 4.0863 - val_acc: 0.4799 - val_top_k_categorical_accuracy: 0.8071 - val_precision: 0.4930 - val_recall: 0.4667 - val_fmeasure: 0.4794\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3234 - acc: 0.9059 - top_k_categorical_accuracy: 0.9953 - precision: 0.9191 - recall: 0.8947 - fmeasure: 0.9066 - val_loss: 1.3494 - val_acc: 0.7770 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8032 - val_recall: 0.7641 - val_fmeasure: 0.7830\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0675 - acc: 0.9810 - top_k_categorical_accuracy: 0.9979 - precision: 0.9848 - recall: 0.9771 - fmeasure: 0.9807 - val_loss: 3.8743 - val_acc: 0.4912 - val_top_k_categorical_accuracy: 0.8135 - val_precision: 0.5103 - val_recall: 0.4796 - val_fmeasure: 0.4944\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.3240 - acc: 0.9030 - top_k_categorical_accuracy: 0.9952 - precision: 0.9189 - recall: 0.8906 - fmeasure: 0.9044 - val_loss: 1.4438 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7910 - val_recall: 0.7520 - val_fmeasure: 0.7709\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0629 - acc: 0.9832 - top_k_categorical_accuracy: 0.9986 - precision: 0.9866 - recall: 0.9793 - fmeasure: 0.9827 - val_loss: 4.2209 - val_acc: 0.4561 - val_top_k_categorical_accuracy: 0.8102 - val_precision: 0.4722 - val_recall: 0.4457 - val_fmeasure: 0.4585\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3023 - acc: 0.9110 - top_k_categorical_accuracy: 0.9949 - precision: 0.9256 - recall: 0.8995 - fmeasure: 0.9122 - val_loss: 1.4039 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.7927 - val_recall: 0.7459 - val_fmeasure: 0.7684\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0615 - acc: 0.9819 - top_k_categorical_accuracy: 0.9986 - precision: 0.9857 - recall: 0.9789 - fmeasure: 0.9821 - val_loss: 3.9250 - val_acc: 0.5119 - val_top_k_categorical_accuracy: 0.8189 - val_precision: 0.5257 - val_recall: 0.4985 - val_fmeasure: 0.5116\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2879 - acc: 0.9126 - top_k_categorical_accuracy: 0.9967 - precision: 0.9247 - recall: 0.9021 - fmeasure: 0.9131 - val_loss: 1.4030 - val_acc: 0.7742 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8013 - val_recall: 0.7635 - val_fmeasure: 0.7818\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 100us/step - loss: 0.0506 - acc: 0.9857 - top_k_categorical_accuracy: 0.9991 - precision: 0.9883 - recall: 0.9830 - fmeasure: 0.9855 - val_loss: 4.0553 - val_acc: 0.5074 - val_top_k_categorical_accuracy: 0.8161 - val_precision: 0.5225 - val_recall: 0.4954 - val_fmeasure: 0.5085\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2638 - acc: 0.9161 - top_k_categorical_accuracy: 0.9965 - precision: 0.9284 - recall: 0.9051 - fmeasure: 0.9165 - val_loss: 1.4295 - val_acc: 0.7664 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7939 - val_recall: 0.7599 - val_fmeasure: 0.7764\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.0526 - acc: 0.9862 - top_k_categorical_accuracy: 0.9989 - precision: 0.9886 - recall: 0.9837 - fmeasure: 0.9860 - val_loss: 3.9343 - val_acc: 0.5066 - val_top_k_categorical_accuracy: 0.8290 - val_precision: 0.5224 - val_recall: 0.4971 - val_fmeasure: 0.5093\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2531 - acc: 0.9226 - top_k_categorical_accuracy: 0.9969 - precision: 0.9323 - recall: 0.9139 - fmeasure: 0.9229 - val_loss: 1.4522 - val_acc: 0.7711 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.7951 - val_recall: 0.7610 - val_fmeasure: 0.7775\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0576 - acc: 0.9833 - top_k_categorical_accuracy: 0.9989 - precision: 0.9868 - recall: 0.9801 - fmeasure: 0.9833 - val_loss: 4.1440 - val_acc: 0.4898 - val_top_k_categorical_accuracy: 0.8082 - val_precision: 0.5007 - val_recall: 0.4768 - val_fmeasure: 0.4884\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2680 - acc: 0.9203 - top_k_categorical_accuracy: 0.9958 - precision: 0.9308 - recall: 0.9101 - fmeasure: 0.9202 - val_loss: 1.4774 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7951 - val_recall: 0.7610 - val_fmeasure: 0.7776\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 105us/step - loss: 0.0611 - acc: 0.9821 - top_k_categorical_accuracy: 0.9989 - precision: 0.9852 - recall: 0.9799 - fmeasure: 0.9824 - val_loss: 3.8677 - val_acc: 0.5161 - val_top_k_categorical_accuracy: 0.8399 - val_precision: 0.5300 - val_recall: 0.5035 - val_fmeasure: 0.5162\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 118us/step - loss: 0.2598 - acc: 0.9190 - top_k_categorical_accuracy: 0.9966 - precision: 0.9304 - recall: 0.9106 - fmeasure: 0.9202 - val_loss: 1.4833 - val_acc: 0.7672 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.7896 - val_recall: 0.7579 - val_fmeasure: 0.7733\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.0462 - acc: 0.9870 - top_k_categorical_accuracy: 0.9992 - precision: 0.9899 - recall: 0.9845 - fmeasure: 0.9871 - val_loss: 3.8831 - val_acc: 0.5184 - val_top_k_categorical_accuracy: 0.8267 - val_precision: 0.5341 - val_recall: 0.5086 - val_fmeasure: 0.5209\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2532 - acc: 0.9226 - top_k_categorical_accuracy: 0.9970 - precision: 0.9332 - recall: 0.9128 - fmeasure: 0.9228 - val_loss: 1.4423 - val_acc: 0.7838 - val_top_k_categorical_accuracy: 0.9284 - val_precision: 0.8080 - val_recall: 0.7759 - val_fmeasure: 0.7915\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0507 - acc: 0.9858 - top_k_categorical_accuracy: 0.9994 - precision: 0.9878 - recall: 0.9834 - fmeasure: 0.9855 - val_loss: 4.1580 - val_acc: 0.4920 - val_top_k_categorical_accuracy: 0.8082 - val_precision: 0.5063 - val_recall: 0.4796 - val_fmeasure: 0.4925\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2445 - acc: 0.9281 - top_k_categorical_accuracy: 0.9969 - precision: 0.9362 - recall: 0.9187 - fmeasure: 0.9273 - val_loss: 1.4889 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.7976 - val_recall: 0.7647 - val_fmeasure: 0.7807\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0391 - acc: 0.9893 - top_k_categorical_accuracy: 0.9993 - precision: 0.9916 - recall: 0.9875 - fmeasure: 0.9894 - val_loss: 3.4216 - val_acc: 0.5571 - val_top_k_categorical_accuracy: 0.8543 - val_precision: 0.5746 - val_recall: 0.5510 - val_fmeasure: 0.5624\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2061 - acc: 0.9342 - top_k_categorical_accuracy: 0.9981 - precision: 0.9415 - recall: 0.9264 - fmeasure: 0.9338 - val_loss: 1.4720 - val_acc: 0.7773 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8015 - val_recall: 0.7664 - val_fmeasure: 0.7834\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0438 - acc: 0.9872 - top_k_categorical_accuracy: 0.9993 - precision: 0.9893 - recall: 0.9852 - fmeasure: 0.9872 - val_loss: 4.3228 - val_acc: 0.5055 - val_top_k_categorical_accuracy: 0.8121 - val_precision: 0.5180 - val_recall: 0.4985 - val_fmeasure: 0.5079\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2299 - acc: 0.9286 - top_k_categorical_accuracy: 0.9976 - precision: 0.9390 - recall: 0.9222 - fmeasure: 0.9305 - val_loss: 1.4870 - val_acc: 0.7765 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.7971 - val_recall: 0.7633 - val_fmeasure: 0.7797\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0336 - acc: 0.9902 - top_k_categorical_accuracy: 0.9995 - precision: 0.9918 - recall: 0.9883 - fmeasure: 0.9900 - val_loss: 3.4172 - val_acc: 0.5647 - val_top_k_categorical_accuracy: 0.8627 - val_precision: 0.5807 - val_recall: 0.5574 - val_fmeasure: 0.5688\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2075 - acc: 0.9366 - top_k_categorical_accuracy: 0.9980 - precision: 0.9432 - recall: 0.9304 - fmeasure: 0.9367 - val_loss: 1.5185 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9186 - val_precision: 0.7943 - val_recall: 0.7498 - val_fmeasure: 0.7712\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0399 - acc: 0.9884 - top_k_categorical_accuracy: 0.9994 - precision: 0.9906 - recall: 0.9867 - fmeasure: 0.9886 - val_loss: 3.3842 - val_acc: 0.5841 - val_top_k_categorical_accuracy: 0.8537 - val_precision: 0.5965 - val_recall: 0.5757 - val_fmeasure: 0.5858\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2073 - acc: 0.9361 - top_k_categorical_accuracy: 0.9987 - precision: 0.9434 - recall: 0.9297 - fmeasure: 0.9364 - val_loss: 1.5089 - val_acc: 0.7804 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.7999 - val_recall: 0.7694 - val_fmeasure: 0.7843\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0894 - acc: 0.9668 - top_k_categorical_accuracy: 1.0000 - precision: 0.9703 - recall: 0.9642 - fmeasure: 0.9672 - val_loss: 1.5393 - val_acc: 0.7661 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.7880 - val_recall: 0.7574 - val_fmeasure: 0.7723\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0904 - acc: 0.9697 - top_k_categorical_accuracy: 1.0000 - precision: 0.9737 - recall: 0.9675 - fmeasure: 0.9706 - val_loss: 1.6408 - val_acc: 0.7504 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7726 - val_recall: 0.7400 - val_fmeasure: 0.7558\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0929 - acc: 0.9676 - top_k_categorical_accuracy: 0.9998 - precision: 0.9709 - recall: 0.9653 - fmeasure: 0.9681 - val_loss: 1.5036 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7970 - val_recall: 0.7680 - val_fmeasure: 0.7822\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0832 - acc: 0.9707 - top_k_categorical_accuracy: 0.9998 - precision: 0.9741 - recall: 0.9681 - fmeasure: 0.9711 - val_loss: 1.5648 - val_acc: 0.7739 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7935 - val_recall: 0.7650 - val_fmeasure: 0.7789\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0743 - acc: 0.9742 - top_k_categorical_accuracy: 1.0000 - precision: 0.9761 - recall: 0.9723 - fmeasure: 0.9742 - val_loss: 1.5361 - val_acc: 0.7838 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7990 - val_recall: 0.7762 - val_fmeasure: 0.7873\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0807 - acc: 0.9703 - top_k_categorical_accuracy: 0.9999 - precision: 0.9740 - recall: 0.9681 - fmeasure: 0.9710 - val_loss: 1.5517 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7885 - val_recall: 0.7593 - val_fmeasure: 0.7735\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0939 - acc: 0.9681 - top_k_categorical_accuracy: 1.0000 - precision: 0.9712 - recall: 0.9656 - fmeasure: 0.9684 - val_loss: 1.5971 - val_acc: 0.7739 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7925 - val_recall: 0.7658 - val_fmeasure: 0.7788\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0964 - acc: 0.9664 - top_k_categorical_accuracy: 1.0000 - precision: 0.9698 - recall: 0.9629 - fmeasure: 0.9663 - val_loss: 1.5357 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7998 - val_recall: 0.7692 - val_fmeasure: 0.7840\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0828 - acc: 0.9706 - top_k_categorical_accuracy: 1.0000 - precision: 0.9755 - recall: 0.9675 - fmeasure: 0.9714 - val_loss: 1.5978 - val_acc: 0.7661 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7878 - val_recall: 0.7571 - val_fmeasure: 0.7720\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0737 - acc: 0.9750 - top_k_categorical_accuracy: 0.9999 - precision: 0.9771 - recall: 0.9729 - fmeasure: 0.9750 - val_loss: 1.5538 - val_acc: 0.7821 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8004 - val_recall: 0.7765 - val_fmeasure: 0.7881\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0842 - acc: 0.9711 - top_k_categorical_accuracy: 1.0000 - precision: 0.9748 - recall: 0.9692 - fmeasure: 0.9720 - val_loss: 1.6033 - val_acc: 0.7680 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7867 - val_recall: 0.7574 - val_fmeasure: 0.7716\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0857 - acc: 0.9679 - top_k_categorical_accuracy: 0.9999 - precision: 0.9713 - recall: 0.9651 - fmeasure: 0.9681 - val_loss: 1.5822 - val_acc: 0.7762 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.7942 - val_recall: 0.7661 - val_fmeasure: 0.7798\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0740 - acc: 0.9729 - top_k_categorical_accuracy: 0.9999 - precision: 0.9758 - recall: 0.9713 - fmeasure: 0.9736 - val_loss: 1.5751 - val_acc: 0.7824 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.8016 - val_recall: 0.7745 - val_fmeasure: 0.7877\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0761 - acc: 0.9703 - top_k_categorical_accuracy: 0.9999 - precision: 0.9739 - recall: 0.9683 - fmeasure: 0.9711 - val_loss: 1.5622 - val_acc: 0.7666 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7867 - val_recall: 0.7554 - val_fmeasure: 0.7706\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0729 - acc: 0.9720 - top_k_categorical_accuracy: 0.9999 - precision: 0.9747 - recall: 0.9695 - fmeasure: 0.9721 - val_loss: 1.6515 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.7888 - val_recall: 0.7672 - val_fmeasure: 0.7778\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0771 - acc: 0.9729 - top_k_categorical_accuracy: 1.0000 - precision: 0.9757 - recall: 0.9705 - fmeasure: 0.9731 - val_loss: 1.6396 - val_acc: 0.7678 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.7855 - val_recall: 0.7596 - val_fmeasure: 0.7722\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0623 - acc: 0.9787 - top_k_categorical_accuracy: 1.0000 - precision: 0.9800 - recall: 0.9774 - fmeasure: 0.9787 - val_loss: 1.5813 - val_acc: 0.7843 - val_top_k_categorical_accuracy: 0.9284 - val_precision: 0.7995 - val_recall: 0.7784 - val_fmeasure: 0.7888\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0533 - acc: 0.9800 - top_k_categorical_accuracy: 1.0000 - precision: 0.9815 - recall: 0.9789 - fmeasure: 0.9802 - val_loss: 1.6352 - val_acc: 0.7787 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.7927 - val_recall: 0.7692 - val_fmeasure: 0.7806\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0599 - acc: 0.9792 - top_k_categorical_accuracy: 0.9999 - precision: 0.9813 - recall: 0.9779 - fmeasure: 0.9795 - val_loss: 1.6651 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.7892 - val_recall: 0.7661 - val_fmeasure: 0.7774\n",
            "deleting......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 168us/step - loss: 3.6166 - acc: 0.1396 - top_k_categorical_accuracy: 0.3750 - precision: 0.2850 - recall: 0.0136 - fmeasure: 0.0254 - val_loss: 2.9085 - val_acc: 0.2690 - val_top_k_categorical_accuracy: 0.6119 - val_precision: 0.8030 - val_recall: 0.0677 - val_fmeasure: 0.1236\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 2.2169 - acc: 0.4548 - top_k_categorical_accuracy: 0.7547 - precision: 0.7996 - recall: 0.2228 - fmeasure: 0.3388 - val_loss: 2.0640 - val_acc: 0.5274 - val_top_k_categorical_accuracy: 0.7852 - val_precision: 0.7691 - val_recall: 0.3058 - val_fmeasure: 0.4349\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 1.5544 - acc: 0.6267 - top_k_categorical_accuracy: 0.8537 - precision: 0.8273 - recall: 0.4586 - fmeasure: 0.5878 - val_loss: 1.5689 - val_acc: 0.6456 - val_top_k_categorical_accuracy: 0.8602 - val_precision: 0.8084 - val_recall: 0.5195 - val_fmeasure: 0.6312\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 1.2201 - acc: 0.6998 - top_k_categorical_accuracy: 0.8945 - precision: 0.8427 - recall: 0.5788 - fmeasure: 0.6845 - val_loss: 1.5019 - val_acc: 0.6568 - val_top_k_categorical_accuracy: 0.8689 - val_precision: 0.7956 - val_recall: 0.5546 - val_fmeasure: 0.6527\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.9976 - acc: 0.7438 - top_k_categorical_accuracy: 0.9239 - precision: 0.8547 - recall: 0.6570 - fmeasure: 0.7416 - val_loss: 1.2800 - val_acc: 0.7006 - val_top_k_categorical_accuracy: 0.8964 - val_precision: 0.8164 - val_recall: 0.6077 - val_fmeasure: 0.6961\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 123us/step - loss: 0.8293 - acc: 0.7792 - top_k_categorical_accuracy: 0.9452 - precision: 0.8763 - recall: 0.7072 - fmeasure: 0.7819 - val_loss: 1.2857 - val_acc: 0.7091 - val_top_k_categorical_accuracy: 0.8964 - val_precision: 0.8103 - val_recall: 0.6369 - val_fmeasure: 0.7121\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.7209 - acc: 0.8002 - top_k_categorical_accuracy: 0.9573 - precision: 0.8770 - recall: 0.7395 - fmeasure: 0.8017 - val_loss: 1.2595 - val_acc: 0.7108 - val_top_k_categorical_accuracy: 0.9023 - val_precision: 0.8014 - val_recall: 0.6487 - val_fmeasure: 0.7165\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 123us/step - loss: 0.6021 - acc: 0.8262 - top_k_categorical_accuracy: 0.9706 - precision: 0.8935 - recall: 0.7737 - fmeasure: 0.8288 - val_loss: 1.1610 - val_acc: 0.7327 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.8134 - val_recall: 0.6830 - val_fmeasure: 0.7419\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.5401 - acc: 0.8411 - top_k_categorical_accuracy: 0.9781 - precision: 0.8978 - recall: 0.7993 - fmeasure: 0.8454 - val_loss: 1.1154 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8284 - val_recall: 0.7043 - val_fmeasure: 0.7608\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.4741 - acc: 0.8584 - top_k_categorical_accuracy: 0.9836 - precision: 0.9036 - recall: 0.8210 - fmeasure: 0.8600 - val_loss: 1.1783 - val_acc: 0.7453 - val_top_k_categorical_accuracy: 0.9177 - val_precision: 0.8194 - val_recall: 0.7026 - val_fmeasure: 0.7561\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.4307 - acc: 0.8682 - top_k_categorical_accuracy: 0.9877 - precision: 0.9118 - recall: 0.8305 - fmeasure: 0.8688 - val_loss: 1.1591 - val_acc: 0.7554 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.8154 - val_recall: 0.7220 - val_fmeasure: 0.7655\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.3875 - acc: 0.8748 - top_k_categorical_accuracy: 0.9912 - precision: 0.9124 - recall: 0.8453 - fmeasure: 0.8773 - val_loss: 1.2061 - val_acc: 0.7498 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.8115 - val_recall: 0.7102 - val_fmeasure: 0.7571\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3333 - acc: 0.8912 - top_k_categorical_accuracy: 0.9940 - precision: 0.9218 - recall: 0.8625 - fmeasure: 0.8909 - val_loss: 1.2746 - val_acc: 0.7416 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7986 - val_recall: 0.7040 - val_fmeasure: 0.7478\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.3099 - acc: 0.9000 - top_k_categorical_accuracy: 0.9953 - precision: 0.9252 - recall: 0.8771 - fmeasure: 0.9003 - val_loss: 1.2566 - val_acc: 0.7515 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7993 - val_recall: 0.7228 - val_fmeasure: 0.7588\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2944 - acc: 0.9062 - top_k_categorical_accuracy: 0.9963 - precision: 0.9271 - recall: 0.8841 - fmeasure: 0.9049 - val_loss: 1.1953 - val_acc: 0.7627 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.8176 - val_recall: 0.7304 - val_fmeasure: 0.7712\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2449 - acc: 0.9202 - top_k_categorical_accuracy: 0.9982 - precision: 0.9381 - recall: 0.9041 - fmeasure: 0.9206 - val_loss: 1.2973 - val_acc: 0.7453 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7899 - val_recall: 0.7189 - val_fmeasure: 0.7524\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2681 - acc: 0.9097 - top_k_categorical_accuracy: 0.9978 - precision: 0.9292 - recall: 0.8896 - fmeasure: 0.9088 - val_loss: 1.2676 - val_acc: 0.7672 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.8092 - val_recall: 0.7360 - val_fmeasure: 0.7706\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2203 - acc: 0.9273 - top_k_categorical_accuracy: 0.9987 - precision: 0.9438 - recall: 0.9127 - fmeasure: 0.9279 - val_loss: 1.3265 - val_acc: 0.7445 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.7888 - val_recall: 0.7169 - val_fmeasure: 0.7510\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2225 - acc: 0.9240 - top_k_categorical_accuracy: 0.9987 - precision: 0.9399 - recall: 0.9080 - fmeasure: 0.9235 - val_loss: 1.3154 - val_acc: 0.7562 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7940 - val_recall: 0.7318 - val_fmeasure: 0.7614\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1847 - acc: 0.9345 - top_k_categorical_accuracy: 0.9989 - precision: 0.9463 - recall: 0.9234 - fmeasure: 0.9347 - val_loss: 1.3168 - val_acc: 0.7658 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7967 - val_recall: 0.7526 - val_fmeasure: 0.7738\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2139 - acc: 0.9301 - top_k_categorical_accuracy: 0.9982 - precision: 0.9430 - recall: 0.9198 - fmeasure: 0.9312 - val_loss: 1.4642 - val_acc: 0.7338 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.7746 - val_recall: 0.7116 - val_fmeasure: 0.7415\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 1.9826 - acc: 0.5280 - top_k_categorical_accuracy: 0.7815 - precision: 0.7425 - recall: 0.3503 - fmeasure: 0.4525 - val_loss: 5.9738 - val_acc: 0.0761 - val_top_k_categorical_accuracy: 0.2575 - val_precision: 0.1081 - val_recall: 0.0500 - val_fmeasure: 0.0681\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.7144 - acc: 0.8098 - top_k_categorical_accuracy: 0.9429 - precision: 0.8725 - recall: 0.7560 - fmeasure: 0.8006 - val_loss: 1.2483 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8049 - val_recall: 0.7338 - val_fmeasure: 0.7674\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 1.0924 - acc: 0.7176 - top_k_categorical_accuracy: 0.9147 - precision: 0.8267 - recall: 0.6148 - fmeasure: 0.6993 - val_loss: 5.6464 - val_acc: 0.0885 - val_top_k_categorical_accuracy: 0.3533 - val_precision: 0.1067 - val_recall: 0.0570 - val_fmeasure: 0.0741\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.6826 - acc: 0.8175 - top_k_categorical_accuracy: 0.9540 - precision: 0.8725 - recall: 0.7673 - fmeasure: 0.8111 - val_loss: 1.1974 - val_acc: 0.7762 - val_top_k_categorical_accuracy: 0.9228 - val_precision: 0.8153 - val_recall: 0.7582 - val_fmeasure: 0.7855\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.7883 - acc: 0.7855 - top_k_categorical_accuracy: 0.9517 - precision: 0.8608 - recall: 0.7156 - fmeasure: 0.7781 - val_loss: 5.3431 - val_acc: 0.1230 - val_top_k_categorical_accuracy: 0.4061 - val_precision: 0.1474 - val_recall: 0.0915 - val_fmeasure: 0.1127\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.6342 - acc: 0.8206 - top_k_categorical_accuracy: 0.9602 - precision: 0.8759 - recall: 0.7774 - fmeasure: 0.8208 - val_loss: 1.2237 - val_acc: 0.7661 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.8045 - val_recall: 0.7394 - val_fmeasure: 0.7703\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.6228 - acc: 0.8200 - top_k_categorical_accuracy: 0.9696 - precision: 0.8799 - recall: 0.7656 - fmeasure: 0.8165 - val_loss: 4.9620 - val_acc: 0.1533 - val_top_k_categorical_accuracy: 0.4726 - val_precision: 0.1842 - val_recall: 0.1160 - val_fmeasure: 0.1421\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.5582 - acc: 0.8388 - top_k_categorical_accuracy: 0.9704 - precision: 0.8854 - recall: 0.8014 - fmeasure: 0.8393 - val_loss: 1.2353 - val_acc: 0.7706 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8115 - val_recall: 0.7475 - val_fmeasure: 0.7779\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.5210 - acc: 0.8460 - top_k_categorical_accuracy: 0.9783 - precision: 0.8921 - recall: 0.8044 - fmeasure: 0.8443 - val_loss: 4.8755 - val_acc: 0.1752 - val_top_k_categorical_accuracy: 0.5538 - val_precision: 0.2045 - val_recall: 0.1441 - val_fmeasure: 0.1688\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.5103 - acc: 0.8516 - top_k_categorical_accuracy: 0.9760 - precision: 0.8893 - recall: 0.8187 - fmeasure: 0.8513 - val_loss: 1.2069 - val_acc: 0.7650 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.8101 - val_recall: 0.7414 - val_fmeasure: 0.7739\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 103us/step - loss: 0.4368 - acc: 0.8691 - top_k_categorical_accuracy: 0.9846 - precision: 0.9055 - recall: 0.8356 - fmeasure: 0.8678 - val_loss: 4.9303 - val_acc: 0.1910 - val_top_k_categorical_accuracy: 0.5423 - val_precision: 0.2133 - val_recall: 0.1452 - val_fmeasure: 0.1724\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 0.5140 - acc: 0.8486 - top_k_categorical_accuracy: 0.9752 - precision: 0.8863 - recall: 0.8177 - fmeasure: 0.8493 - val_loss: 1.2590 - val_acc: 0.7619 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8001 - val_recall: 0.7391 - val_fmeasure: 0.7682\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 106us/step - loss: 0.3983 - acc: 0.8795 - top_k_categorical_accuracy: 0.9872 - precision: 0.9116 - recall: 0.8459 - fmeasure: 0.8761 - val_loss: 4.4850 - val_acc: 0.2275 - val_top_k_categorical_accuracy: 0.5948 - val_precision: 0.2666 - val_recall: 0.1853 - val_fmeasure: 0.2183\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.4580 - acc: 0.8670 - top_k_categorical_accuracy: 0.9815 - precision: 0.8947 - recall: 0.8388 - fmeasure: 0.8649 - val_loss: 1.2210 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.8102 - val_recall: 0.7551 - val_fmeasure: 0.7814\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 107us/step - loss: 0.3393 - acc: 0.8923 - top_k_categorical_accuracy: 0.9906 - precision: 0.9192 - recall: 0.8656 - fmeasure: 0.8907 - val_loss: 4.1025 - val_acc: 0.2772 - val_top_k_categorical_accuracy: 0.6602 - val_precision: 0.3224 - val_recall: 0.2325 - val_fmeasure: 0.2697\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.3978 - acc: 0.8824 - top_k_categorical_accuracy: 0.9865 - precision: 0.9070 - recall: 0.8565 - fmeasure: 0.8804 - val_loss: 1.2564 - val_acc: 0.7773 - val_top_k_categorical_accuracy: 0.9273 - val_precision: 0.8105 - val_recall: 0.7596 - val_fmeasure: 0.7841\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 103us/step - loss: 0.3071 - acc: 0.9025 - top_k_categorical_accuracy: 0.9920 - precision: 0.9256 - recall: 0.8794 - fmeasure: 0.9011 - val_loss: 4.2474 - val_acc: 0.2932 - val_top_k_categorical_accuracy: 0.6627 - val_precision: 0.3252 - val_recall: 0.2432 - val_fmeasure: 0.2780\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.3855 - acc: 0.8811 - top_k_categorical_accuracy: 0.9888 - precision: 0.9045 - recall: 0.8587 - fmeasure: 0.8804 - val_loss: 1.2366 - val_acc: 0.7753 - val_top_k_categorical_accuracy: 0.9219 - val_precision: 0.8179 - val_recall: 0.7537 - val_fmeasure: 0.7842\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.2736 - acc: 0.9116 - top_k_categorical_accuracy: 0.9942 - precision: 0.9329 - recall: 0.8931 - fmeasure: 0.9119 - val_loss: 3.7931 - val_acc: 0.3378 - val_top_k_categorical_accuracy: 0.7113 - val_precision: 0.3795 - val_recall: 0.2963 - val_fmeasure: 0.3325\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.3586 - acc: 0.8890 - top_k_categorical_accuracy: 0.9884 - precision: 0.9146 - recall: 0.8691 - fmeasure: 0.8908 - val_loss: 1.2914 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.8050 - val_recall: 0.7520 - val_fmeasure: 0.7774\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.2589 - acc: 0.9177 - top_k_categorical_accuracy: 0.9941 - precision: 0.9346 - recall: 0.8999 - fmeasure: 0.9163 - val_loss: 4.0393 - val_acc: 0.3392 - val_top_k_categorical_accuracy: 0.7040 - val_precision: 0.3728 - val_recall: 0.2991 - val_fmeasure: 0.3315\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.3615 - acc: 0.8882 - top_k_categorical_accuracy: 0.9890 - precision: 0.9125 - recall: 0.8710 - fmeasure: 0.8908 - val_loss: 1.3139 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.8070 - val_recall: 0.7635 - val_fmeasure: 0.7844\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.2333 - acc: 0.9262 - top_k_categorical_accuracy: 0.9950 - precision: 0.9423 - recall: 0.9099 - fmeasure: 0.9253 - val_loss: 3.7342 - val_acc: 0.3875 - val_top_k_categorical_accuracy: 0.7248 - val_precision: 0.4294 - val_recall: 0.3477 - val_fmeasure: 0.3839\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3136 - acc: 0.9063 - top_k_categorical_accuracy: 0.9907 - precision: 0.9263 - recall: 0.8885 - fmeasure: 0.9066 - val_loss: 1.4626 - val_acc: 0.7551 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.7812 - val_recall: 0.7416 - val_fmeasure: 0.7608\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.2146 - acc: 0.9293 - top_k_categorical_accuracy: 0.9955 - precision: 0.9444 - recall: 0.9154 - fmeasure: 0.9292 - val_loss: 4.2387 - val_acc: 0.3201 - val_top_k_categorical_accuracy: 0.6970 - val_precision: 0.3603 - val_recall: 0.2890 - val_fmeasure: 0.3203\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3114 - acc: 0.9032 - top_k_categorical_accuracy: 0.9923 - precision: 0.9203 - recall: 0.8876 - fmeasure: 0.9033 - val_loss: 1.3610 - val_acc: 0.7756 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8029 - val_recall: 0.7652 - val_fmeasure: 0.7834\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2067 - acc: 0.9311 - top_k_categorical_accuracy: 0.9957 - precision: 0.9455 - recall: 0.9197 - fmeasure: 0.9320 - val_loss: 3.5339 - val_acc: 0.4153 - val_top_k_categorical_accuracy: 0.7546 - val_precision: 0.4580 - val_recall: 0.3797 - val_fmeasure: 0.4149\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2809 - acc: 0.9114 - top_k_categorical_accuracy: 0.9939 - precision: 0.9272 - recall: 0.8961 - fmeasure: 0.9111 - val_loss: 1.3788 - val_acc: 0.7829 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.8099 - val_recall: 0.7686 - val_fmeasure: 0.7886\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1898 - acc: 0.9378 - top_k_categorical_accuracy: 0.9969 - precision: 0.9498 - recall: 0.9269 - fmeasure: 0.9379 - val_loss: 3.6025 - val_acc: 0.4080 - val_top_k_categorical_accuracy: 0.7627 - val_precision: 0.4461 - val_recall: 0.3816 - val_fmeasure: 0.4111\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2824 - acc: 0.9110 - top_k_categorical_accuracy: 0.9937 - precision: 0.9279 - recall: 0.8985 - fmeasure: 0.9127 - val_loss: 1.3849 - val_acc: 0.7773 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8083 - val_recall: 0.7619 - val_fmeasure: 0.7843\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1830 - acc: 0.9388 - top_k_categorical_accuracy: 0.9969 - precision: 0.9519 - recall: 0.9283 - fmeasure: 0.9396 - val_loss: 3.4139 - val_acc: 0.4358 - val_top_k_categorical_accuracy: 0.7846 - val_precision: 0.4715 - val_recall: 0.4044 - val_fmeasure: 0.4351\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2640 - acc: 0.9143 - top_k_categorical_accuracy: 0.9952 - precision: 0.9282 - recall: 0.9015 - fmeasure: 0.9144 - val_loss: 1.4104 - val_acc: 0.7790 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.8077 - val_recall: 0.7652 - val_fmeasure: 0.7857\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1752 - acc: 0.9427 - top_k_categorical_accuracy: 0.9974 - precision: 0.9535 - recall: 0.9325 - fmeasure: 0.9426 - val_loss: 3.5299 - val_acc: 0.4325 - val_top_k_categorical_accuracy: 0.7652 - val_precision: 0.4698 - val_recall: 0.3996 - val_fmeasure: 0.4316\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2700 - acc: 0.9160 - top_k_categorical_accuracy: 0.9946 - precision: 0.9305 - recall: 0.9045 - fmeasure: 0.9171 - val_loss: 1.4344 - val_acc: 0.7720 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8008 - val_recall: 0.7610 - val_fmeasure: 0.7802\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1629 - acc: 0.9468 - top_k_categorical_accuracy: 0.9968 - precision: 0.9567 - recall: 0.9377 - fmeasure: 0.9469 - val_loss: 3.7896 - val_acc: 0.4007 - val_top_k_categorical_accuracy: 0.7518 - val_precision: 0.4375 - val_recall: 0.3693 - val_fmeasure: 0.4002\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2699 - acc: 0.9218 - top_k_categorical_accuracy: 0.9924 - precision: 0.9341 - recall: 0.9116 - fmeasure: 0.9225 - val_loss: 1.3590 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8042 - val_recall: 0.7666 - val_fmeasure: 0.7848\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1514 - acc: 0.9505 - top_k_categorical_accuracy: 0.9974 - precision: 0.9605 - recall: 0.9419 - fmeasure: 0.9509 - val_loss: 3.7828 - val_acc: 0.4165 - val_top_k_categorical_accuracy: 0.7489 - val_precision: 0.4491 - val_recall: 0.3858 - val_fmeasure: 0.4148\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.2346 - acc: 0.9246 - top_k_categorical_accuracy: 0.9957 - precision: 0.9364 - recall: 0.9150 - fmeasure: 0.9254 - val_loss: 1.4187 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.8008 - val_recall: 0.7638 - val_fmeasure: 0.7817\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1467 - acc: 0.9492 - top_k_categorical_accuracy: 0.9982 - precision: 0.9578 - recall: 0.9412 - fmeasure: 0.9492 - val_loss: 3.3413 - val_acc: 0.4642 - val_top_k_categorical_accuracy: 0.7885 - val_precision: 0.4985 - val_recall: 0.4291 - val_fmeasure: 0.4610\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.2617 - acc: 0.9161 - top_k_categorical_accuracy: 0.9965 - precision: 0.9295 - recall: 0.9042 - fmeasure: 0.9165 - val_loss: 1.5013 - val_acc: 0.7697 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7917 - val_recall: 0.7591 - val_fmeasure: 0.7749\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1413 - acc: 0.9528 - top_k_categorical_accuracy: 0.9982 - precision: 0.9613 - recall: 0.9450 - fmeasure: 0.9529 - val_loss: 3.3768 - val_acc: 0.4813 - val_top_k_categorical_accuracy: 0.7869 - val_precision: 0.5211 - val_recall: 0.4555 - val_fmeasure: 0.4859\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2288 - acc: 0.9280 - top_k_categorical_accuracy: 0.9964 - precision: 0.9388 - recall: 0.9196 - fmeasure: 0.9289 - val_loss: 1.4882 - val_acc: 0.7770 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7999 - val_recall: 0.7686 - val_fmeasure: 0.7838\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.1282 - acc: 0.9574 - top_k_categorical_accuracy: 0.9986 - precision: 0.9654 - recall: 0.9506 - fmeasure: 0.9578 - val_loss: 2.9088 - val_acc: 0.5274 - val_top_k_categorical_accuracy: 0.8183 - val_precision: 0.5699 - val_recall: 0.4979 - val_fmeasure: 0.5311\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.2075 - acc: 0.9320 - top_k_categorical_accuracy: 0.9976 - precision: 0.9422 - recall: 0.9242 - fmeasure: 0.9330 - val_loss: 1.5001 - val_acc: 0.7770 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7968 - val_recall: 0.7678 - val_fmeasure: 0.7819\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 106us/step - loss: 0.1282 - acc: 0.9571 - top_k_categorical_accuracy: 0.9984 - precision: 0.9638 - recall: 0.9514 - fmeasure: 0.9575 - val_loss: 3.1569 - val_acc: 0.5063 - val_top_k_categorical_accuracy: 0.8149 - val_precision: 0.5445 - val_recall: 0.4794 - val_fmeasure: 0.5097\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.2059 - acc: 0.9315 - top_k_categorical_accuracy: 0.9976 - precision: 0.9401 - recall: 0.9240 - fmeasure: 0.9319 - val_loss: 1.5182 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7871 - val_recall: 0.7509 - val_fmeasure: 0.7685\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1144 - acc: 0.9611 - top_k_categorical_accuracy: 0.9986 - precision: 0.9689 - recall: 0.9562 - fmeasure: 0.9624 - val_loss: 3.4826 - val_acc: 0.4746 - val_top_k_categorical_accuracy: 0.7972 - val_precision: 0.5073 - val_recall: 0.4504 - val_fmeasure: 0.4769\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1882 - acc: 0.9396 - top_k_categorical_accuracy: 0.9970 - precision: 0.9464 - recall: 0.9333 - fmeasure: 0.9397 - val_loss: 1.4935 - val_acc: 0.7790 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.8023 - val_recall: 0.7678 - val_fmeasure: 0.7846\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1157 - acc: 0.9605 - top_k_categorical_accuracy: 0.9989 - precision: 0.9670 - recall: 0.9540 - fmeasure: 0.9604 - val_loss: 3.1836 - val_acc: 0.5049 - val_top_k_categorical_accuracy: 0.8208 - val_precision: 0.5395 - val_recall: 0.4774 - val_fmeasure: 0.5064\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2046 - acc: 0.9357 - top_k_categorical_accuracy: 0.9977 - precision: 0.9452 - recall: 0.9281 - fmeasure: 0.9365 - val_loss: 1.5782 - val_acc: 0.7633 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.7857 - val_recall: 0.7579 - val_fmeasure: 0.7715\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1055 - acc: 0.9645 - top_k_categorical_accuracy: 0.9989 - precision: 0.9699 - recall: 0.9592 - fmeasure: 0.9645 - val_loss: 3.1851 - val_acc: 0.5015 - val_top_k_categorical_accuracy: 0.8068 - val_precision: 0.5344 - val_recall: 0.4782 - val_fmeasure: 0.5046\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2051 - acc: 0.9348 - top_k_categorical_accuracy: 0.9978 - precision: 0.9431 - recall: 0.9278 - fmeasure: 0.9353 - val_loss: 1.5318 - val_acc: 0.7686 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7936 - val_recall: 0.7585 - val_fmeasure: 0.7756\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.1057 - acc: 0.9641 - top_k_categorical_accuracy: 0.9992 - precision: 0.9701 - recall: 0.9588 - fmeasure: 0.9644 - val_loss: 2.7390 - val_acc: 0.5706 - val_top_k_categorical_accuracy: 0.8388 - val_precision: 0.6132 - val_recall: 0.5487 - val_fmeasure: 0.5789\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1655 - acc: 0.9464 - top_k_categorical_accuracy: 0.9987 - precision: 0.9528 - recall: 0.9409 - fmeasure: 0.9467 - val_loss: 1.6043 - val_acc: 0.7610 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.7820 - val_recall: 0.7554 - val_fmeasure: 0.7684\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1009 - acc: 0.9662 - top_k_categorical_accuracy: 0.9993 - precision: 0.9713 - recall: 0.9620 - fmeasure: 0.9665 - val_loss: 3.2277 - val_acc: 0.5161 - val_top_k_categorical_accuracy: 0.8071 - val_precision: 0.5520 - val_recall: 0.4968 - val_fmeasure: 0.5226\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1845 - acc: 0.9417 - top_k_categorical_accuracy: 0.9984 - precision: 0.9488 - recall: 0.9376 - fmeasure: 0.9431 - val_loss: 1.5453 - val_acc: 0.7647 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7887 - val_recall: 0.7557 - val_fmeasure: 0.7717\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.0903 - acc: 0.9695 - top_k_categorical_accuracy: 0.9992 - precision: 0.9742 - recall: 0.9655 - fmeasure: 0.9697 - val_loss: 2.8159 - val_acc: 0.5712 - val_top_k_categorical_accuracy: 0.8340 - val_precision: 0.6062 - val_recall: 0.5535 - val_fmeasure: 0.5785\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1665 - acc: 0.9446 - top_k_categorical_accuracy: 0.9987 - precision: 0.9527 - recall: 0.9382 - fmeasure: 0.9453 - val_loss: 1.5812 - val_acc: 0.7650 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.7874 - val_recall: 0.7565 - val_fmeasure: 0.7716\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.0985 - acc: 0.9669 - top_k_categorical_accuracy: 0.9992 - precision: 0.9711 - recall: 0.9629 - fmeasure: 0.9669 - val_loss: 2.9891 - val_acc: 0.5563 - val_top_k_categorical_accuracy: 0.8312 - val_precision: 0.5809 - val_recall: 0.5352 - val_fmeasure: 0.5570\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.1649 - acc: 0.9437 - top_k_categorical_accuracy: 0.9988 - precision: 0.9510 - recall: 0.9384 - fmeasure: 0.9446 - val_loss: 1.5912 - val_acc: 0.7582 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7789 - val_recall: 0.7481 - val_fmeasure: 0.7631\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0945 - acc: 0.9638 - top_k_categorical_accuracy: 1.0000 - precision: 0.9680 - recall: 0.9614 - fmeasure: 0.9646 - val_loss: 1.5512 - val_acc: 0.7655 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7894 - val_recall: 0.7523 - val_fmeasure: 0.7702\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0887 - acc: 0.9683 - top_k_categorical_accuracy: 0.9996 - precision: 0.9719 - recall: 0.9661 - fmeasure: 0.9690 - val_loss: 1.5448 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.7986 - val_recall: 0.7697 - val_fmeasure: 0.7838\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0872 - acc: 0.9686 - top_k_categorical_accuracy: 1.0000 - precision: 0.9715 - recall: 0.9651 - fmeasure: 0.9683 - val_loss: 1.6239 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7873 - val_recall: 0.7591 - val_fmeasure: 0.7728\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0874 - acc: 0.9682 - top_k_categorical_accuracy: 1.0000 - precision: 0.9718 - recall: 0.9651 - fmeasure: 0.9684 - val_loss: 1.6333 - val_acc: 0.7650 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.7859 - val_recall: 0.7560 - val_fmeasure: 0.7706\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0866 - acc: 0.9680 - top_k_categorical_accuracy: 1.0000 - precision: 0.9708 - recall: 0.9647 - fmeasure: 0.9677 - val_loss: 1.6532 - val_acc: 0.7745 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.7886 - val_recall: 0.7672 - val_fmeasure: 0.7777\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0929 - acc: 0.9689 - top_k_categorical_accuracy: 0.9999 - precision: 0.9719 - recall: 0.9663 - fmeasure: 0.9691 - val_loss: 1.6498 - val_acc: 0.7697 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7847 - val_recall: 0.7605 - val_fmeasure: 0.7723\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.0705 - acc: 0.9751 - top_k_categorical_accuracy: 1.0000 - precision: 0.9782 - recall: 0.9727 - fmeasure: 0.9754 - val_loss: 1.6179 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.7972 - val_recall: 0.7694 - val_fmeasure: 0.7830\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.0631 - acc: 0.9774 - top_k_categorical_accuracy: 0.9999 - precision: 0.9799 - recall: 0.9747 - fmeasure: 0.9773 - val_loss: 1.7104 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.7877 - val_recall: 0.7638 - val_fmeasure: 0.7755\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.0831 - acc: 0.9727 - top_k_categorical_accuracy: 1.0000 - precision: 0.9754 - recall: 0.9703 - fmeasure: 0.9728 - val_loss: 1.6435 - val_acc: 0.7773 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7935 - val_recall: 0.7723 - val_fmeasure: 0.7827\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 0.0565 - acc: 0.9792 - top_k_categorical_accuracy: 1.0000 - precision: 0.9810 - recall: 0.9781 - fmeasure: 0.9796 - val_loss: 1.5901 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7890 - val_recall: 0.7596 - val_fmeasure: 0.7739\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 118us/step - loss: 0.0604 - acc: 0.9781 - top_k_categorical_accuracy: 0.9999 - precision: 0.9798 - recall: 0.9762 - fmeasure: 0.9780 - val_loss: 1.6233 - val_acc: 0.7756 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7904 - val_recall: 0.7706 - val_fmeasure: 0.7803\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 118us/step - loss: 0.0753 - acc: 0.9734 - top_k_categorical_accuracy: 0.9999 - precision: 0.9759 - recall: 0.9713 - fmeasure: 0.9736 - val_loss: 1.6683 - val_acc: 0.7548 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.7740 - val_recall: 0.7464 - val_fmeasure: 0.7598\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0703 - acc: 0.9745 - top_k_categorical_accuracy: 1.0000 - precision: 0.9773 - recall: 0.9729 - fmeasure: 0.9751 - val_loss: 1.7270 - val_acc: 0.7635 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.7792 - val_recall: 0.7596 - val_fmeasure: 0.7692\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0602 - acc: 0.9788 - top_k_categorical_accuracy: 1.0000 - precision: 0.9809 - recall: 0.9765 - fmeasure: 0.9787 - val_loss: 1.6637 - val_acc: 0.7737 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.7892 - val_recall: 0.7683 - val_fmeasure: 0.7786\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0728 - acc: 0.9759 - top_k_categorical_accuracy: 0.9999 - precision: 0.9786 - recall: 0.9740 - fmeasure: 0.9763 - val_loss: 1.7074 - val_acc: 0.7666 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7808 - val_recall: 0.7619 - val_fmeasure: 0.7711\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0557 - acc: 0.9803 - top_k_categorical_accuracy: 0.9999 - precision: 0.9821 - recall: 0.9788 - fmeasure: 0.9804 - val_loss: 1.6367 - val_acc: 0.7739 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7900 - val_recall: 0.7678 - val_fmeasure: 0.7786\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0550 - acc: 0.9821 - top_k_categorical_accuracy: 1.0000 - precision: 0.9842 - recall: 0.9806 - fmeasure: 0.9824 - val_loss: 1.6375 - val_acc: 0.7734 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.7900 - val_recall: 0.7650 - val_fmeasure: 0.7772\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0451 - acc: 0.9837 - top_k_categorical_accuracy: 1.0000 - precision: 0.9863 - recall: 0.9828 - fmeasure: 0.9845 - val_loss: 1.7736 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.7864 - val_recall: 0.7644 - val_fmeasure: 0.7751\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0545 - acc: 0.9793 - top_k_categorical_accuracy: 1.0000 - precision: 0.9820 - recall: 0.9780 - fmeasure: 0.9800 - val_loss: 1.6786 - val_acc: 0.7728 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7916 - val_recall: 0.7661 - val_fmeasure: 0.7785\n",
            "shuffling......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 167us/step - loss: 3.6283 - acc: 0.1325 - top_k_categorical_accuracy: 0.3690 - precision: 0.1797 - recall: 0.0105 - fmeasure: 0.0193 - val_loss: 2.8711 - val_acc: 0.2752 - val_top_k_categorical_accuracy: 0.6215 - val_precision: 0.7899 - val_recall: 0.0652 - val_fmeasure: 0.1193\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 2.2682 - acc: 0.4352 - top_k_categorical_accuracy: 0.7485 - precision: 0.7776 - recall: 0.2024 - fmeasure: 0.3096 - val_loss: 2.0031 - val_acc: 0.5178 - val_top_k_categorical_accuracy: 0.8023 - val_precision: 0.7704 - val_recall: 0.3235 - val_fmeasure: 0.4544\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 107us/step - loss: 1.5743 - acc: 0.6182 - top_k_categorical_accuracy: 0.8482 - precision: 0.8113 - recall: 0.4513 - fmeasure: 0.5773 - val_loss: 1.6301 - val_acc: 0.6391 - val_top_k_categorical_accuracy: 0.8500 - val_precision: 0.8280 - val_recall: 0.4516 - val_fmeasure: 0.5829\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 1.2113 - acc: 0.7017 - top_k_categorical_accuracy: 0.8932 - precision: 0.8456 - recall: 0.5819 - fmeasure: 0.6881 - val_loss: 1.3727 - val_acc: 0.6911 - val_top_k_categorical_accuracy: 0.8745 - val_precision: 0.8313 - val_recall: 0.5821 - val_fmeasure: 0.6835\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.9616 - acc: 0.7541 - top_k_categorical_accuracy: 0.9301 - precision: 0.8648 - recall: 0.6715 - fmeasure: 0.7551 - val_loss: 1.3144 - val_acc: 0.6922 - val_top_k_categorical_accuracy: 0.8877 - val_precision: 0.8179 - val_recall: 0.6054 - val_fmeasure: 0.6949\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.8291 - acc: 0.7771 - top_k_categorical_accuracy: 0.9461 - precision: 0.8664 - recall: 0.7027 - fmeasure: 0.7752 - val_loss: 1.2258 - val_acc: 0.7200 - val_top_k_categorical_accuracy: 0.9026 - val_precision: 0.8175 - val_recall: 0.6434 - val_fmeasure: 0.7194\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.7111 - acc: 0.8065 - top_k_categorical_accuracy: 0.9599 - precision: 0.8819 - recall: 0.7419 - fmeasure: 0.8052 - val_loss: 1.2073 - val_acc: 0.7284 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.8221 - val_recall: 0.6608 - val_fmeasure: 0.7318\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.6246 - acc: 0.8240 - top_k_categorical_accuracy: 0.9679 - precision: 0.8860 - recall: 0.7726 - fmeasure: 0.8249 - val_loss: 1.2436 - val_acc: 0.7231 - val_top_k_categorical_accuracy: 0.9056 - val_precision: 0.8036 - val_recall: 0.6658 - val_fmeasure: 0.7279\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.5223 - acc: 0.8477 - top_k_categorical_accuracy: 0.9783 - precision: 0.8983 - recall: 0.8041 - fmeasure: 0.8482 - val_loss: 1.2433 - val_acc: 0.7099 - val_top_k_categorical_accuracy: 0.9065 - val_precision: 0.7976 - val_recall: 0.6422 - val_fmeasure: 0.7108\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.4750 - acc: 0.8543 - top_k_categorical_accuracy: 0.9829 - precision: 0.9007 - recall: 0.8174 - fmeasure: 0.8565 - val_loss: 1.2416 - val_acc: 0.7310 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7960 - val_recall: 0.6818 - val_fmeasure: 0.7342\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.4157 - acc: 0.8718 - top_k_categorical_accuracy: 0.9884 - precision: 0.9101 - recall: 0.8387 - fmeasure: 0.8726 - val_loss: 1.1636 - val_acc: 0.7495 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.8119 - val_recall: 0.7035 - val_fmeasure: 0.7535\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3592 - acc: 0.8856 - top_k_categorical_accuracy: 0.9917 - precision: 0.9193 - recall: 0.8547 - fmeasure: 0.8855 - val_loss: 1.2423 - val_acc: 0.7453 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7991 - val_recall: 0.7102 - val_fmeasure: 0.7517\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3507 - acc: 0.8854 - top_k_categorical_accuracy: 0.9935 - precision: 0.9168 - recall: 0.8601 - fmeasure: 0.8873 - val_loss: 1.2182 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.8036 - val_recall: 0.7192 - val_fmeasure: 0.7586\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3273 - acc: 0.8964 - top_k_categorical_accuracy: 0.9951 - precision: 0.9241 - recall: 0.8722 - fmeasure: 0.8971 - val_loss: 1.2323 - val_acc: 0.7445 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8029 - val_recall: 0.7144 - val_fmeasure: 0.7559\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2555 - acc: 0.9153 - top_k_categorical_accuracy: 0.9966 - precision: 0.9359 - recall: 0.8978 - fmeasure: 0.9163 - val_loss: 1.3037 - val_acc: 0.7366 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7814 - val_recall: 0.7130 - val_fmeasure: 0.7454\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2470 - acc: 0.9197 - top_k_categorical_accuracy: 0.9978 - precision: 0.9367 - recall: 0.9047 - fmeasure: 0.9202 - val_loss: 1.2749 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.8075 - val_recall: 0.7416 - val_fmeasure: 0.7729\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2591 - acc: 0.9166 - top_k_categorical_accuracy: 0.9986 - precision: 0.9346 - recall: 0.9002 - fmeasure: 0.9169 - val_loss: 1.3233 - val_acc: 0.7481 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.7943 - val_recall: 0.7284 - val_fmeasure: 0.7597\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2241 - acc: 0.9252 - top_k_categorical_accuracy: 0.9989 - precision: 0.9405 - recall: 0.9083 - fmeasure: 0.9239 - val_loss: 1.3027 - val_acc: 0.7574 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.8006 - val_recall: 0.7315 - val_fmeasure: 0.7642\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2232 - acc: 0.9260 - top_k_categorical_accuracy: 0.9989 - precision: 0.9420 - recall: 0.9109 - fmeasure: 0.9261 - val_loss: 1.3115 - val_acc: 0.7557 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.7915 - val_recall: 0.7360 - val_fmeasure: 0.7626\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2122 - acc: 0.9283 - top_k_categorical_accuracy: 0.9987 - precision: 0.9414 - recall: 0.9168 - fmeasure: 0.9289 - val_loss: 1.3275 - val_acc: 0.7408 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7891 - val_recall: 0.7167 - val_fmeasure: 0.7509\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1803 - acc: 0.9374 - top_k_categorical_accuracy: 0.9995 - precision: 0.9483 - recall: 0.9283 - fmeasure: 0.9381 - val_loss: 1.3037 - val_acc: 0.7664 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7996 - val_recall: 0.7459 - val_fmeasure: 0.7715\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 1.2104 - acc: 0.6710 - top_k_categorical_accuracy: 0.8994 - precision: 0.8139 - recall: 0.5775 - fmeasure: 0.6742 - val_loss: 1.2702 - val_acc: 0.7088 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7719 - val_recall: 0.6647 - val_fmeasure: 0.7138\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2165 - acc: 0.9272 - top_k_categorical_accuracy: 0.9984 - precision: 0.9424 - recall: 0.9102 - fmeasure: 0.9258 - val_loss: 1.1251 - val_acc: 0.7928 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.8313 - val_recall: 0.7739 - val_fmeasure: 0.8014\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.8318 - acc: 0.7562 - top_k_categorical_accuracy: 0.9452 - precision: 0.8543 - recall: 0.6878 - fmeasure: 0.7611 - val_loss: 1.2352 - val_acc: 0.7273 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7998 - val_recall: 0.6917 - val_fmeasure: 0.7413\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1927 - acc: 0.9311 - top_k_categorical_accuracy: 0.9988 - precision: 0.9473 - recall: 0.9175 - fmeasure: 0.9320 - val_loss: 1.1422 - val_acc: 0.7857 - val_top_k_categorical_accuracy: 0.9326 - val_precision: 0.8225 - val_recall: 0.7714 - val_fmeasure: 0.7959\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.6560 - acc: 0.8011 - top_k_categorical_accuracy: 0.9636 - precision: 0.8737 - recall: 0.7474 - fmeasure: 0.8051 - val_loss: 1.2258 - val_acc: 0.7315 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7884 - val_recall: 0.6976 - val_fmeasure: 0.7399\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1916 - acc: 0.9333 - top_k_categorical_accuracy: 0.9993 - precision: 0.9458 - recall: 0.9210 - fmeasure: 0.9331 - val_loss: 1.1936 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9301 - val_precision: 0.8195 - val_recall: 0.7585 - val_fmeasure: 0.7876\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.5212 - acc: 0.8380 - top_k_categorical_accuracy: 0.9756 - precision: 0.8941 - recall: 0.7966 - fmeasure: 0.8421 - val_loss: 1.5971 - val_acc: 0.6849 - val_top_k_categorical_accuracy: 0.8933 - val_precision: 0.7465 - val_recall: 0.6571 - val_fmeasure: 0.6987\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.1708 - acc: 0.9396 - top_k_categorical_accuracy: 0.9989 - precision: 0.9499 - recall: 0.9280 - fmeasure: 0.9387 - val_loss: 1.2148 - val_acc: 0.7793 - val_top_k_categorical_accuracy: 0.9281 - val_precision: 0.8150 - val_recall: 0.7635 - val_fmeasure: 0.7882\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.4243 - acc: 0.8655 - top_k_categorical_accuracy: 0.9839 - precision: 0.9091 - recall: 0.8317 - fmeasure: 0.8684 - val_loss: 1.3104 - val_acc: 0.7540 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.7897 - val_recall: 0.7310 - val_fmeasure: 0.7589\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.1403 - acc: 0.9473 - top_k_categorical_accuracy: 0.9999 - precision: 0.9556 - recall: 0.9399 - fmeasure: 0.9476 - val_loss: 1.3691 - val_acc: 0.7697 - val_top_k_categorical_accuracy: 0.9275 - val_precision: 0.7967 - val_recall: 0.7577 - val_fmeasure: 0.7765\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.3612 - acc: 0.8818 - top_k_categorical_accuracy: 0.9896 - precision: 0.9171 - recall: 0.8534 - fmeasure: 0.8839 - val_loss: 1.3932 - val_acc: 0.7481 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7819 - val_recall: 0.7301 - val_fmeasure: 0.7549\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1487 - acc: 0.9469 - top_k_categorical_accuracy: 0.9995 - precision: 0.9537 - recall: 0.9411 - fmeasure: 0.9473 - val_loss: 1.3282 - val_acc: 0.7720 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.7989 - val_recall: 0.7593 - val_fmeasure: 0.7785\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.2936 - acc: 0.9030 - top_k_categorical_accuracy: 0.9922 - precision: 0.9294 - recall: 0.8817 - fmeasure: 0.9047 - val_loss: 1.4531 - val_acc: 0.7388 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7638 - val_recall: 0.7200 - val_fmeasure: 0.7411\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1260 - acc: 0.9546 - top_k_categorical_accuracy: 0.9999 - precision: 0.9605 - recall: 0.9487 - fmeasure: 0.9545 - val_loss: 1.3705 - val_acc: 0.7596 - val_top_k_categorical_accuracy: 0.9287 - val_precision: 0.7895 - val_recall: 0.7475 - val_fmeasure: 0.7678\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2469 - acc: 0.9175 - top_k_categorical_accuracy: 0.9949 - precision: 0.9384 - recall: 0.9006 - fmeasure: 0.9189 - val_loss: 1.4950 - val_acc: 0.7526 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7830 - val_recall: 0.7405 - val_fmeasure: 0.7610\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1310 - acc: 0.9523 - top_k_categorical_accuracy: 0.9999 - precision: 0.9574 - recall: 0.9473 - fmeasure: 0.9523 - val_loss: 1.4619 - val_acc: 0.7700 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7907 - val_recall: 0.7588 - val_fmeasure: 0.7743\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 100us/step - loss: 0.2137 - acc: 0.9285 - top_k_categorical_accuracy: 0.9963 - precision: 0.9463 - recall: 0.9144 - fmeasure: 0.9300 - val_loss: 1.5464 - val_acc: 0.7433 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7766 - val_recall: 0.7324 - val_fmeasure: 0.7537\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1314 - acc: 0.9531 - top_k_categorical_accuracy: 0.9998 - precision: 0.9575 - recall: 0.9464 - fmeasure: 0.9519 - val_loss: 1.4516 - val_acc: 0.7593 - val_top_k_categorical_accuracy: 0.9309 - val_precision: 0.7832 - val_recall: 0.7520 - val_fmeasure: 0.7672\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1802 - acc: 0.9379 - top_k_categorical_accuracy: 0.9974 - precision: 0.9522 - recall: 0.9265 - fmeasure: 0.9391 - val_loss: 1.5090 - val_acc: 0.7616 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.7834 - val_recall: 0.7509 - val_fmeasure: 0.7667\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1102 - acc: 0.9604 - top_k_categorical_accuracy: 0.9999 - precision: 0.9654 - recall: 0.9553 - fmeasure: 0.9603 - val_loss: 1.5853 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.7863 - val_recall: 0.7633 - val_fmeasure: 0.7745\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1622 - acc: 0.9451 - top_k_categorical_accuracy: 0.9976 - precision: 0.9568 - recall: 0.9365 - fmeasure: 0.9464 - val_loss: 1.6266 - val_acc: 0.7574 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7783 - val_recall: 0.7509 - val_fmeasure: 0.7642\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1360 - acc: 0.9508 - top_k_categorical_accuracy: 1.0000 - precision: 0.9559 - recall: 0.9473 - fmeasure: 0.9515 - val_loss: 1.5576 - val_acc: 0.7565 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7765 - val_recall: 0.7492 - val_fmeasure: 0.7626\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.1609 - acc: 0.9475 - top_k_categorical_accuracy: 0.9978 - precision: 0.9584 - recall: 0.9380 - fmeasure: 0.9480 - val_loss: 1.6088 - val_acc: 0.7607 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.7804 - val_recall: 0.7554 - val_fmeasure: 0.7676\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0913 - acc: 0.9683 - top_k_categorical_accuracy: 1.0000 - precision: 0.9719 - recall: 0.9653 - fmeasure: 0.9686 - val_loss: 1.6215 - val_acc: 0.7664 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.7862 - val_recall: 0.7605 - val_fmeasure: 0.7730\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1297 - acc: 0.9554 - top_k_categorical_accuracy: 0.9990 - precision: 0.9636 - recall: 0.9490 - fmeasure: 0.9562 - val_loss: 1.6312 - val_acc: 0.7655 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7860 - val_recall: 0.7593 - val_fmeasure: 0.7724\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1127 - acc: 0.9591 - top_k_categorical_accuracy: 0.9998 - precision: 0.9627 - recall: 0.9565 - fmeasure: 0.9596 - val_loss: 1.6113 - val_acc: 0.7571 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.7809 - val_recall: 0.7459 - val_fmeasure: 0.7629\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1320 - acc: 0.9556 - top_k_categorical_accuracy: 0.9987 - precision: 0.9636 - recall: 0.9486 - fmeasure: 0.9560 - val_loss: 1.7238 - val_acc: 0.7475 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7666 - val_recall: 0.7394 - val_fmeasure: 0.7527\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0967 - acc: 0.9655 - top_k_categorical_accuracy: 1.0000 - precision: 0.9679 - recall: 0.9632 - fmeasure: 0.9655 - val_loss: 1.5794 - val_acc: 0.7678 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.7844 - val_recall: 0.7605 - val_fmeasure: 0.7722\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.1126 - acc: 0.9629 - top_k_categorical_accuracy: 0.9992 - precision: 0.9690 - recall: 0.9577 - fmeasure: 0.9633 - val_loss: 1.8828 - val_acc: 0.7372 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7516 - val_recall: 0.7296 - val_fmeasure: 0.7404\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0987 - acc: 0.9673 - top_k_categorical_accuracy: 1.0000 - precision: 0.9698 - recall: 0.9650 - fmeasure: 0.9673 - val_loss: 1.6391 - val_acc: 0.7613 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.7800 - val_recall: 0.7492 - val_fmeasure: 0.7642\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.0956 - acc: 0.9678 - top_k_categorical_accuracy: 0.9995 - precision: 0.9727 - recall: 0.9636 - fmeasure: 0.9681 - val_loss: 1.7496 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7774 - val_recall: 0.7554 - val_fmeasure: 0.7661\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0853 - acc: 0.9697 - top_k_categorical_accuracy: 1.0000 - precision: 0.9714 - recall: 0.9680 - fmeasure: 0.9697 - val_loss: 1.6264 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.7764 - val_recall: 0.7534 - val_fmeasure: 0.7647\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0918 - acc: 0.9683 - top_k_categorical_accuracy: 0.9994 - precision: 0.9731 - recall: 0.9644 - fmeasure: 0.9687 - val_loss: 1.8643 - val_acc: 0.7397 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7553 - val_recall: 0.7338 - val_fmeasure: 0.7443\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0779 - acc: 0.9730 - top_k_categorical_accuracy: 0.9999 - precision: 0.9746 - recall: 0.9706 - fmeasure: 0.9726 - val_loss: 1.6897 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.7835 - val_recall: 0.7624 - val_fmeasure: 0.7727\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0881 - acc: 0.9718 - top_k_categorical_accuracy: 0.9992 - precision: 0.9754 - recall: 0.9686 - fmeasure: 0.9720 - val_loss: 1.7949 - val_acc: 0.7540 - val_top_k_categorical_accuracy: 0.9219 - val_precision: 0.7699 - val_recall: 0.7478 - val_fmeasure: 0.7586\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0951 - acc: 0.9669 - top_k_categorical_accuracy: 0.9999 - precision: 0.9689 - recall: 0.9655 - fmeasure: 0.9672 - val_loss: 1.6682 - val_acc: 0.7694 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7862 - val_recall: 0.7633 - val_fmeasure: 0.7745\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 100us/step - loss: 0.0859 - acc: 0.9714 - top_k_categorical_accuracy: 0.9993 - precision: 0.9755 - recall: 0.9678 - fmeasure: 0.9716 - val_loss: 1.8894 - val_acc: 0.7498 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7667 - val_recall: 0.7456 - val_fmeasure: 0.7559\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0845 - acc: 0.9704 - top_k_categorical_accuracy: 0.9995 - precision: 0.9719 - recall: 0.9691 - fmeasure: 0.9705 - val_loss: 1.6680 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7881 - val_recall: 0.7661 - val_fmeasure: 0.7769\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.0834 - acc: 0.9723 - top_k_categorical_accuracy: 0.9996 - precision: 0.9758 - recall: 0.9699 - fmeasure: 0.9728 - val_loss: 1.8786 - val_acc: 0.7419 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7602 - val_recall: 0.7363 - val_fmeasure: 0.7480\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0818 - acc: 0.9723 - top_k_categorical_accuracy: 0.9999 - precision: 0.9745 - recall: 0.9709 - fmeasure: 0.9727 - val_loss: 1.7141 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.7835 - val_recall: 0.7579 - val_fmeasure: 0.7704\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0563 - acc: 0.9817 - top_k_categorical_accuracy: 0.9997 - precision: 0.9843 - recall: 0.9801 - fmeasure: 0.9822 - val_loss: 1.9230 - val_acc: 0.7540 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7673 - val_recall: 0.7492 - val_fmeasure: 0.7581\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0876 - acc: 0.9701 - top_k_categorical_accuracy: 0.9999 - precision: 0.9733 - recall: 0.9689 - fmeasure: 0.9711 - val_loss: 1.7876 - val_acc: 0.7613 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7778 - val_recall: 0.7565 - val_fmeasure: 0.7670\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.0710 - acc: 0.9771 - top_k_categorical_accuracy: 0.9996 - precision: 0.9808 - recall: 0.9750 - fmeasure: 0.9779 - val_loss: 1.9109 - val_acc: 0.7593 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.7726 - val_recall: 0.7560 - val_fmeasure: 0.7641\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0865 - acc: 0.9717 - top_k_categorical_accuracy: 1.0000 - precision: 0.9734 - recall: 0.9695 - fmeasure: 0.9714 - val_loss: 1.7988 - val_acc: 0.7551 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7722 - val_recall: 0.7523 - val_fmeasure: 0.7621\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 100us/step - loss: 0.0657 - acc: 0.9785 - top_k_categorical_accuracy: 0.9995 - precision: 0.9807 - recall: 0.9768 - fmeasure: 0.9787 - val_loss: 2.0262 - val_acc: 0.7475 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.7637 - val_recall: 0.7447 - val_fmeasure: 0.7540\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0693 - acc: 0.9775 - top_k_categorical_accuracy: 1.0000 - precision: 0.9784 - recall: 0.9768 - fmeasure: 0.9776 - val_loss: 1.8381 - val_acc: 0.7621 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7769 - val_recall: 0.7582 - val_fmeasure: 0.7673\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.0611 - acc: 0.9796 - top_k_categorical_accuracy: 0.9998 - precision: 0.9816 - recall: 0.9773 - fmeasure: 0.9794 - val_loss: 1.9812 - val_acc: 0.7453 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7579 - val_recall: 0.7411 - val_fmeasure: 0.7493\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0727 - acc: 0.9770 - top_k_categorical_accuracy: 0.9999 - precision: 0.9782 - recall: 0.9752 - fmeasure: 0.9767 - val_loss: 1.8046 - val_acc: 0.7498 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7693 - val_recall: 0.7447 - val_fmeasure: 0.7567\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0567 - acc: 0.9814 - top_k_categorical_accuracy: 0.9996 - precision: 0.9834 - recall: 0.9800 - fmeasure: 0.9817 - val_loss: 1.9691 - val_acc: 0.7456 - val_top_k_categorical_accuracy: 0.9129 - val_precision: 0.7604 - val_recall: 0.7419 - val_fmeasure: 0.7509\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0831 - acc: 0.9729 - top_k_categorical_accuracy: 0.9998 - precision: 0.9747 - recall: 0.9712 - fmeasure: 0.9730 - val_loss: 1.7829 - val_acc: 0.7717 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.7883 - val_recall: 0.7678 - val_fmeasure: 0.7778\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0511 - acc: 0.9831 - top_k_categorical_accuracy: 0.9999 - precision: 0.9846 - recall: 0.9821 - fmeasure: 0.9833 - val_loss: 1.9456 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7731 - val_recall: 0.7577 - val_fmeasure: 0.7652\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0660 - acc: 0.9771 - top_k_categorical_accuracy: 1.0000 - precision: 0.9782 - recall: 0.9764 - fmeasure: 0.9773 - val_loss: 1.8334 - val_acc: 0.7638 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7740 - val_recall: 0.7568 - val_fmeasure: 0.7652\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0557 - acc: 0.9817 - top_k_categorical_accuracy: 0.9998 - precision: 0.9831 - recall: 0.9807 - fmeasure: 0.9819 - val_loss: 1.8829 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.7831 - val_recall: 0.7680 - val_fmeasure: 0.7754\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0569 - acc: 0.9798 - top_k_categorical_accuracy: 0.9999 - precision: 0.9810 - recall: 0.9793 - fmeasure: 0.9801 - val_loss: 1.8388 - val_acc: 0.7641 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.7798 - val_recall: 0.7577 - val_fmeasure: 0.7685\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0513 - acc: 0.9839 - top_k_categorical_accuracy: 0.9998 - precision: 0.9851 - recall: 0.9829 - fmeasure: 0.9840 - val_loss: 2.0111 - val_acc: 0.7574 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7715 - val_recall: 0.7551 - val_fmeasure: 0.7631\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0468 - acc: 0.9825 - top_k_categorical_accuracy: 1.0000 - precision: 0.9832 - recall: 0.9821 - fmeasure: 0.9826 - val_loss: 1.8410 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7819 - val_recall: 0.7694 - val_fmeasure: 0.7756\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.0555 - acc: 0.9825 - top_k_categorical_accuracy: 0.9998 - precision: 0.9842 - recall: 0.9811 - fmeasure: 0.9826 - val_loss: 2.0194 - val_acc: 0.7591 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7712 - val_recall: 0.7529 - val_fmeasure: 0.7618\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0518 - acc: 0.9825 - top_k_categorical_accuracy: 1.0000 - precision: 0.9832 - recall: 0.9816 - fmeasure: 0.9824 - val_loss: 1.8770 - val_acc: 0.7621 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7748 - val_recall: 0.7579 - val_fmeasure: 0.7662\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.0431 - acc: 0.9872 - top_k_categorical_accuracy: 0.9999 - precision: 0.9886 - recall: 0.9860 - fmeasure: 0.9873 - val_loss: 2.0999 - val_acc: 0.7574 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7691 - val_recall: 0.7537 - val_fmeasure: 0.7613\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0616 - acc: 0.9788 - top_k_categorical_accuracy: 1.0000 - precision: 0.9800 - recall: 0.9785 - fmeasure: 0.9792 - val_loss: 1.8625 - val_acc: 0.7647 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7777 - val_recall: 0.7610 - val_fmeasure: 0.7692\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0635 - acc: 0.9809 - top_k_categorical_accuracy: 1.0000 - precision: 0.9818 - recall: 0.9798 - fmeasure: 0.9808 - val_loss: 1.9061 - val_acc: 0.7585 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.7724 - val_recall: 0.7551 - val_fmeasure: 0.7636\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0467 - acc: 0.9839 - top_k_categorical_accuracy: 0.9999 - precision: 0.9844 - recall: 0.9825 - fmeasure: 0.9835 - val_loss: 1.8508 - val_acc: 0.7686 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.7791 - val_recall: 0.7666 - val_fmeasure: 0.7727\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0499 - acc: 0.9837 - top_k_categorical_accuracy: 1.0000 - precision: 0.9842 - recall: 0.9836 - fmeasure: 0.9839 - val_loss: 1.8241 - val_acc: 0.7700 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.7816 - val_recall: 0.7644 - val_fmeasure: 0.7729\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0254 - acc: 0.9912 - top_k_categorical_accuracy: 0.9999 - precision: 0.9914 - recall: 0.9912 - fmeasure: 0.9913 - val_loss: 1.8888 - val_acc: 0.7703 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.7828 - val_recall: 0.7666 - val_fmeasure: 0.7746\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0337 - acc: 0.9894 - top_k_categorical_accuracy: 1.0000 - precision: 0.9898 - recall: 0.9893 - fmeasure: 0.9895 - val_loss: 1.7538 - val_acc: 0.7829 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7957 - val_recall: 0.7779 - val_fmeasure: 0.7866\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0333 - acc: 0.9877 - top_k_categorical_accuracy: 1.0000 - precision: 0.9881 - recall: 0.9875 - fmeasure: 0.9878 - val_loss: 1.7621 - val_acc: 0.7779 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.7899 - val_recall: 0.7737 - val_fmeasure: 0.7816\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0417 - acc: 0.9852 - top_k_categorical_accuracy: 0.9998 - precision: 0.9857 - recall: 0.9847 - fmeasure: 0.9852 - val_loss: 1.8084 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7877 - val_recall: 0.7700 - val_fmeasure: 0.7787\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0606 - acc: 0.9795 - top_k_categorical_accuracy: 0.9999 - precision: 0.9808 - recall: 0.9789 - fmeasure: 0.9799 - val_loss: 1.8385 - val_acc: 0.7621 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.7770 - val_recall: 0.7568 - val_fmeasure: 0.7667\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0422 - acc: 0.9853 - top_k_categorical_accuracy: 1.0000 - precision: 0.9866 - recall: 0.9845 - fmeasure: 0.9855 - val_loss: 1.7959 - val_acc: 0.7709 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7817 - val_recall: 0.7652 - val_fmeasure: 0.7734\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0329 - acc: 0.9884 - top_k_categorical_accuracy: 0.9999 - precision: 0.9886 - recall: 0.9882 - fmeasure: 0.9884 - val_loss: 1.7787 - val_acc: 0.7728 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.7844 - val_recall: 0.7692 - val_fmeasure: 0.7767\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0214 - acc: 0.9925 - top_k_categorical_accuracy: 1.0000 - precision: 0.9930 - recall: 0.9922 - fmeasure: 0.9926 - val_loss: 1.8576 - val_acc: 0.7770 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7904 - val_recall: 0.7737 - val_fmeasure: 0.7819\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0504 - acc: 0.9844 - top_k_categorical_accuracy: 0.9996 - precision: 0.9854 - recall: 0.9837 - fmeasure: 0.9846 - val_loss: 1.9258 - val_acc: 0.7610 - val_top_k_categorical_accuracy: 0.9135 - val_precision: 0.7724 - val_recall: 0.7557 - val_fmeasure: 0.7639\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0392 - acc: 0.9862 - top_k_categorical_accuracy: 1.0000 - precision: 0.9869 - recall: 0.9857 - fmeasure: 0.9863 - val_loss: 1.8536 - val_acc: 0.7709 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7845 - val_recall: 0.7650 - val_fmeasure: 0.7745\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0223 - acc: 0.9913 - top_k_categorical_accuracy: 1.0000 - precision: 0.9921 - recall: 0.9912 - fmeasure: 0.9916 - val_loss: 1.8974 - val_acc: 0.7745 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7873 - val_recall: 0.7711 - val_fmeasure: 0.7791\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0307 - acc: 0.9895 - top_k_categorical_accuracy: 1.0000 - precision: 0.9900 - recall: 0.9894 - fmeasure: 0.9897 - val_loss: 1.9419 - val_acc: 0.7678 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7810 - val_recall: 0.7658 - val_fmeasure: 0.7732\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0523 - acc: 0.9834 - top_k_categorical_accuracy: 1.0000 - precision: 0.9836 - recall: 0.9828 - fmeasure: 0.9832 - val_loss: 1.8327 - val_acc: 0.7739 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7877 - val_recall: 0.7703 - val_fmeasure: 0.7788\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0337 - acc: 0.9883 - top_k_categorical_accuracy: 1.0000 - precision: 0.9895 - recall: 0.9880 - fmeasure: 0.9887 - val_loss: 1.8310 - val_acc: 0.7737 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.7822 - val_recall: 0.7709 - val_fmeasure: 0.7764\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0325 - acc: 0.9886 - top_k_categorical_accuracy: 0.9998 - precision: 0.9887 - recall: 0.9881 - fmeasure: 0.9884 - val_loss: 1.8058 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7899 - val_recall: 0.7714 - val_fmeasure: 0.7805\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0299 - acc: 0.9898 - top_k_categorical_accuracy: 1.0000 - precision: 0.9902 - recall: 0.9895 - fmeasure: 0.9899 - val_loss: 1.7750 - val_acc: 0.7765 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7860 - val_recall: 0.7734 - val_fmeasure: 0.7796\n",
            "transplanting......\n",
            "When the process freezing, please check that datatype_Close has been set correctly\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 185us/step - loss: 3.6036 - acc: 0.1422 - top_k_categorical_accuracy: 0.3722 - precision: 0.2635 - recall: 0.0142 - fmeasure: 0.0260 - val_loss: 2.9167 - val_acc: 0.2929 - val_top_k_categorical_accuracy: 0.5816 - val_precision: 0.8507 - val_recall: 0.0691 - val_fmeasure: 0.1262\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 2.2393 - acc: 0.4518 - top_k_categorical_accuracy: 0.7497 - precision: 0.7912 - recall: 0.2116 - fmeasure: 0.3231 - val_loss: 1.9425 - val_acc: 0.5439 - val_top_k_categorical_accuracy: 0.8110 - val_precision: 0.7863 - val_recall: 0.3524 - val_fmeasure: 0.4844\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 1.5351 - acc: 0.6350 - top_k_categorical_accuracy: 0.8554 - precision: 0.8306 - recall: 0.4626 - fmeasure: 0.5910 - val_loss: 1.6199 - val_acc: 0.6338 - val_top_k_categorical_accuracy: 0.8458 - val_precision: 0.8054 - val_recall: 0.4830 - val_fmeasure: 0.6022\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 1.2054 - acc: 0.7045 - top_k_categorical_accuracy: 0.8978 - precision: 0.8432 - recall: 0.5894 - fmeasure: 0.6922 - val_loss: 1.4338 - val_acc: 0.6751 - val_top_k_categorical_accuracy: 0.8739 - val_precision: 0.8342 - val_recall: 0.5465 - val_fmeasure: 0.6590\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.9622 - acc: 0.7557 - top_k_categorical_accuracy: 0.9287 - precision: 0.8646 - recall: 0.6692 - fmeasure: 0.7535 - val_loss: 1.3790 - val_acc: 0.6757 - val_top_k_categorical_accuracy: 0.8818 - val_precision: 0.7886 - val_recall: 0.6038 - val_fmeasure: 0.6832\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.8374 - acc: 0.7784 - top_k_categorical_accuracy: 0.9415 - precision: 0.8705 - recall: 0.7046 - fmeasure: 0.7780 - val_loss: 1.2567 - val_acc: 0.7099 - val_top_k_categorical_accuracy: 0.9031 - val_precision: 0.8082 - val_recall: 0.6417 - val_fmeasure: 0.7148\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.7031 - acc: 0.8098 - top_k_categorical_accuracy: 0.9616 - precision: 0.8837 - recall: 0.7498 - fmeasure: 0.8107 - val_loss: 1.2323 - val_acc: 0.7138 - val_top_k_categorical_accuracy: 0.9065 - val_precision: 0.8012 - val_recall: 0.6571 - val_fmeasure: 0.7212\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.6108 - acc: 0.8236 - top_k_categorical_accuracy: 0.9681 - precision: 0.8878 - recall: 0.7730 - fmeasure: 0.8258 - val_loss: 1.1355 - val_acc: 0.7464 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.8276 - val_recall: 0.6925 - val_fmeasure: 0.7535\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.5255 - acc: 0.8456 - top_k_categorical_accuracy: 0.9771 - precision: 0.8993 - recall: 0.8005 - fmeasure: 0.8467 - val_loss: 1.1639 - val_acc: 0.7436 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.8072 - val_recall: 0.6947 - val_fmeasure: 0.7463\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.4712 - acc: 0.8606 - top_k_categorical_accuracy: 0.9833 - precision: 0.9057 - recall: 0.8216 - fmeasure: 0.8612 - val_loss: 1.1780 - val_acc: 0.7436 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.8120 - val_recall: 0.7043 - val_fmeasure: 0.7539\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.4164 - acc: 0.8666 - top_k_categorical_accuracy: 0.9886 - precision: 0.9079 - recall: 0.8340 - fmeasure: 0.8691 - val_loss: 1.1739 - val_acc: 0.7579 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.8169 - val_recall: 0.7197 - val_fmeasure: 0.7648\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.3569 - acc: 0.8856 - top_k_categorical_accuracy: 0.9931 - precision: 0.9177 - recall: 0.8584 - fmeasure: 0.8868 - val_loss: 1.2838 - val_acc: 0.7304 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.7876 - val_recall: 0.6992 - val_fmeasure: 0.7405\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3139 - acc: 0.8983 - top_k_categorical_accuracy: 0.9945 - precision: 0.9274 - recall: 0.8737 - fmeasure: 0.8995 - val_loss: 1.3436 - val_acc: 0.7411 - val_top_k_categorical_accuracy: 0.9135 - val_precision: 0.7978 - val_recall: 0.7063 - val_fmeasure: 0.7488\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3172 - acc: 0.8989 - top_k_categorical_accuracy: 0.9952 - precision: 0.9253 - recall: 0.8759 - fmeasure: 0.8997 - val_loss: 1.2605 - val_acc: 0.7489 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7927 - val_recall: 0.7110 - val_fmeasure: 0.7493\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2709 - acc: 0.9131 - top_k_categorical_accuracy: 0.9978 - precision: 0.9371 - recall: 0.8923 - fmeasure: 0.9139 - val_loss: 1.2402 - val_acc: 0.7467 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.8021 - val_recall: 0.7152 - val_fmeasure: 0.7558\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.2620 - acc: 0.9153 - top_k_categorical_accuracy: 0.9975 - precision: 0.9338 - recall: 0.8951 - fmeasure: 0.9139 - val_loss: 1.2662 - val_acc: 0.7509 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.8023 - val_recall: 0.7284 - val_fmeasure: 0.7633\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2334 - acc: 0.9215 - top_k_categorical_accuracy: 0.9983 - precision: 0.9396 - recall: 0.9054 - fmeasure: 0.9220 - val_loss: 1.5423 - val_acc: 0.7256 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7608 - val_recall: 0.7063 - val_fmeasure: 0.7323\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2099 - acc: 0.9314 - top_k_categorical_accuracy: 0.9995 - precision: 0.9450 - recall: 0.9161 - fmeasure: 0.9302 - val_loss: 1.3039 - val_acc: 0.7548 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7967 - val_recall: 0.7329 - val_fmeasure: 0.7632\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2083 - acc: 0.9317 - top_k_categorical_accuracy: 0.9986 - precision: 0.9449 - recall: 0.9185 - fmeasure: 0.9314 - val_loss: 1.3593 - val_acc: 0.7548 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7855 - val_recall: 0.7357 - val_fmeasure: 0.7596\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1945 - acc: 0.9339 - top_k_categorical_accuracy: 0.9993 - precision: 0.9464 - recall: 0.9220 - fmeasure: 0.9339 - val_loss: 1.4440 - val_acc: 0.7223 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.7675 - val_recall: 0.7004 - val_fmeasure: 0.7321\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1959 - acc: 0.9317 - top_k_categorical_accuracy: 0.9995 - precision: 0.9458 - recall: 0.9180 - fmeasure: 0.9316 - val_loss: 1.4018 - val_acc: 0.7498 - val_top_k_categorical_accuracy: 0.9177 - val_precision: 0.7828 - val_recall: 0.7313 - val_fmeasure: 0.7559\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 3.4498 - acc: 0.2584 - top_k_categorical_accuracy: 0.4702 - precision: 0.6707 - recall: 0.1044 - fmeasure: 0.1759 - val_loss: 1.9390 - val_acc: 0.5630 - val_top_k_categorical_accuracy: 0.8222 - val_precision: 0.8318 - val_recall: 0.2988 - val_fmeasure: 0.4372\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.5094 - acc: 0.8612 - top_k_categorical_accuracy: 0.9760 - precision: 0.9198 - recall: 0.7991 - fmeasure: 0.8497 - val_loss: 1.0786 - val_acc: 0.7725 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8207 - val_recall: 0.7445 - val_fmeasure: 0.7804\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 2.8205 - acc: 0.3615 - top_k_categorical_accuracy: 0.5994 - precision: 0.7282 - recall: 0.1949 - fmeasure: 0.3035 - val_loss: 1.7393 - val_acc: 0.5897 - val_top_k_categorical_accuracy: 0.8517 - val_precision: 0.7939 - val_recall: 0.3496 - val_fmeasure: 0.4833\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.5257 - acc: 0.8478 - top_k_categorical_accuracy: 0.9786 - precision: 0.9055 - recall: 0.7908 - fmeasure: 0.8409 - val_loss: 1.0048 - val_acc: 0.7759 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8368 - val_recall: 0.7442 - val_fmeasure: 0.7874\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 2.4552 - acc: 0.4277 - top_k_categorical_accuracy: 0.6691 - precision: 0.7551 - recall: 0.2713 - fmeasure: 0.3964 - val_loss: 1.4985 - val_acc: 0.6602 - val_top_k_categorical_accuracy: 0.8689 - val_precision: 0.8428 - val_recall: 0.4535 - val_fmeasure: 0.5879\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.4502 - acc: 0.8671 - top_k_categorical_accuracy: 0.9837 - precision: 0.9157 - recall: 0.8179 - fmeasure: 0.8609 - val_loss: 1.0270 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9320 - val_precision: 0.8362 - val_recall: 0.7495 - val_fmeasure: 0.7901\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 2.1744 - acc: 0.4780 - top_k_categorical_accuracy: 0.7220 - precision: 0.7764 - recall: 0.3317 - fmeasure: 0.4622 - val_loss: 1.3950 - val_acc: 0.6709 - val_top_k_categorical_accuracy: 0.8851 - val_precision: 0.8527 - val_recall: 0.4987 - val_fmeasure: 0.6271\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.4251 - acc: 0.8714 - top_k_categorical_accuracy: 0.9858 - precision: 0.9130 - recall: 0.8291 - fmeasure: 0.8667 - val_loss: 0.9970 - val_acc: 0.7919 - val_top_k_categorical_accuracy: 0.9354 - val_precision: 0.8446 - val_recall: 0.7635 - val_fmeasure: 0.8016\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 1.9409 - acc: 0.5204 - top_k_categorical_accuracy: 0.7616 - precision: 0.7972 - recall: 0.3860 - fmeasure: 0.5179 - val_loss: 1.3769 - val_acc: 0.6740 - val_top_k_categorical_accuracy: 0.8807 - val_precision: 0.8428 - val_recall: 0.5310 - val_fmeasure: 0.6498\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.3667 - acc: 0.8836 - top_k_categorical_accuracy: 0.9877 - precision: 0.9213 - recall: 0.8494 - fmeasure: 0.8825 - val_loss: 1.0128 - val_acc: 0.7933 - val_top_k_categorical_accuracy: 0.9385 - val_precision: 0.8336 - val_recall: 0.7739 - val_fmeasure: 0.8023\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 1.7655 - acc: 0.5556 - top_k_categorical_accuracy: 0.7889 - precision: 0.8102 - recall: 0.4289 - fmeasure: 0.5588 - val_loss: 1.3097 - val_acc: 0.6897 - val_top_k_categorical_accuracy: 0.8908 - val_precision: 0.8364 - val_recall: 0.5504 - val_fmeasure: 0.6625\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.3500 - acc: 0.8917 - top_k_categorical_accuracy: 0.9907 - precision: 0.9253 - recall: 0.8607 - fmeasure: 0.8907 - val_loss: 0.9477 - val_acc: 0.7956 - val_top_k_categorical_accuracy: 0.9413 - val_precision: 0.8419 - val_recall: 0.7739 - val_fmeasure: 0.8060\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 1.6041 - acc: 0.5860 - top_k_categorical_accuracy: 0.8178 - precision: 0.8145 - recall: 0.4632 - fmeasure: 0.5888 - val_loss: 1.3439 - val_acc: 0.6737 - val_top_k_categorical_accuracy: 0.8818 - val_precision: 0.8224 - val_recall: 0.5715 - val_fmeasure: 0.6730\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.3204 - acc: 0.8984 - top_k_categorical_accuracy: 0.9939 - precision: 0.9273 - recall: 0.8713 - fmeasure: 0.8977 - val_loss: 0.9555 - val_acc: 0.7888 - val_top_k_categorical_accuracy: 0.9436 - val_precision: 0.8327 - val_recall: 0.7689 - val_fmeasure: 0.7992\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 1.4457 - acc: 0.6183 - top_k_categorical_accuracy: 0.8424 - precision: 0.8286 - recall: 0.5035 - fmeasure: 0.6247 - val_loss: 1.2448 - val_acc: 0.6992 - val_top_k_categorical_accuracy: 0.9006 - val_precision: 0.8372 - val_recall: 0.6071 - val_fmeasure: 0.7028\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2957 - acc: 0.9055 - top_k_categorical_accuracy: 0.9954 - precision: 0.9306 - recall: 0.8796 - fmeasure: 0.9037 - val_loss: 1.0374 - val_acc: 0.7902 - val_top_k_categorical_accuracy: 0.9348 - val_precision: 0.8286 - val_recall: 0.7714 - val_fmeasure: 0.7988\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 1.2912 - acc: 0.6486 - top_k_categorical_accuracy: 0.8677 - precision: 0.8406 - recall: 0.5442 - fmeasure: 0.6591 - val_loss: 1.2701 - val_acc: 0.7032 - val_top_k_categorical_accuracy: 0.8964 - val_precision: 0.8157 - val_recall: 0.6316 - val_fmeasure: 0.7107\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2672 - acc: 0.9128 - top_k_categorical_accuracy: 0.9940 - precision: 0.9328 - recall: 0.8951 - fmeasure: 0.9131 - val_loss: 0.9623 - val_acc: 0.8071 - val_top_k_categorical_accuracy: 0.9438 - val_precision: 0.8413 - val_recall: 0.7874 - val_fmeasure: 0.8132\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 1.1578 - acc: 0.6793 - top_k_categorical_accuracy: 0.8914 - precision: 0.8495 - recall: 0.5822 - fmeasure: 0.6896 - val_loss: 1.2424 - val_acc: 0.7124 - val_top_k_categorical_accuracy: 0.9045 - val_precision: 0.8204 - val_recall: 0.6532 - val_fmeasure: 0.7267\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2452 - acc: 0.9210 - top_k_categorical_accuracy: 0.9966 - precision: 0.9401 - recall: 0.9041 - fmeasure: 0.9214 - val_loss: 1.0941 - val_acc: 0.7869 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.8246 - val_recall: 0.7739 - val_fmeasure: 0.7983\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 1.0494 - acc: 0.7092 - top_k_categorical_accuracy: 0.9082 - precision: 0.8592 - recall: 0.6119 - fmeasure: 0.7134 - val_loss: 1.4257 - val_acc: 0.6740 - val_top_k_categorical_accuracy: 0.8781 - val_precision: 0.7844 - val_recall: 0.6212 - val_fmeasure: 0.6926\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2454 - acc: 0.9159 - top_k_categorical_accuracy: 0.9971 - precision: 0.9347 - recall: 0.8973 - fmeasure: 0.9151 - val_loss: 1.1230 - val_acc: 0.7919 - val_top_k_categorical_accuracy: 0.9382 - val_precision: 0.8245 - val_recall: 0.7723 - val_fmeasure: 0.7972\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.9284 - acc: 0.7365 - top_k_categorical_accuracy: 0.9244 - precision: 0.8683 - recall: 0.6500 - fmeasure: 0.7423 - val_loss: 1.3523 - val_acc: 0.7026 - val_top_k_categorical_accuracy: 0.8927 - val_precision: 0.7915 - val_recall: 0.6523 - val_fmeasure: 0.7146\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2502 - acc: 0.9160 - top_k_categorical_accuracy: 0.9960 - precision: 0.9341 - recall: 0.8997 - fmeasure: 0.9163 - val_loss: 1.0899 - val_acc: 0.7958 - val_top_k_categorical_accuracy: 0.9323 - val_precision: 0.8339 - val_recall: 0.7793 - val_fmeasure: 0.8054\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.8322 - acc: 0.7585 - top_k_categorical_accuracy: 0.9360 - precision: 0.8788 - recall: 0.6813 - fmeasure: 0.7667 - val_loss: 1.3811 - val_acc: 0.7094 - val_top_k_categorical_accuracy: 0.8981 - val_precision: 0.7862 - val_recall: 0.6672 - val_fmeasure: 0.7214\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2141 - acc: 0.9255 - top_k_categorical_accuracy: 0.9971 - precision: 0.9391 - recall: 0.9107 - fmeasure: 0.9244 - val_loss: 1.1358 - val_acc: 0.7956 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8258 - val_recall: 0.7824 - val_fmeasure: 0.8033\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.7194 - acc: 0.7901 - top_k_categorical_accuracy: 0.9485 - precision: 0.8894 - recall: 0.7220 - fmeasure: 0.7961 - val_loss: 1.4798 - val_acc: 0.6978 - val_top_k_categorical_accuracy: 0.8880 - val_precision: 0.7638 - val_recall: 0.6605 - val_fmeasure: 0.7081\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2049 - acc: 0.9283 - top_k_categorical_accuracy: 0.9977 - precision: 0.9401 - recall: 0.9196 - fmeasure: 0.9295 - val_loss: 1.2647 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9348 - val_precision: 0.8053 - val_recall: 0.7655 - val_fmeasure: 0.7848\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.6258 - acc: 0.8155 - top_k_categorical_accuracy: 0.9581 - precision: 0.9046 - recall: 0.7559 - fmeasure: 0.8230 - val_loss: 1.5569 - val_acc: 0.7006 - val_top_k_categorical_accuracy: 0.8891 - val_precision: 0.7709 - val_recall: 0.6684 - val_fmeasure: 0.7154\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.2160 - acc: 0.9296 - top_k_categorical_accuracy: 0.9975 - precision: 0.9408 - recall: 0.9214 - fmeasure: 0.9309 - val_loss: 1.1601 - val_acc: 0.7956 - val_top_k_categorical_accuracy: 0.9371 - val_precision: 0.8222 - val_recall: 0.7801 - val_fmeasure: 0.8004\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 104us/step - loss: 0.5729 - acc: 0.8285 - top_k_categorical_accuracy: 0.9642 - precision: 0.9073 - recall: 0.7765 - fmeasure: 0.8362 - val_loss: 1.4678 - val_acc: 0.7167 - val_top_k_categorical_accuracy: 0.9034 - val_precision: 0.7739 - val_recall: 0.6933 - val_fmeasure: 0.7310\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.1945 - acc: 0.9339 - top_k_categorical_accuracy: 0.9987 - precision: 0.9445 - recall: 0.9245 - fmeasure: 0.9343 - val_loss: 1.2988 - val_acc: 0.7908 - val_top_k_categorical_accuracy: 0.9287 - val_precision: 0.8180 - val_recall: 0.7810 - val_fmeasure: 0.7989\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 105us/step - loss: 0.5038 - acc: 0.8500 - top_k_categorical_accuracy: 0.9717 - precision: 0.9153 - recall: 0.8022 - fmeasure: 0.8545 - val_loss: 1.5946 - val_acc: 0.6959 - val_top_k_categorical_accuracy: 0.8947 - val_precision: 0.7533 - val_recall: 0.6698 - val_fmeasure: 0.7088\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2085 - acc: 0.9320 - top_k_categorical_accuracy: 0.9984 - precision: 0.9407 - recall: 0.9240 - fmeasure: 0.9322 - val_loss: 1.3399 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7958 - val_recall: 0.7548 - val_fmeasure: 0.7746\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.4755 - acc: 0.8570 - top_k_categorical_accuracy: 0.9745 - precision: 0.9160 - recall: 0.8146 - fmeasure: 0.8618 - val_loss: 1.5682 - val_acc: 0.7296 - val_top_k_categorical_accuracy: 0.8975 - val_precision: 0.7837 - val_recall: 0.7138 - val_fmeasure: 0.7469\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.1822 - acc: 0.9379 - top_k_categorical_accuracy: 0.9989 - precision: 0.9469 - recall: 0.9314 - fmeasure: 0.9390 - val_loss: 1.2909 - val_acc: 0.7885 - val_top_k_categorical_accuracy: 0.9323 - val_precision: 0.8136 - val_recall: 0.7773 - val_fmeasure: 0.7948\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.4092 - acc: 0.8748 - top_k_categorical_accuracy: 0.9790 - precision: 0.9285 - recall: 0.8387 - fmeasure: 0.8809 - val_loss: 1.6390 - val_acc: 0.7138 - val_top_k_categorical_accuracy: 0.8958 - val_precision: 0.7619 - val_recall: 0.6953 - val_fmeasure: 0.7268\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2044 - acc: 0.9309 - top_k_categorical_accuracy: 0.9990 - precision: 0.9402 - recall: 0.9254 - fmeasure: 0.9327 - val_loss: 1.3470 - val_acc: 0.7798 - val_top_k_categorical_accuracy: 0.9273 - val_precision: 0.8095 - val_recall: 0.7700 - val_fmeasure: 0.7890\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.3742 - acc: 0.8884 - top_k_categorical_accuracy: 0.9819 - precision: 0.9331 - recall: 0.8552 - fmeasure: 0.8921 - val_loss: 1.6742 - val_acc: 0.7223 - val_top_k_categorical_accuracy: 0.8972 - val_precision: 0.7706 - val_recall: 0.7110 - val_fmeasure: 0.7394\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1740 - acc: 0.9408 - top_k_categorical_accuracy: 0.9996 - precision: 0.9467 - recall: 0.9343 - fmeasure: 0.9404 - val_loss: 1.3814 - val_acc: 0.7832 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8030 - val_recall: 0.7739 - val_fmeasure: 0.7881\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.3434 - acc: 0.8970 - top_k_categorical_accuracy: 0.9838 - precision: 0.9361 - recall: 0.8675 - fmeasure: 0.9002 - val_loss: 1.6043 - val_acc: 0.7254 - val_top_k_categorical_accuracy: 0.8969 - val_precision: 0.7714 - val_recall: 0.7088 - val_fmeasure: 0.7386\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1697 - acc: 0.9426 - top_k_categorical_accuracy: 0.9987 - precision: 0.9499 - recall: 0.9376 - fmeasure: 0.9437 - val_loss: 1.5002 - val_acc: 0.7717 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7999 - val_recall: 0.7638 - val_fmeasure: 0.7813\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.3121 - acc: 0.9066 - top_k_categorical_accuracy: 0.9850 - precision: 0.9414 - recall: 0.8817 - fmeasure: 0.9103 - val_loss: 1.7173 - val_acc: 0.7169 - val_top_k_categorical_accuracy: 0.9000 - val_precision: 0.7556 - val_recall: 0.7020 - val_fmeasure: 0.7277\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.1514 - acc: 0.9447 - top_k_categorical_accuracy: 0.9999 - precision: 0.9506 - recall: 0.9414 - fmeasure: 0.9459 - val_loss: 1.4317 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8024 - val_recall: 0.7725 - val_fmeasure: 0.7871\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 102us/step - loss: 0.3006 - acc: 0.9093 - top_k_categorical_accuracy: 0.9871 - precision: 0.9413 - recall: 0.8879 - fmeasure: 0.9136 - val_loss: 1.7599 - val_acc: 0.7088 - val_top_k_categorical_accuracy: 0.8944 - val_precision: 0.7507 - val_recall: 0.6939 - val_fmeasure: 0.7209\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.1668 - acc: 0.9435 - top_k_categorical_accuracy: 0.9988 - precision: 0.9498 - recall: 0.9392 - fmeasure: 0.9444 - val_loss: 1.4204 - val_acc: 0.7790 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8069 - val_recall: 0.7711 - val_fmeasure: 0.7885\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 107us/step - loss: 0.2685 - acc: 0.9189 - top_k_categorical_accuracy: 0.9886 - precision: 0.9480 - recall: 0.8983 - fmeasure: 0.9222 - val_loss: 1.7216 - val_acc: 0.7341 - val_top_k_categorical_accuracy: 0.9003 - val_precision: 0.7664 - val_recall: 0.7228 - val_fmeasure: 0.7438\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 0.1588 - acc: 0.9492 - top_k_categorical_accuracy: 0.9990 - precision: 0.9541 - recall: 0.9435 - fmeasure: 0.9488 - val_loss: 1.4728 - val_acc: 0.7748 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.7970 - val_recall: 0.7652 - val_fmeasure: 0.7806\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 3s 101us/step - loss: 0.2654 - acc: 0.9209 - top_k_categorical_accuracy: 0.9890 - precision: 0.9471 - recall: 0.9013 - fmeasure: 0.9234 - val_loss: 1.8117 - val_acc: 0.7161 - val_top_k_categorical_accuracy: 0.8941 - val_precision: 0.7524 - val_recall: 0.7051 - val_fmeasure: 0.7278\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 109us/step - loss: 0.1572 - acc: 0.9500 - top_k_categorical_accuracy: 0.9994 - precision: 0.9557 - recall: 0.9459 - fmeasure: 0.9507 - val_loss: 1.4818 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.8001 - val_recall: 0.7711 - val_fmeasure: 0.7852\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2373 - acc: 0.9287 - top_k_categorical_accuracy: 0.9904 - precision: 0.9523 - recall: 0.9122 - fmeasure: 0.9316 - val_loss: 1.7668 - val_acc: 0.7282 - val_top_k_categorical_accuracy: 0.8967 - val_precision: 0.7647 - val_recall: 0.7192 - val_fmeasure: 0.7411\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1473 - acc: 0.9505 - top_k_categorical_accuracy: 0.9994 - precision: 0.9557 - recall: 0.9456 - fmeasure: 0.9506 - val_loss: 1.5229 - val_acc: 0.7720 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7880 - val_recall: 0.7661 - val_fmeasure: 0.7768\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2281 - acc: 0.9320 - top_k_categorical_accuracy: 0.9909 - precision: 0.9535 - recall: 0.9175 - fmeasure: 0.9350 - val_loss: 1.7924 - val_acc: 0.7268 - val_top_k_categorical_accuracy: 0.8975 - val_precision: 0.7597 - val_recall: 0.7158 - val_fmeasure: 0.7370\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1506 - acc: 0.9544 - top_k_categorical_accuracy: 0.9994 - precision: 0.9592 - recall: 0.9497 - fmeasure: 0.9544 - val_loss: 1.4486 - val_acc: 0.7897 - val_top_k_categorical_accuracy: 0.9312 - val_precision: 0.8080 - val_recall: 0.7829 - val_fmeasure: 0.7952\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.2036 - acc: 0.9396 - top_k_categorical_accuracy: 0.9922 - precision: 0.9581 - recall: 0.9244 - fmeasure: 0.9409 - val_loss: 1.7533 - val_acc: 0.7343 - val_top_k_categorical_accuracy: 0.9042 - val_precision: 0.7671 - val_recall: 0.7228 - val_fmeasure: 0.7442\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1365 - acc: 0.9531 - top_k_categorical_accuracy: 0.9995 - precision: 0.9585 - recall: 0.9491 - fmeasure: 0.9537 - val_loss: 1.4242 - val_acc: 0.7902 - val_top_k_categorical_accuracy: 0.9306 - val_precision: 0.8155 - val_recall: 0.7815 - val_fmeasure: 0.7980\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2107 - acc: 0.9343 - top_k_categorical_accuracy: 0.9926 - precision: 0.9533 - recall: 0.9213 - fmeasure: 0.9369 - val_loss: 1.8402 - val_acc: 0.7254 - val_top_k_categorical_accuracy: 0.8967 - val_precision: 0.7556 - val_recall: 0.7133 - val_fmeasure: 0.7337\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1404 - acc: 0.9556 - top_k_categorical_accuracy: 0.9995 - precision: 0.9592 - recall: 0.9504 - fmeasure: 0.9547 - val_loss: 1.6199 - val_acc: 0.7728 - val_top_k_categorical_accuracy: 0.9219 - val_precision: 0.7930 - val_recall: 0.7641 - val_fmeasure: 0.7782\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1907 - acc: 0.9424 - top_k_categorical_accuracy: 0.9919 - precision: 0.9598 - recall: 0.9301 - fmeasure: 0.9446 - val_loss: 1.7846 - val_acc: 0.7290 - val_top_k_categorical_accuracy: 0.9026 - val_precision: 0.7600 - val_recall: 0.7152 - val_fmeasure: 0.7368\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1232 - acc: 0.9591 - top_k_categorical_accuracy: 0.9994 - precision: 0.9631 - recall: 0.9567 - fmeasure: 0.9599 - val_loss: 1.5012 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7973 - val_recall: 0.7683 - val_fmeasure: 0.7824\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.1101 - acc: 0.9629 - top_k_categorical_accuracy: 0.9999 - precision: 0.9667 - recall: 0.9605 - fmeasure: 0.9636 - val_loss: 1.5500 - val_acc: 0.7683 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7887 - val_recall: 0.7551 - val_fmeasure: 0.7714\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0915 - acc: 0.9703 - top_k_categorical_accuracy: 1.0000 - precision: 0.9721 - recall: 0.9671 - fmeasure: 0.9696 - val_loss: 1.4755 - val_acc: 0.7880 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8039 - val_recall: 0.7812 - val_fmeasure: 0.7924\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0917 - acc: 0.9689 - top_k_categorical_accuracy: 0.9999 - precision: 0.9713 - recall: 0.9658 - fmeasure: 0.9685 - val_loss: 1.4908 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9292 - val_precision: 0.7986 - val_recall: 0.7686 - val_fmeasure: 0.7832\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0726 - acc: 0.9758 - top_k_categorical_accuracy: 0.9995 - precision: 0.9782 - recall: 0.9733 - fmeasure: 0.9757 - val_loss: 1.6081 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7925 - val_recall: 0.7728 - val_fmeasure: 0.7825\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0879 - acc: 0.9705 - top_k_categorical_accuracy: 0.9998 - precision: 0.9731 - recall: 0.9688 - fmeasure: 0.9710 - val_loss: 1.4804 - val_acc: 0.7899 - val_top_k_categorical_accuracy: 0.9306 - val_precision: 0.8114 - val_recall: 0.7790 - val_fmeasure: 0.7947\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0703 - acc: 0.9753 - top_k_categorical_accuracy: 1.0000 - precision: 0.9781 - recall: 0.9732 - fmeasure: 0.9756 - val_loss: 1.5445 - val_acc: 0.7804 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7972 - val_recall: 0.7731 - val_fmeasure: 0.7849\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0752 - acc: 0.9744 - top_k_categorical_accuracy: 0.9999 - precision: 0.9779 - recall: 0.9718 - fmeasure: 0.9748 - val_loss: 1.4842 - val_acc: 0.7874 - val_top_k_categorical_accuracy: 0.9281 - val_precision: 0.8071 - val_recall: 0.7815 - val_fmeasure: 0.7941\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0731 - acc: 0.9727 - top_k_categorical_accuracy: 1.0000 - precision: 0.9759 - recall: 0.9699 - fmeasure: 0.9729 - val_loss: 1.4754 - val_acc: 0.7899 - val_top_k_categorical_accuracy: 0.9295 - val_precision: 0.8085 - val_recall: 0.7855 - val_fmeasure: 0.7967\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0933 - acc: 0.9700 - top_k_categorical_accuracy: 0.9999 - precision: 0.9724 - recall: 0.9682 - fmeasure: 0.9703 - val_loss: 1.5674 - val_acc: 0.7745 - val_top_k_categorical_accuracy: 0.9275 - val_precision: 0.7966 - val_recall: 0.7647 - val_fmeasure: 0.7802\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0726 - acc: 0.9733 - top_k_categorical_accuracy: 1.0000 - precision: 0.9760 - recall: 0.9712 - fmeasure: 0.9736 - val_loss: 1.5316 - val_acc: 0.7916 - val_top_k_categorical_accuracy: 0.9275 - val_precision: 0.8088 - val_recall: 0.7832 - val_fmeasure: 0.7957\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0641 - acc: 0.9800 - top_k_categorical_accuracy: 1.0000 - precision: 0.9815 - recall: 0.9779 - fmeasure: 0.9797 - val_loss: 1.5003 - val_acc: 0.7793 - val_top_k_categorical_accuracy: 0.9298 - val_precision: 0.7986 - val_recall: 0.7734 - val_fmeasure: 0.7857\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0709 - acc: 0.9764 - top_k_categorical_accuracy: 0.9999 - precision: 0.9772 - recall: 0.9748 - fmeasure: 0.9760 - val_loss: 1.4598 - val_acc: 0.7922 - val_top_k_categorical_accuracy: 0.9343 - val_precision: 0.8089 - val_recall: 0.7871 - val_fmeasure: 0.7978\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0647 - acc: 0.9759 - top_k_categorical_accuracy: 1.0000 - precision: 0.9780 - recall: 0.9739 - fmeasure: 0.9759 - val_loss: 1.5393 - val_acc: 0.7874 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8065 - val_recall: 0.7824 - val_fmeasure: 0.7941\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0506 - acc: 0.9831 - top_k_categorical_accuracy: 1.0000 - precision: 0.9847 - recall: 0.9817 - fmeasure: 0.9832 - val_loss: 1.5654 - val_acc: 0.7871 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8044 - val_recall: 0.7838 - val_fmeasure: 0.7939\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0563 - acc: 0.9795 - top_k_categorical_accuracy: 1.0000 - precision: 0.9805 - recall: 0.9786 - fmeasure: 0.9795 - val_loss: 1.4750 - val_acc: 0.7942 - val_top_k_categorical_accuracy: 0.9304 - val_precision: 0.8134 - val_recall: 0.7899 - val_fmeasure: 0.8014\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0584 - acc: 0.9797 - top_k_categorical_accuracy: 1.0000 - precision: 0.9812 - recall: 0.9783 - fmeasure: 0.9797 - val_loss: 1.4131 - val_acc: 0.7942 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.8133 - val_recall: 0.7883 - val_fmeasure: 0.8005\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0500 - acc: 0.9822 - top_k_categorical_accuracy: 1.0000 - precision: 0.9832 - recall: 0.9810 - fmeasure: 0.9821 - val_loss: 1.4519 - val_acc: 0.7928 - val_top_k_categorical_accuracy: 0.9304 - val_precision: 0.8130 - val_recall: 0.7860 - val_fmeasure: 0.7992\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0522 - acc: 0.9811 - top_k_categorical_accuracy: 1.0000 - precision: 0.9831 - recall: 0.9798 - fmeasure: 0.9814 - val_loss: 1.5403 - val_acc: 0.7958 - val_top_k_categorical_accuracy: 0.9323 - val_precision: 0.8093 - val_recall: 0.7891 - val_fmeasure: 0.7990\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0642 - acc: 0.9781 - top_k_categorical_accuracy: 1.0000 - precision: 0.9798 - recall: 0.9771 - fmeasure: 0.9785 - val_loss: 1.5045 - val_acc: 0.7908 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.8099 - val_recall: 0.7838 - val_fmeasure: 0.7965\n",
            "mixup......\n",
            "When the process freezing, please check that datatype_Close has been set correctly\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 195us/step - loss: 3.5979 - acc: 0.1457 - top_k_categorical_accuracy: 0.3752 - precision: 0.3278 - recall: 0.0187 - fmeasure: 0.0343 - val_loss: 2.8320 - val_acc: 0.3013 - val_top_k_categorical_accuracy: 0.6582 - val_precision: 0.6964 - val_recall: 0.0640 - val_fmeasure: 0.1158\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 2.1910 - acc: 0.4656 - top_k_categorical_accuracy: 0.7604 - precision: 0.7922 - recall: 0.2273 - fmeasure: 0.3435 - val_loss: 1.9230 - val_acc: 0.5552 - val_top_k_categorical_accuracy: 0.8060 - val_precision: 0.8058 - val_recall: 0.3583 - val_fmeasure: 0.4940\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 1.5215 - acc: 0.6390 - top_k_categorical_accuracy: 0.8583 - precision: 0.8201 - recall: 0.4696 - fmeasure: 0.5945 - val_loss: 1.5959 - val_acc: 0.6271 - val_top_k_categorical_accuracy: 0.8590 - val_precision: 0.8082 - val_recall: 0.4912 - val_fmeasure: 0.6099\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 1.1892 - acc: 0.7084 - top_k_categorical_accuracy: 0.9020 - precision: 0.8448 - recall: 0.5895 - fmeasure: 0.6934 - val_loss: 1.4168 - val_acc: 0.6641 - val_top_k_categorical_accuracy: 0.8753 - val_precision: 0.8149 - val_recall: 0.5479 - val_fmeasure: 0.6538\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.9690 - acc: 0.7602 - top_k_categorical_accuracy: 0.9267 - precision: 0.8650 - recall: 0.6690 - fmeasure: 0.7531 - val_loss: 1.2614 - val_acc: 0.7077 - val_top_k_categorical_accuracy: 0.8975 - val_precision: 0.8310 - val_recall: 0.6240 - val_fmeasure: 0.7118\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.8102 - acc: 0.7848 - top_k_categorical_accuracy: 0.9473 - precision: 0.8746 - recall: 0.7164 - fmeasure: 0.7870 - val_loss: 1.2703 - val_acc: 0.6908 - val_top_k_categorical_accuracy: 0.8981 - val_precision: 0.7994 - val_recall: 0.6099 - val_fmeasure: 0.6912\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.6970 - acc: 0.8074 - top_k_categorical_accuracy: 0.9603 - precision: 0.8835 - recall: 0.7471 - fmeasure: 0.8089 - val_loss: 1.2215 - val_acc: 0.7251 - val_top_k_categorical_accuracy: 0.9070 - val_precision: 0.8127 - val_recall: 0.6630 - val_fmeasure: 0.7296\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.5977 - acc: 0.8363 - top_k_categorical_accuracy: 0.9670 - precision: 0.8959 - recall: 0.7850 - fmeasure: 0.8362 - val_loss: 1.2774 - val_acc: 0.7071 - val_top_k_categorical_accuracy: 0.9014 - val_precision: 0.7905 - val_recall: 0.6369 - val_fmeasure: 0.7050\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.5288 - acc: 0.8462 - top_k_categorical_accuracy: 0.9762 - precision: 0.8994 - recall: 0.8055 - fmeasure: 0.8494 - val_loss: 1.1882 - val_acc: 0.7377 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.8133 - val_recall: 0.6967 - val_fmeasure: 0.7500\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.4901 - acc: 0.8558 - top_k_categorical_accuracy: 0.9830 - precision: 0.9035 - recall: 0.8147 - fmeasure: 0.8564 - val_loss: 1.1838 - val_acc: 0.7329 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.8097 - val_recall: 0.6776 - val_fmeasure: 0.7372\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 108us/step - loss: 0.3996 - acc: 0.8797 - top_k_categorical_accuracy: 0.9898 - precision: 0.9177 - recall: 0.8482 - fmeasure: 0.8812 - val_loss: 1.2162 - val_acc: 0.7355 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7878 - val_recall: 0.7004 - val_fmeasure: 0.7411\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3594 - acc: 0.8836 - top_k_categorical_accuracy: 0.9907 - precision: 0.9173 - recall: 0.8560 - fmeasure: 0.8853 - val_loss: 1.2450 - val_acc: 0.7402 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.7988 - val_recall: 0.7102 - val_fmeasure: 0.7515\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3422 - acc: 0.8895 - top_k_categorical_accuracy: 0.9939 - precision: 0.9198 - recall: 0.8632 - fmeasure: 0.8904 - val_loss: 1.2102 - val_acc: 0.7577 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.8152 - val_recall: 0.7195 - val_fmeasure: 0.7639\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2896 - acc: 0.9084 - top_k_categorical_accuracy: 0.9953 - precision: 0.9310 - recall: 0.8827 - fmeasure: 0.9060 - val_loss: 1.3390 - val_acc: 0.7301 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7812 - val_recall: 0.6973 - val_fmeasure: 0.7364\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2923 - acc: 0.9029 - top_k_categorical_accuracy: 0.9961 - precision: 0.9257 - recall: 0.8803 - fmeasure: 0.9022 - val_loss: 1.2733 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7998 - val_recall: 0.7284 - val_fmeasure: 0.7622\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2621 - acc: 0.9156 - top_k_categorical_accuracy: 0.9972 - precision: 0.9358 - recall: 0.8972 - fmeasure: 0.9160 - val_loss: 1.3170 - val_acc: 0.7346 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.7860 - val_recall: 0.7004 - val_fmeasure: 0.7404\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2519 - acc: 0.9165 - top_k_categorical_accuracy: 0.9976 - precision: 0.9361 - recall: 0.8988 - fmeasure: 0.9169 - val_loss: 1.3891 - val_acc: 0.7380 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.7816 - val_recall: 0.7147 - val_fmeasure: 0.7464\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2449 - acc: 0.9221 - top_k_categorical_accuracy: 0.9982 - precision: 0.9387 - recall: 0.9062 - fmeasure: 0.9220 - val_loss: 1.3148 - val_acc: 0.7509 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7943 - val_recall: 0.7256 - val_fmeasure: 0.7581\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2071 - acc: 0.9275 - top_k_categorical_accuracy: 0.9996 - precision: 0.9440 - recall: 0.9144 - fmeasure: 0.9288 - val_loss: 1.2621 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9273 - val_precision: 0.8120 - val_recall: 0.7582 - val_fmeasure: 0.7839\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2018 - acc: 0.9346 - top_k_categorical_accuracy: 0.9993 - precision: 0.9473 - recall: 0.9227 - fmeasure: 0.9347 - val_loss: 1.4004 - val_acc: 0.7481 - val_top_k_categorical_accuracy: 0.9177 - val_precision: 0.7830 - val_recall: 0.7332 - val_fmeasure: 0.7571\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2097 - acc: 0.9266 - top_k_categorical_accuracy: 0.9986 - precision: 0.9416 - recall: 0.9124 - fmeasure: 0.9266 - val_loss: 1.3478 - val_acc: 0.7414 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.7844 - val_recall: 0.7209 - val_fmeasure: 0.7511\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 2.8637 - acc: 0.3665 - top_k_categorical_accuracy: 0.6009 - precision: 0.7280 - recall: 0.2027 - fmeasure: 0.3115 - val_loss: 1.4927 - val_acc: 0.6737 - val_top_k_categorical_accuracy: 0.8756 - val_precision: 0.8789 - val_recall: 0.4291 - val_fmeasure: 0.5745\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.4150 - acc: 0.8791 - top_k_categorical_accuracy: 0.9854 - precision: 0.9253 - recall: 0.8339 - fmeasure: 0.8750 - val_loss: 1.0541 - val_acc: 0.7762 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.8291 - val_recall: 0.7453 - val_fmeasure: 0.7845\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 2.2251 - acc: 0.4746 - top_k_categorical_accuracy: 0.7169 - precision: 0.7769 - recall: 0.3231 - fmeasure: 0.4531 - val_loss: 1.2941 - val_acc: 0.6990 - val_top_k_categorical_accuracy: 0.8947 - val_precision: 0.8609 - val_recall: 0.5254 - val_fmeasure: 0.6513\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.3833 - acc: 0.8859 - top_k_categorical_accuracy: 0.9893 - precision: 0.9233 - recall: 0.8431 - fmeasure: 0.8797 - val_loss: 1.0578 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8185 - val_recall: 0.7318 - val_fmeasure: 0.7723\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 1.9002 - acc: 0.5397 - top_k_categorical_accuracy: 0.7703 - precision: 0.7967 - recall: 0.3997 - fmeasure: 0.5303 - val_loss: 1.3299 - val_acc: 0.6728 - val_top_k_categorical_accuracy: 0.8882 - val_precision: 0.8196 - val_recall: 0.5465 - val_fmeasure: 0.6537\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3699 - acc: 0.8871 - top_k_categorical_accuracy: 0.9901 - precision: 0.9237 - recall: 0.8495 - fmeasure: 0.8840 - val_loss: 1.0117 - val_acc: 0.7978 - val_top_k_categorical_accuracy: 0.9323 - val_precision: 0.8381 - val_recall: 0.7720 - val_fmeasure: 0.8033\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 1.6489 - acc: 0.5851 - top_k_categorical_accuracy: 0.8120 - precision: 0.8169 - recall: 0.4626 - fmeasure: 0.5889 - val_loss: 1.2307 - val_acc: 0.7077 - val_top_k_categorical_accuracy: 0.8986 - val_precision: 0.8474 - val_recall: 0.5869 - val_fmeasure: 0.6921\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.3317 - acc: 0.8973 - top_k_categorical_accuracy: 0.9936 - precision: 0.9249 - recall: 0.8652 - fmeasure: 0.8934 - val_loss: 1.0426 - val_acc: 0.7748 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.8302 - val_recall: 0.7459 - val_fmeasure: 0.7854\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 1.4550 - acc: 0.6221 - top_k_categorical_accuracy: 0.8435 - precision: 0.8293 - recall: 0.5114 - fmeasure: 0.6309 - val_loss: 1.1008 - val_acc: 0.7461 - val_top_k_categorical_accuracy: 0.9135 - val_precision: 0.8610 - val_recall: 0.6417 - val_fmeasure: 0.7342\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 109us/step - loss: 0.3076 - acc: 0.9003 - top_k_categorical_accuracy: 0.9934 - precision: 0.9268 - recall: 0.8743 - fmeasure: 0.8992 - val_loss: 1.0016 - val_acc: 0.7916 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.8334 - val_recall: 0.7742 - val_fmeasure: 0.8025\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 1.2931 - acc: 0.6595 - top_k_categorical_accuracy: 0.8707 - precision: 0.8412 - recall: 0.5540 - fmeasure: 0.6665 - val_loss: 1.1118 - val_acc: 0.7383 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.8483 - val_recall: 0.6633 - val_fmeasure: 0.7437\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2778 - acc: 0.9103 - top_k_categorical_accuracy: 0.9961 - precision: 0.9316 - recall: 0.8873 - fmeasure: 0.9086 - val_loss: 1.0207 - val_acc: 0.7930 - val_top_k_categorical_accuracy: 0.9385 - val_precision: 0.8308 - val_recall: 0.7711 - val_fmeasure: 0.7996\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 1.1462 - acc: 0.6888 - top_k_categorical_accuracy: 0.8924 - precision: 0.8496 - recall: 0.5896 - fmeasure: 0.6948 - val_loss: 1.1305 - val_acc: 0.7228 - val_top_k_categorical_accuracy: 0.9073 - val_precision: 0.8250 - val_recall: 0.6546 - val_fmeasure: 0.7293\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2547 - acc: 0.9148 - top_k_categorical_accuracy: 0.9958 - precision: 0.9371 - recall: 0.8959 - fmeasure: 0.9157 - val_loss: 1.0550 - val_acc: 0.7832 - val_top_k_categorical_accuracy: 0.9371 - val_precision: 0.8221 - val_recall: 0.7641 - val_fmeasure: 0.7919\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 1.0023 - acc: 0.7206 - top_k_categorical_accuracy: 0.9128 - precision: 0.8627 - recall: 0.6333 - fmeasure: 0.7293 - val_loss: 1.0841 - val_acc: 0.7518 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.8408 - val_recall: 0.6858 - val_fmeasure: 0.7546\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.2342 - acc: 0.9210 - top_k_categorical_accuracy: 0.9969 - precision: 0.9384 - recall: 0.9035 - fmeasure: 0.9203 - val_loss: 1.0550 - val_acc: 0.8023 - val_top_k_categorical_accuracy: 0.9379 - val_precision: 0.8372 - val_recall: 0.7852 - val_fmeasure: 0.8101\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.8743 - acc: 0.7516 - top_k_categorical_accuracy: 0.9298 - precision: 0.8744 - recall: 0.6742 - fmeasure: 0.7604 - val_loss: 1.1890 - val_acc: 0.7405 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.8179 - val_recall: 0.6891 - val_fmeasure: 0.7474\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.2227 - acc: 0.9240 - top_k_categorical_accuracy: 0.9986 - precision: 0.9374 - recall: 0.9088 - fmeasure: 0.9227 - val_loss: 1.0776 - val_acc: 0.7972 - val_top_k_categorical_accuracy: 0.9405 - val_precision: 0.8301 - val_recall: 0.7832 - val_fmeasure: 0.8058\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.7650 - acc: 0.7779 - top_k_categorical_accuracy: 0.9461 - precision: 0.8829 - recall: 0.7068 - fmeasure: 0.7843 - val_loss: 1.1629 - val_acc: 0.7400 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.8187 - val_recall: 0.6984 - val_fmeasure: 0.7532\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2045 - acc: 0.9311 - top_k_categorical_accuracy: 0.9987 - precision: 0.9443 - recall: 0.9210 - fmeasure: 0.9323 - val_loss: 1.0863 - val_acc: 0.7916 - val_top_k_categorical_accuracy: 0.9391 - val_precision: 0.8263 - val_recall: 0.7759 - val_fmeasure: 0.8002\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.6683 - acc: 0.8039 - top_k_categorical_accuracy: 0.9565 - precision: 0.8910 - recall: 0.7397 - fmeasure: 0.8076 - val_loss: 1.2683 - val_acc: 0.7377 - val_top_k_categorical_accuracy: 0.9101 - val_precision: 0.8013 - val_recall: 0.7051 - val_fmeasure: 0.7497\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1935 - acc: 0.9326 - top_k_categorical_accuracy: 0.9988 - precision: 0.9432 - recall: 0.9222 - fmeasure: 0.9325 - val_loss: 1.0838 - val_acc: 0.7857 - val_top_k_categorical_accuracy: 0.9388 - val_precision: 0.8220 - val_recall: 0.7723 - val_fmeasure: 0.7962\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.5856 - acc: 0.8254 - top_k_categorical_accuracy: 0.9644 - precision: 0.9013 - recall: 0.7700 - fmeasure: 0.8299 - val_loss: 1.2980 - val_acc: 0.7430 - val_top_k_categorical_accuracy: 0.9177 - val_precision: 0.7981 - val_recall: 0.7113 - val_fmeasure: 0.7519\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.2000 - acc: 0.9307 - top_k_categorical_accuracy: 0.9984 - precision: 0.9406 - recall: 0.9216 - fmeasure: 0.9309 - val_loss: 1.2400 - val_acc: 0.7812 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8128 - val_recall: 0.7683 - val_fmeasure: 0.7898\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.5179 - acc: 0.8442 - top_k_categorical_accuracy: 0.9722 - precision: 0.9095 - recall: 0.7960 - fmeasure: 0.8484 - val_loss: 1.3273 - val_acc: 0.7456 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7931 - val_recall: 0.7175 - val_fmeasure: 0.7531\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.2118 - acc: 0.9281 - top_k_categorical_accuracy: 0.9982 - precision: 0.9394 - recall: 0.9197 - fmeasure: 0.9293 - val_loss: 1.1519 - val_acc: 0.8006 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8296 - val_recall: 0.7894 - val_fmeasure: 0.8088\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.4456 - acc: 0.8658 - top_k_categorical_accuracy: 0.9768 - precision: 0.9194 - recall: 0.8240 - fmeasure: 0.8686 - val_loss: 1.3497 - val_acc: 0.7450 - val_top_k_categorical_accuracy: 0.9099 - val_precision: 0.8018 - val_recall: 0.7228 - val_fmeasure: 0.7600\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1928 - acc: 0.9328 - top_k_categorical_accuracy: 0.9993 - precision: 0.9431 - recall: 0.9231 - fmeasure: 0.9329 - val_loss: 1.2095 - val_acc: 0.7919 - val_top_k_categorical_accuracy: 0.9343 - val_precision: 0.8168 - val_recall: 0.7793 - val_fmeasure: 0.7974\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.4078 - acc: 0.8731 - top_k_categorical_accuracy: 0.9825 - precision: 0.9226 - recall: 0.8361 - fmeasure: 0.8769 - val_loss: 1.4386 - val_acc: 0.7360 - val_top_k_categorical_accuracy: 0.9076 - val_precision: 0.7897 - val_recall: 0.7127 - val_fmeasure: 0.7488\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1860 - acc: 0.9385 - top_k_categorical_accuracy: 0.9990 - precision: 0.9461 - recall: 0.9316 - fmeasure: 0.9388 - val_loss: 1.2233 - val_acc: 0.7984 - val_top_k_categorical_accuracy: 0.9368 - val_precision: 0.8268 - val_recall: 0.7880 - val_fmeasure: 0.8068\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.3621 - acc: 0.8884 - top_k_categorical_accuracy: 0.9846 - precision: 0.9306 - recall: 0.8551 - fmeasure: 0.8909 - val_loss: 1.3678 - val_acc: 0.7506 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7976 - val_recall: 0.7363 - val_fmeasure: 0.7656\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1734 - acc: 0.9428 - top_k_categorical_accuracy: 0.9988 - precision: 0.9496 - recall: 0.9384 - fmeasure: 0.9439 - val_loss: 1.3225 - val_acc: 0.7840 - val_top_k_categorical_accuracy: 0.9312 - val_precision: 0.8102 - val_recall: 0.7720 - val_fmeasure: 0.7905\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.3351 - acc: 0.8960 - top_k_categorical_accuracy: 0.9866 - precision: 0.9325 - recall: 0.8689 - fmeasure: 0.8993 - val_loss: 1.4263 - val_acc: 0.7433 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7857 - val_recall: 0.7248 - val_fmeasure: 0.7538\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1699 - acc: 0.9458 - top_k_categorical_accuracy: 0.9987 - precision: 0.9535 - recall: 0.9402 - fmeasure: 0.9467 - val_loss: 1.3380 - val_acc: 0.7753 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.8055 - val_recall: 0.7644 - val_fmeasure: 0.7843\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.3051 - acc: 0.9075 - top_k_categorical_accuracy: 0.9883 - precision: 0.9398 - recall: 0.8821 - fmeasure: 0.9098 - val_loss: 1.4273 - val_acc: 0.7607 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7952 - val_recall: 0.7518 - val_fmeasure: 0.7727\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 108us/step - loss: 0.1450 - acc: 0.9502 - top_k_categorical_accuracy: 0.9996 - precision: 0.9559 - recall: 0.9451 - fmeasure: 0.9504 - val_loss: 1.2629 - val_acc: 0.7953 - val_top_k_categorical_accuracy: 0.9363 - val_precision: 0.8210 - val_recall: 0.7855 - val_fmeasure: 0.8026\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 100us/step - loss: 0.2623 - acc: 0.9195 - top_k_categorical_accuracy: 0.9913 - precision: 0.9457 - recall: 0.8990 - fmeasure: 0.9215 - val_loss: 1.5367 - val_acc: 0.7523 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.7889 - val_recall: 0.7377 - val_fmeasure: 0.7623\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1361 - acc: 0.9543 - top_k_categorical_accuracy: 0.9996 - precision: 0.9596 - recall: 0.9494 - fmeasure: 0.9545 - val_loss: 1.4082 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9301 - val_precision: 0.8014 - val_recall: 0.7692 - val_fmeasure: 0.7849\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.2580 - acc: 0.9204 - top_k_categorical_accuracy: 0.9927 - precision: 0.9454 - recall: 0.9005 - fmeasure: 0.9222 - val_loss: 1.5180 - val_acc: 0.7523 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.7888 - val_recall: 0.7377 - val_fmeasure: 0.7622\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1522 - acc: 0.9456 - top_k_categorical_accuracy: 0.9993 - precision: 0.9525 - recall: 0.9409 - fmeasure: 0.9466 - val_loss: 1.3788 - val_acc: 0.7883 - val_top_k_categorical_accuracy: 0.9365 - val_precision: 0.8103 - val_recall: 0.7804 - val_fmeasure: 0.7949\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2242 - acc: 0.9297 - top_k_categorical_accuracy: 0.9937 - precision: 0.9501 - recall: 0.9137 - fmeasure: 0.9314 - val_loss: 1.4910 - val_acc: 0.7652 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7925 - val_recall: 0.7571 - val_fmeasure: 0.7743\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.1407 - acc: 0.9511 - top_k_categorical_accuracy: 0.9995 - precision: 0.9567 - recall: 0.9479 - fmeasure: 0.9522 - val_loss: 1.3646 - val_acc: 0.7950 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8153 - val_recall: 0.7863 - val_fmeasure: 0.8004\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.2114 - acc: 0.9352 - top_k_categorical_accuracy: 0.9937 - precision: 0.9540 - recall: 0.9200 - fmeasure: 0.9365 - val_loss: 1.5292 - val_acc: 0.7664 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.8012 - val_recall: 0.7548 - val_fmeasure: 0.7772\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1304 - acc: 0.9552 - top_k_categorical_accuracy: 1.0000 - precision: 0.9599 - recall: 0.9509 - fmeasure: 0.9553 - val_loss: 1.3864 - val_acc: 0.7905 - val_top_k_categorical_accuracy: 0.9312 - val_precision: 0.8081 - val_recall: 0.7826 - val_fmeasure: 0.7951\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1937 - acc: 0.9396 - top_k_categorical_accuracy: 0.9947 - precision: 0.9564 - recall: 0.9270 - fmeasure: 0.9413 - val_loss: 1.5348 - val_acc: 0.7621 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7937 - val_recall: 0.7498 - val_fmeasure: 0.7710\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1264 - acc: 0.9562 - top_k_categorical_accuracy: 0.9999 - precision: 0.9614 - recall: 0.9523 - fmeasure: 0.9568 - val_loss: 1.4087 - val_acc: 0.7914 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8109 - val_recall: 0.7835 - val_fmeasure: 0.7968\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1948 - acc: 0.9380 - top_k_categorical_accuracy: 0.9953 - precision: 0.9545 - recall: 0.9253 - fmeasure: 0.9396 - val_loss: 1.6558 - val_acc: 0.7386 - val_top_k_categorical_accuracy: 0.9085 - val_precision: 0.7695 - val_recall: 0.7262 - val_fmeasure: 0.7470\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.1432 - acc: 0.9512 - top_k_categorical_accuracy: 0.9996 - precision: 0.9561 - recall: 0.9480 - fmeasure: 0.9520 - val_loss: 1.4495 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9292 - val_precision: 0.7974 - val_recall: 0.7717 - val_fmeasure: 0.7842\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1750 - acc: 0.9444 - top_k_categorical_accuracy: 0.9952 - precision: 0.9595 - recall: 0.9350 - fmeasure: 0.9469 - val_loss: 1.5314 - val_acc: 0.7753 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8011 - val_recall: 0.7624 - val_fmeasure: 0.7812\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1096 - acc: 0.9627 - top_k_categorical_accuracy: 0.9995 - precision: 0.9671 - recall: 0.9582 - fmeasure: 0.9626 - val_loss: 1.4718 - val_acc: 0.7793 - val_top_k_categorical_accuracy: 0.9304 - val_precision: 0.8034 - val_recall: 0.7697 - val_fmeasure: 0.7861\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 97us/step - loss: 0.1625 - acc: 0.9480 - top_k_categorical_accuracy: 0.9960 - precision: 0.9604 - recall: 0.9380 - fmeasure: 0.9490 - val_loss: 1.6304 - val_acc: 0.7557 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.7850 - val_recall: 0.7484 - val_fmeasure: 0.7661\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1589 - acc: 0.9516 - top_k_categorical_accuracy: 0.9988 - precision: 0.9556 - recall: 0.9478 - fmeasure: 0.9516 - val_loss: 1.4539 - val_acc: 0.7972 - val_top_k_categorical_accuracy: 0.9320 - val_precision: 0.8127 - val_recall: 0.7894 - val_fmeasure: 0.8008\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1542 - acc: 0.9529 - top_k_categorical_accuracy: 0.9964 - precision: 0.9643 - recall: 0.9436 - fmeasure: 0.9538 - val_loss: 1.6184 - val_acc: 0.7610 - val_top_k_categorical_accuracy: 0.9186 - val_precision: 0.7837 - val_recall: 0.7506 - val_fmeasure: 0.7667\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1107 - acc: 0.9648 - top_k_categorical_accuracy: 0.9996 - precision: 0.9683 - recall: 0.9627 - fmeasure: 0.9654 - val_loss: 1.5118 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8015 - val_recall: 0.7686 - val_fmeasure: 0.7846\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 98us/step - loss: 0.1497 - acc: 0.9529 - top_k_categorical_accuracy: 0.9963 - precision: 0.9646 - recall: 0.9439 - fmeasure: 0.9541 - val_loss: 1.6200 - val_acc: 0.7568 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7762 - val_recall: 0.7473 - val_fmeasure: 0.7613\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.1070 - acc: 0.9636 - top_k_categorical_accuracy: 1.0000 - precision: 0.9666 - recall: 0.9605 - fmeasure: 0.9635 - val_loss: 1.4990 - val_acc: 0.7916 - val_top_k_categorical_accuracy: 0.9354 - val_precision: 0.8103 - val_recall: 0.7860 - val_fmeasure: 0.7979\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1578 - acc: 0.9512 - top_k_categorical_accuracy: 0.9964 - precision: 0.9636 - recall: 0.9431 - fmeasure: 0.9531 - val_loss: 1.6078 - val_acc: 0.7666 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.7932 - val_recall: 0.7579 - val_fmeasure: 0.7750\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1130 - acc: 0.9626 - top_k_categorical_accuracy: 1.0000 - precision: 0.9653 - recall: 0.9600 - fmeasure: 0.9627 - val_loss: 1.5146 - val_acc: 0.7894 - val_top_k_categorical_accuracy: 0.9337 - val_precision: 0.8034 - val_recall: 0.7812 - val_fmeasure: 0.7921\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 2s 99us/step - loss: 0.1042 - acc: 0.9689 - top_k_categorical_accuracy: 0.9974 - precision: 0.9763 - recall: 0.9633 - fmeasure: 0.9697 - val_loss: 1.6745 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.7841 - val_recall: 0.7534 - val_fmeasure: 0.7683\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.1156 - acc: 0.9622 - top_k_categorical_accuracy: 0.9998 - precision: 0.9653 - recall: 0.9602 - fmeasure: 0.9627 - val_loss: 1.5651 - val_acc: 0.7880 - val_top_k_categorical_accuracy: 0.9323 - val_precision: 0.8043 - val_recall: 0.7832 - val_fmeasure: 0.7935\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 109us/step - loss: 0.0755 - acc: 0.9764 - top_k_categorical_accuracy: 0.9998 - precision: 0.9786 - recall: 0.9750 - fmeasure: 0.9768 - val_loss: 1.4596 - val_acc: 0.7891 - val_top_k_categorical_accuracy: 0.9379 - val_precision: 0.8040 - val_recall: 0.7832 - val_fmeasure: 0.7934\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0891 - acc: 0.9687 - top_k_categorical_accuracy: 0.9999 - precision: 0.9713 - recall: 0.9673 - fmeasure: 0.9693 - val_loss: 1.4627 - val_acc: 0.7944 - val_top_k_categorical_accuracy: 0.9388 - val_precision: 0.8088 - val_recall: 0.7860 - val_fmeasure: 0.7972\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0714 - acc: 0.9758 - top_k_categorical_accuracy: 0.9996 - precision: 0.9777 - recall: 0.9741 - fmeasure: 0.9759 - val_loss: 1.5326 - val_acc: 0.7860 - val_top_k_categorical_accuracy: 0.9343 - val_precision: 0.8011 - val_recall: 0.7796 - val_fmeasure: 0.7901\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0709 - acc: 0.9759 - top_k_categorical_accuracy: 1.0000 - precision: 0.9781 - recall: 0.9740 - fmeasure: 0.9760 - val_loss: 1.4474 - val_acc: 0.8034 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.8187 - val_recall: 0.7975 - val_fmeasure: 0.8079\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0694 - acc: 0.9765 - top_k_categorical_accuracy: 0.9999 - precision: 0.9788 - recall: 0.9746 - fmeasure: 0.9767 - val_loss: 1.5156 - val_acc: 0.7911 - val_top_k_categorical_accuracy: 0.9363 - val_precision: 0.8039 - val_recall: 0.7838 - val_fmeasure: 0.7936\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0605 - acc: 0.9782 - top_k_categorical_accuracy: 1.0000 - precision: 0.9799 - recall: 0.9763 - fmeasure: 0.9781 - val_loss: 1.4983 - val_acc: 0.7928 - val_top_k_categorical_accuracy: 0.9365 - val_precision: 0.8132 - val_recall: 0.7869 - val_fmeasure: 0.7997\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0613 - acc: 0.9786 - top_k_categorical_accuracy: 1.0000 - precision: 0.9806 - recall: 0.9775 - fmeasure: 0.9790 - val_loss: 1.4182 - val_acc: 0.7939 - val_top_k_categorical_accuracy: 0.9377 - val_precision: 0.8129 - val_recall: 0.7880 - val_fmeasure: 0.8001\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0713 - acc: 0.9751 - top_k_categorical_accuracy: 1.0000 - precision: 0.9769 - recall: 0.9729 - fmeasure: 0.9749 - val_loss: 1.5852 - val_acc: 0.7798 - val_top_k_categorical_accuracy: 0.9292 - val_precision: 0.7931 - val_recall: 0.7723 - val_fmeasure: 0.7825\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0634 - acc: 0.9795 - top_k_categorical_accuracy: 0.9999 - precision: 0.9815 - recall: 0.9781 - fmeasure: 0.9798 - val_loss: 1.5249 - val_acc: 0.7939 - val_top_k_categorical_accuracy: 0.9382 - val_precision: 0.8074 - val_recall: 0.7888 - val_fmeasure: 0.7979\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0566 - acc: 0.9813 - top_k_categorical_accuracy: 0.9999 - precision: 0.9824 - recall: 0.9797 - fmeasure: 0.9810 - val_loss: 1.5330 - val_acc: 0.7944 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8075 - val_recall: 0.7897 - val_fmeasure: 0.7984\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0728 - acc: 0.9757 - top_k_categorical_accuracy: 0.9999 - precision: 0.9780 - recall: 0.9746 - fmeasure: 0.9763 - val_loss: 1.5054 - val_acc: 0.7849 - val_top_k_categorical_accuracy: 0.9315 - val_precision: 0.8018 - val_recall: 0.7784 - val_fmeasure: 0.7899\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0547 - acc: 0.9821 - top_k_categorical_accuracy: 0.9999 - precision: 0.9833 - recall: 0.9804 - fmeasure: 0.9818 - val_loss: 1.5175 - val_acc: 0.7911 - val_top_k_categorical_accuracy: 0.9365 - val_precision: 0.8039 - val_recall: 0.7849 - val_fmeasure: 0.7942\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0558 - acc: 0.9815 - top_k_categorical_accuracy: 0.9999 - precision: 0.9824 - recall: 0.9805 - fmeasure: 0.9814 - val_loss: 1.4430 - val_acc: 0.7911 - val_top_k_categorical_accuracy: 0.9340 - val_precision: 0.8082 - val_recall: 0.7826 - val_fmeasure: 0.7951\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0443 - acc: 0.9845 - top_k_categorical_accuracy: 1.0000 - precision: 0.9859 - recall: 0.9835 - fmeasure: 0.9847 - val_loss: 1.4987 - val_acc: 0.8020 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8195 - val_recall: 0.7972 - val_fmeasure: 0.8081\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0502 - acc: 0.9824 - top_k_categorical_accuracy: 1.0000 - precision: 0.9835 - recall: 0.9811 - fmeasure: 0.9823 - val_loss: 1.4538 - val_acc: 0.7975 - val_top_k_categorical_accuracy: 0.9382 - val_precision: 0.8110 - val_recall: 0.7930 - val_fmeasure: 0.8018\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.0520 - acc: 0.9830 - top_k_categorical_accuracy: 0.9999 - precision: 0.9843 - recall: 0.9822 - fmeasure: 0.9832 - val_loss: 1.5729 - val_acc: 0.7765 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.7969 - val_recall: 0.7709 - val_fmeasure: 0.7835\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 118us/step - loss: 0.0568 - acc: 0.9811 - top_k_categorical_accuracy: 0.9998 - precision: 0.9822 - recall: 0.9800 - fmeasure: 0.9811 - val_loss: 1.4760 - val_acc: 0.7978 - val_top_k_categorical_accuracy: 0.9363 - val_precision: 0.8156 - val_recall: 0.7908 - val_fmeasure: 0.8029\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0500 - acc: 0.9819 - top_k_categorical_accuracy: 1.0000 - precision: 0.9838 - recall: 0.9806 - fmeasure: 0.9822 - val_loss: 1.4590 - val_acc: 0.7975 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.8142 - val_recall: 0.7944 - val_fmeasure: 0.8041\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0510 - acc: 0.9839 - top_k_categorical_accuracy: 1.0000 - precision: 0.9853 - recall: 0.9822 - fmeasure: 0.9837 - val_loss: 1.5500 - val_acc: 0.7860 - val_top_k_categorical_accuracy: 0.9326 - val_precision: 0.8046 - val_recall: 0.7793 - val_fmeasure: 0.7916\n",
            "the shape of x_train (8307, 5000)\n",
            "the shape of y_train (8307, 108)\n",
            "the shape of x_test (3561, 5000)\n",
            "the shape of y_test (3561, 108)\n",
            "base_line_now#######################################################################################################################################################################################################\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/100\n",
            "8307/8307 [==============================] - 2s 205us/step - loss: 3.6317 - acc: 0.1386 - top_k_categorical_accuracy: 0.3745 - precision: 0.2632 - recall: 0.0123 - fmeasure: 0.0229 - val_loss: 2.9392 - val_acc: 0.2628 - val_top_k_categorical_accuracy: 0.6052 - val_precision: 0.6595 - val_recall: 0.0812 - val_fmeasure: 0.1434\n",
            "Epoch 2/100\n",
            "8307/8307 [==============================] - 1s 122us/step - loss: 2.2446 - acc: 0.4497 - top_k_categorical_accuracy: 0.7488 - precision: 0.7653 - recall: 0.2176 - fmeasure: 0.3292 - val_loss: 1.9381 - val_acc: 0.5372 - val_top_k_categorical_accuracy: 0.8071 - val_precision: 0.8002 - val_recall: 0.3589 - val_fmeasure: 0.4936\n",
            "Epoch 3/100\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 1.5447 - acc: 0.6213 - top_k_categorical_accuracy: 0.8554 - precision: 0.8173 - recall: 0.4538 - fmeasure: 0.5810 - val_loss: 1.6537 - val_acc: 0.6231 - val_top_k_categorical_accuracy: 0.8422 - val_precision: 0.8103 - val_recall: 0.4538 - val_fmeasure: 0.5802\n",
            "Epoch 4/100\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 1.1963 - acc: 0.7084 - top_k_categorical_accuracy: 0.8995 - precision: 0.8435 - recall: 0.5889 - fmeasure: 0.6922 - val_loss: 1.4048 - val_acc: 0.6745 - val_top_k_categorical_accuracy: 0.8767 - val_precision: 0.8240 - val_recall: 0.5524 - val_fmeasure: 0.6602\n",
            "Epoch 5/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.9874 - acc: 0.7489 - top_k_categorical_accuracy: 0.9280 - precision: 0.8571 - recall: 0.6610 - fmeasure: 0.7454 - val_loss: 1.3612 - val_acc: 0.6942 - val_top_k_categorical_accuracy: 0.8849 - val_precision: 0.8203 - val_recall: 0.6083 - val_fmeasure: 0.6976\n",
            "Epoch 6/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.8210 - acc: 0.7830 - top_k_categorical_accuracy: 0.9496 - precision: 0.8712 - recall: 0.7063 - fmeasure: 0.7794 - val_loss: 1.3069 - val_acc: 0.6967 - val_top_k_categorical_accuracy: 0.8955 - val_precision: 0.7949 - val_recall: 0.6243 - val_fmeasure: 0.6986\n",
            "Epoch 7/100\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.6861 - acc: 0.8111 - top_k_categorical_accuracy: 0.9590 - precision: 0.8834 - recall: 0.7535 - fmeasure: 0.8126 - val_loss: 1.1732 - val_acc: 0.7470 - val_top_k_categorical_accuracy: 0.9059 - val_precision: 0.8382 - val_recall: 0.6773 - val_fmeasure: 0.7486\n",
            "Epoch 8/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.6133 - acc: 0.8258 - top_k_categorical_accuracy: 0.9695 - precision: 0.8921 - recall: 0.7757 - fmeasure: 0.8294 - val_loss: 1.2754 - val_acc: 0.7138 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.7988 - val_recall: 0.6594 - val_fmeasure: 0.7220\n",
            "Epoch 9/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.5439 - acc: 0.8463 - top_k_categorical_accuracy: 0.9757 - precision: 0.9006 - recall: 0.8017 - fmeasure: 0.8479 - val_loss: 1.1840 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9079 - val_precision: 0.8270 - val_recall: 0.6984 - val_fmeasure: 0.7568\n",
            "Epoch 10/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.4698 - acc: 0.8602 - top_k_categorical_accuracy: 0.9827 - precision: 0.9048 - recall: 0.8214 - fmeasure: 0.8606 - val_loss: 1.1861 - val_acc: 0.7450 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.8131 - val_recall: 0.7029 - val_fmeasure: 0.7537\n",
            "Epoch 11/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.4182 - acc: 0.8675 - top_k_categorical_accuracy: 0.9871 - precision: 0.9070 - recall: 0.8342 - fmeasure: 0.8688 - val_loss: 1.2295 - val_acc: 0.7408 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7957 - val_recall: 0.7099 - val_fmeasure: 0.7500\n",
            "Epoch 12/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.3731 - acc: 0.8829 - top_k_categorical_accuracy: 0.9905 - precision: 0.9175 - recall: 0.8534 - fmeasure: 0.8840 - val_loss: 1.3178 - val_acc: 0.7279 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.7846 - val_recall: 0.6903 - val_fmeasure: 0.7341\n",
            "Epoch 13/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.3365 - acc: 0.8972 - top_k_categorical_accuracy: 0.9939 - precision: 0.9229 - recall: 0.8705 - fmeasure: 0.8957 - val_loss: 1.3959 - val_acc: 0.7237 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.7798 - val_recall: 0.6984 - val_fmeasure: 0.7366\n",
            "Epoch 14/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.3045 - acc: 0.9001 - top_k_categorical_accuracy: 0.9954 - precision: 0.9240 - recall: 0.8773 - fmeasure: 0.8999 - val_loss: 1.4268 - val_acc: 0.7211 - val_top_k_categorical_accuracy: 0.9056 - val_precision: 0.7666 - val_recall: 0.6945 - val_fmeasure: 0.7285\n",
            "Epoch 15/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2999 - acc: 0.9021 - top_k_categorical_accuracy: 0.9974 - precision: 0.9245 - recall: 0.8825 - fmeasure: 0.9028 - val_loss: 1.3797 - val_acc: 0.7299 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7796 - val_recall: 0.7043 - val_fmeasure: 0.7398\n",
            "Epoch 16/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2692 - acc: 0.9106 - top_k_categorical_accuracy: 0.9974 - precision: 0.9309 - recall: 0.8920 - fmeasure: 0.9109 - val_loss: 1.3462 - val_acc: 0.7405 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7862 - val_recall: 0.7116 - val_fmeasure: 0.7467\n",
            "Epoch 17/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.2345 - acc: 0.9227 - top_k_categorical_accuracy: 0.9982 - precision: 0.9374 - recall: 0.9069 - fmeasure: 0.9218 - val_loss: 1.3560 - val_acc: 0.7588 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.7995 - val_recall: 0.7377 - val_fmeasure: 0.7670\n",
            "Epoch 18/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.2300 - acc: 0.9216 - top_k_categorical_accuracy: 0.9981 - precision: 0.9379 - recall: 0.9067 - fmeasure: 0.9219 - val_loss: 1.4107 - val_acc: 0.7324 - val_top_k_categorical_accuracy: 0.9113 - val_precision: 0.7805 - val_recall: 0.7088 - val_fmeasure: 0.7426\n",
            "Epoch 19/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.2208 - acc: 0.9274 - top_k_categorical_accuracy: 0.9988 - precision: 0.9441 - recall: 0.9125 - fmeasure: 0.9279 - val_loss: 1.4192 - val_acc: 0.7430 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7833 - val_recall: 0.7223 - val_fmeasure: 0.7513\n",
            "Epoch 20/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1944 - acc: 0.9350 - top_k_categorical_accuracy: 0.9993 - precision: 0.9462 - recall: 0.9224 - fmeasure: 0.9340 - val_loss: 1.5064 - val_acc: 0.7217 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.7629 - val_recall: 0.7029 - val_fmeasure: 0.7314\n",
            "Epoch 21/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1822 - acc: 0.9374 - top_k_categorical_accuracy: 0.9998 - precision: 0.9491 - recall: 0.9273 - fmeasure: 0.9380 - val_loss: 1.4756 - val_acc: 0.7270 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7651 - val_recall: 0.7091 - val_fmeasure: 0.7358\n",
            "Epoch 22/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.1920 - acc: 0.9354 - top_k_categorical_accuracy: 0.9994 - precision: 0.9468 - recall: 0.9250 - fmeasure: 0.9357 - val_loss: 1.4117 - val_acc: 0.7450 - val_top_k_categorical_accuracy: 0.9155 - val_precision: 0.7794 - val_recall: 0.7290 - val_fmeasure: 0.7532\n",
            "Epoch 23/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.1488 - acc: 0.9470 - top_k_categorical_accuracy: 0.9994 - precision: 0.9563 - recall: 0.9390 - fmeasure: 0.9475 - val_loss: 1.4526 - val_acc: 0.7593 - val_top_k_categorical_accuracy: 0.9155 - val_precision: 0.7891 - val_recall: 0.7459 - val_fmeasure: 0.7668\n",
            "Epoch 24/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1540 - acc: 0.9480 - top_k_categorical_accuracy: 0.9998 - precision: 0.9561 - recall: 0.9409 - fmeasure: 0.9483 - val_loss: 1.4169 - val_acc: 0.7599 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.7944 - val_recall: 0.7453 - val_fmeasure: 0.7689\n",
            "Epoch 25/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.1618 - acc: 0.9444 - top_k_categorical_accuracy: 0.9999 - precision: 0.9538 - recall: 0.9369 - fmeasure: 0.9452 - val_loss: 1.4535 - val_acc: 0.7577 - val_top_k_categorical_accuracy: 0.9155 - val_precision: 0.7901 - val_recall: 0.7442 - val_fmeasure: 0.7662\n",
            "Epoch 26/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1741 - acc: 0.9404 - top_k_categorical_accuracy: 0.9994 - precision: 0.9485 - recall: 0.9295 - fmeasure: 0.9388 - val_loss: 1.5118 - val_acc: 0.7498 - val_top_k_categorical_accuracy: 0.9177 - val_precision: 0.7805 - val_recall: 0.7360 - val_fmeasure: 0.7575\n",
            "Epoch 27/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.1321 - acc: 0.9549 - top_k_categorical_accuracy: 1.0000 - precision: 0.9594 - recall: 0.9482 - fmeasure: 0.9538 - val_loss: 1.4938 - val_acc: 0.7543 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7858 - val_recall: 0.7422 - val_fmeasure: 0.7632\n",
            "Epoch 28/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.1340 - acc: 0.9540 - top_k_categorical_accuracy: 0.9998 - precision: 0.9618 - recall: 0.9466 - fmeasure: 0.9540 - val_loss: 1.6433 - val_acc: 0.7380 - val_top_k_categorical_accuracy: 0.9034 - val_precision: 0.7702 - val_recall: 0.7223 - val_fmeasure: 0.7453\n",
            "Epoch 29/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1313 - acc: 0.9537 - top_k_categorical_accuracy: 0.9999 - precision: 0.9600 - recall: 0.9484 - fmeasure: 0.9541 - val_loss: 1.4909 - val_acc: 0.7678 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7916 - val_recall: 0.7543 - val_fmeasure: 0.7723\n",
            "Epoch 30/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.1086 - acc: 0.9638 - top_k_categorical_accuracy: 0.9996 - precision: 0.9692 - recall: 0.9591 - fmeasure: 0.9641 - val_loss: 1.5545 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9186 - val_precision: 0.7788 - val_recall: 0.7456 - val_fmeasure: 0.7617\n",
            "Epoch 31/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.1106 - acc: 0.9622 - top_k_categorical_accuracy: 0.9999 - precision: 0.9659 - recall: 0.9573 - fmeasure: 0.9615 - val_loss: 1.6692 - val_acc: 0.7416 - val_top_k_categorical_accuracy: 0.9099 - val_precision: 0.7670 - val_recall: 0.7310 - val_fmeasure: 0.7484\n",
            "Epoch 32/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.1355 - acc: 0.9529 - top_k_categorical_accuracy: 0.9996 - precision: 0.9593 - recall: 0.9464 - fmeasure: 0.9527 - val_loss: 1.5975 - val_acc: 0.7461 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.7758 - val_recall: 0.7369 - val_fmeasure: 0.7557\n",
            "Epoch 33/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.1203 - acc: 0.9590 - top_k_categorical_accuracy: 0.9996 - precision: 0.9636 - recall: 0.9537 - fmeasure: 0.9586 - val_loss: 1.5609 - val_acc: 0.7475 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.7742 - val_recall: 0.7338 - val_fmeasure: 0.7533\n",
            "Epoch 34/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0826 - acc: 0.9709 - top_k_categorical_accuracy: 1.0000 - precision: 0.9739 - recall: 0.9677 - fmeasure: 0.9708 - val_loss: 1.5496 - val_acc: 0.7596 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.7839 - val_recall: 0.7509 - val_fmeasure: 0.7669\n",
            "Epoch 35/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0981 - acc: 0.9676 - top_k_categorical_accuracy: 0.9999 - precision: 0.9715 - recall: 0.9646 - fmeasure: 0.9680 - val_loss: 1.5841 - val_acc: 0.7621 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7860 - val_recall: 0.7523 - val_fmeasure: 0.7687\n",
            "Epoch 36/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.1148 - acc: 0.9606 - top_k_categorical_accuracy: 0.9996 - precision: 0.9661 - recall: 0.9569 - fmeasure: 0.9614 - val_loss: 1.6305 - val_acc: 0.7380 - val_top_k_categorical_accuracy: 0.9056 - val_precision: 0.7700 - val_recall: 0.7214 - val_fmeasure: 0.7448\n",
            "Epoch 37/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0889 - acc: 0.9685 - top_k_categorical_accuracy: 1.0000 - precision: 0.9726 - recall: 0.9647 - fmeasure: 0.9686 - val_loss: 1.6181 - val_acc: 0.7664 - val_top_k_categorical_accuracy: 0.9155 - val_precision: 0.7862 - val_recall: 0.7593 - val_fmeasure: 0.7725\n",
            "Epoch 38/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0928 - acc: 0.9681 - top_k_categorical_accuracy: 0.9998 - precision: 0.9720 - recall: 0.9647 - fmeasure: 0.9683 - val_loss: 1.6777 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7758 - val_recall: 0.7506 - val_fmeasure: 0.7629\n",
            "Epoch 39/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0996 - acc: 0.9656 - top_k_categorical_accuracy: 0.9998 - precision: 0.9692 - recall: 0.9623 - fmeasure: 0.9657 - val_loss: 1.6739 - val_acc: 0.7422 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.7675 - val_recall: 0.7343 - val_fmeasure: 0.7504\n",
            "Epoch 40/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0765 - acc: 0.9720 - top_k_categorical_accuracy: 0.9996 - precision: 0.9758 - recall: 0.9694 - fmeasure: 0.9726 - val_loss: 1.7158 - val_acc: 0.7495 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7690 - val_recall: 0.7430 - val_fmeasure: 0.7556\n",
            "Epoch 41/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0937 - acc: 0.9687 - top_k_categorical_accuracy: 1.0000 - precision: 0.9713 - recall: 0.9663 - fmeasure: 0.9688 - val_loss: 1.6821 - val_acc: 0.7414 - val_top_k_categorical_accuracy: 0.9096 - val_precision: 0.7642 - val_recall: 0.7307 - val_fmeasure: 0.7469\n",
            "Epoch 42/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0929 - acc: 0.9675 - top_k_categorical_accuracy: 1.0000 - precision: 0.9702 - recall: 0.9638 - fmeasure: 0.9669 - val_loss: 1.6992 - val_acc: 0.7400 - val_top_k_categorical_accuracy: 0.9073 - val_precision: 0.7646 - val_recall: 0.7287 - val_fmeasure: 0.7461\n",
            "Epoch 43/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0668 - acc: 0.9776 - top_k_categorical_accuracy: 1.0000 - precision: 0.9797 - recall: 0.9752 - fmeasure: 0.9774 - val_loss: 1.6877 - val_acc: 0.7661 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.7863 - val_recall: 0.7560 - val_fmeasure: 0.7707\n",
            "Epoch 44/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0823 - acc: 0.9703 - top_k_categorical_accuracy: 1.0000 - precision: 0.9728 - recall: 0.9679 - fmeasure: 0.9703 - val_loss: 1.7420 - val_acc: 0.7543 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7733 - val_recall: 0.7464 - val_fmeasure: 0.7595\n",
            "Epoch 45/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0978 - acc: 0.9697 - top_k_categorical_accuracy: 0.9998 - precision: 0.9720 - recall: 0.9675 - fmeasure: 0.9697 - val_loss: 1.7718 - val_acc: 0.7217 - val_top_k_categorical_accuracy: 0.8947 - val_precision: 0.7560 - val_recall: 0.7082 - val_fmeasure: 0.7311\n",
            "Epoch 46/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0728 - acc: 0.9760 - top_k_categorical_accuracy: 0.9998 - precision: 0.9780 - recall: 0.9738 - fmeasure: 0.9758 - val_loss: 1.6988 - val_acc: 0.7616 - val_top_k_categorical_accuracy: 0.9146 - val_precision: 0.7802 - val_recall: 0.7523 - val_fmeasure: 0.7659\n",
            "Epoch 47/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0626 - acc: 0.9788 - top_k_categorical_accuracy: 0.9999 - precision: 0.9807 - recall: 0.9776 - fmeasure: 0.9791 - val_loss: 1.7292 - val_acc: 0.7709 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.7908 - val_recall: 0.7641 - val_fmeasure: 0.7771\n",
            "Epoch 48/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0613 - acc: 0.9783 - top_k_categorical_accuracy: 0.9999 - precision: 0.9808 - recall: 0.9776 - fmeasure: 0.9792 - val_loss: 1.7223 - val_acc: 0.7506 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7700 - val_recall: 0.7433 - val_fmeasure: 0.7563\n",
            "Epoch 49/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0676 - acc: 0.9757 - top_k_categorical_accuracy: 1.0000 - precision: 0.9776 - recall: 0.9740 - fmeasure: 0.9758 - val_loss: 1.7829 - val_acc: 0.7537 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.7686 - val_recall: 0.7481 - val_fmeasure: 0.7581\n",
            "Epoch 50/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0642 - acc: 0.9776 - top_k_categorical_accuracy: 0.9999 - precision: 0.9787 - recall: 0.9765 - fmeasure: 0.9776 - val_loss: 1.7445 - val_acc: 0.7562 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.7777 - val_recall: 0.7481 - val_fmeasure: 0.7626\n",
            "Epoch 51/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0558 - acc: 0.9825 - top_k_categorical_accuracy: 1.0000 - precision: 0.9845 - recall: 0.9809 - fmeasure: 0.9827 - val_loss: 1.6797 - val_acc: 0.7680 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7857 - val_recall: 0.7610 - val_fmeasure: 0.7731\n",
            "Epoch 52/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0569 - acc: 0.9818 - top_k_categorical_accuracy: 1.0000 - precision: 0.9836 - recall: 0.9799 - fmeasure: 0.9817 - val_loss: 1.7533 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7708 - val_recall: 0.7459 - val_fmeasure: 0.7580\n",
            "Epoch 53/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0684 - acc: 0.9770 - top_k_categorical_accuracy: 0.9999 - precision: 0.9790 - recall: 0.9751 - fmeasure: 0.9770 - val_loss: 1.7975 - val_acc: 0.7557 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7711 - val_recall: 0.7489 - val_fmeasure: 0.7598\n",
            "Epoch 54/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0756 - acc: 0.9738 - top_k_categorical_accuracy: 0.9999 - precision: 0.9761 - recall: 0.9722 - fmeasure: 0.9741 - val_loss: 1.9028 - val_acc: 0.7301 - val_top_k_categorical_accuracy: 0.9042 - val_precision: 0.7532 - val_recall: 0.7197 - val_fmeasure: 0.7359\n",
            "Epoch 55/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0582 - acc: 0.9809 - top_k_categorical_accuracy: 0.9999 - precision: 0.9825 - recall: 0.9799 - fmeasure: 0.9812 - val_loss: 1.7076 - val_acc: 0.7579 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.7760 - val_recall: 0.7509 - val_fmeasure: 0.7631\n",
            "Epoch 56/100\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0416 - acc: 0.9863 - top_k_categorical_accuracy: 1.0000 - precision: 0.9877 - recall: 0.9851 - fmeasure: 0.9864 - val_loss: 1.7670 - val_acc: 0.7461 - val_top_k_categorical_accuracy: 0.9087 - val_precision: 0.7650 - val_recall: 0.7388 - val_fmeasure: 0.7516\n",
            "Epoch 57/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0598 - acc: 0.9799 - top_k_categorical_accuracy: 0.9999 - precision: 0.9818 - recall: 0.9786 - fmeasure: 0.9802 - val_loss: 1.9179 - val_acc: 0.7211 - val_top_k_categorical_accuracy: 0.9009 - val_precision: 0.7457 - val_recall: 0.7138 - val_fmeasure: 0.7293\n",
            "Epoch 58/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0452 - acc: 0.9845 - top_k_categorical_accuracy: 0.9999 - precision: 0.9855 - recall: 0.9836 - fmeasure: 0.9846 - val_loss: 1.8546 - val_acc: 0.7647 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7753 - val_recall: 0.7591 - val_fmeasure: 0.7670\n",
            "Epoch 59/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0603 - acc: 0.9812 - top_k_categorical_accuracy: 0.9996 - precision: 0.9820 - recall: 0.9803 - fmeasure: 0.9811 - val_loss: 1.8205 - val_acc: 0.7591 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7747 - val_recall: 0.7506 - val_fmeasure: 0.7623\n",
            "Epoch 60/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0641 - acc: 0.9797 - top_k_categorical_accuracy: 1.0000 - precision: 0.9809 - recall: 0.9780 - fmeasure: 0.9794 - val_loss: 1.8000 - val_acc: 0.7515 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.7722 - val_recall: 0.7445 - val_fmeasure: 0.7580\n",
            "Epoch 61/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0519 - acc: 0.9841 - top_k_categorical_accuracy: 0.9999 - precision: 0.9852 - recall: 0.9829 - fmeasure: 0.9840 - val_loss: 1.8239 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9146 - val_precision: 0.7863 - val_recall: 0.7630 - val_fmeasure: 0.7743\n",
            "Epoch 62/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0385 - acc: 0.9872 - top_k_categorical_accuracy: 1.0000 - precision: 0.9878 - recall: 0.9870 - fmeasure: 0.9874 - val_loss: 1.8411 - val_acc: 0.7523 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7670 - val_recall: 0.7450 - val_fmeasure: 0.7558\n",
            "Epoch 63/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0593 - acc: 0.9809 - top_k_categorical_accuracy: 1.0000 - precision: 0.9818 - recall: 0.9794 - fmeasure: 0.9806 - val_loss: 1.9179 - val_acc: 0.7591 - val_top_k_categorical_accuracy: 0.9070 - val_precision: 0.7730 - val_recall: 0.7540 - val_fmeasure: 0.7633\n",
            "Epoch 64/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0466 - acc: 0.9866 - top_k_categorical_accuracy: 0.9999 - precision: 0.9870 - recall: 0.9857 - fmeasure: 0.9863 - val_loss: 1.9878 - val_acc: 0.7470 - val_top_k_categorical_accuracy: 0.9059 - val_precision: 0.7623 - val_recall: 0.7442 - val_fmeasure: 0.7530\n",
            "Epoch 65/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0446 - acc: 0.9851 - top_k_categorical_accuracy: 1.0000 - precision: 0.9859 - recall: 0.9844 - fmeasure: 0.9851 - val_loss: 1.8587 - val_acc: 0.7627 - val_top_k_categorical_accuracy: 0.9129 - val_precision: 0.7792 - val_recall: 0.7574 - val_fmeasure: 0.7681\n",
            "Epoch 66/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0396 - acc: 0.9865 - top_k_categorical_accuracy: 1.0000 - precision: 0.9873 - recall: 0.9857 - fmeasure: 0.9865 - val_loss: 1.9377 - val_acc: 0.7582 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.7701 - val_recall: 0.7506 - val_fmeasure: 0.7602\n",
            "Epoch 67/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0468 - acc: 0.9840 - top_k_categorical_accuracy: 0.9999 - precision: 0.9853 - recall: 0.9837 - fmeasure: 0.9845 - val_loss: 1.9288 - val_acc: 0.7554 - val_top_k_categorical_accuracy: 0.9110 - val_precision: 0.7673 - val_recall: 0.7512 - val_fmeasure: 0.7591\n",
            "Epoch 68/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0607 - acc: 0.9804 - top_k_categorical_accuracy: 0.9998 - precision: 0.9817 - recall: 0.9788 - fmeasure: 0.9802 - val_loss: 1.9045 - val_acc: 0.7591 - val_top_k_categorical_accuracy: 0.9085 - val_precision: 0.7737 - val_recall: 0.7551 - val_fmeasure: 0.7642\n",
            "Epoch 69/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0435 - acc: 0.9862 - top_k_categorical_accuracy: 1.0000 - precision: 0.9870 - recall: 0.9857 - fmeasure: 0.9863 - val_loss: 1.8863 - val_acc: 0.7484 - val_top_k_categorical_accuracy: 0.9107 - val_precision: 0.7675 - val_recall: 0.7419 - val_fmeasure: 0.7544\n",
            "Epoch 70/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0550 - acc: 0.9829 - top_k_categorical_accuracy: 0.9998 - precision: 0.9843 - recall: 0.9809 - fmeasure: 0.9826 - val_loss: 1.8243 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7815 - val_recall: 0.7593 - val_fmeasure: 0.7702\n",
            "Epoch 71/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0340 - acc: 0.9880 - top_k_categorical_accuracy: 1.0000 - precision: 0.9884 - recall: 0.9872 - fmeasure: 0.9878 - val_loss: 1.8955 - val_acc: 0.7562 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7721 - val_recall: 0.7509 - val_fmeasure: 0.7613\n",
            "Epoch 72/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0565 - acc: 0.9821 - top_k_categorical_accuracy: 0.9998 - precision: 0.9837 - recall: 0.9809 - fmeasure: 0.9823 - val_loss: 1.9476 - val_acc: 0.7453 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.7614 - val_recall: 0.7411 - val_fmeasure: 0.7511\n",
            "Epoch 73/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0471 - acc: 0.9841 - top_k_categorical_accuracy: 1.0000 - precision: 0.9853 - recall: 0.9833 - fmeasure: 0.9843 - val_loss: 1.8481 - val_acc: 0.7650 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.7775 - val_recall: 0.7610 - val_fmeasure: 0.7691\n",
            "Epoch 74/100\n",
            "8307/8307 [==============================] - 1s 111us/step - loss: 0.0234 - acc: 0.9925 - top_k_categorical_accuracy: 1.0000 - precision: 0.9925 - recall: 0.9921 - fmeasure: 0.9923 - val_loss: 1.8548 - val_acc: 0.7703 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7817 - val_recall: 0.7675 - val_fmeasure: 0.7745\n",
            "Epoch 75/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0268 - acc: 0.9906 - top_k_categorical_accuracy: 1.0000 - precision: 0.9907 - recall: 0.9902 - fmeasure: 0.9905 - val_loss: 1.9147 - val_acc: 0.7588 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7728 - val_recall: 0.7540 - val_fmeasure: 0.7632\n",
            "Epoch 76/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0389 - acc: 0.9892 - top_k_categorical_accuracy: 1.0000 - precision: 0.9898 - recall: 0.9884 - fmeasure: 0.9891 - val_loss: 1.9319 - val_acc: 0.7560 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.7706 - val_recall: 0.7523 - val_fmeasure: 0.7613\n",
            "Epoch 77/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0455 - acc: 0.9875 - top_k_categorical_accuracy: 0.9999 - precision: 0.9883 - recall: 0.9864 - fmeasure: 0.9873 - val_loss: 1.8719 - val_acc: 0.7577 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7738 - val_recall: 0.7515 - val_fmeasure: 0.7624\n",
            "Epoch 78/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0343 - acc: 0.9871 - top_k_categorical_accuracy: 1.0000 - precision: 0.9874 - recall: 0.9862 - fmeasure: 0.9868 - val_loss: 1.8941 - val_acc: 0.7593 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7758 - val_recall: 0.7562 - val_fmeasure: 0.7658\n",
            "Epoch 79/100\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0421 - acc: 0.9858 - top_k_categorical_accuracy: 1.0000 - precision: 0.9870 - recall: 0.9852 - fmeasure: 0.9861 - val_loss: 1.9812 - val_acc: 0.7487 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.7630 - val_recall: 0.7414 - val_fmeasure: 0.7519\n",
            "Epoch 80/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0414 - acc: 0.9864 - top_k_categorical_accuracy: 0.9998 - precision: 0.9867 - recall: 0.9857 - fmeasure: 0.9862 - val_loss: 1.8733 - val_acc: 0.7652 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7793 - val_recall: 0.7593 - val_fmeasure: 0.7691\n",
            "Epoch 81/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0214 - acc: 0.9934 - top_k_categorical_accuracy: 1.0000 - precision: 0.9936 - recall: 0.9933 - fmeasure: 0.9934 - val_loss: 1.8950 - val_acc: 0.7635 - val_top_k_categorical_accuracy: 0.9155 - val_precision: 0.7808 - val_recall: 0.7605 - val_fmeasure: 0.7704\n",
            "Epoch 82/100\n",
            "8307/8307 [==============================] - 1s 119us/step - loss: 0.0337 - acc: 0.9911 - top_k_categorical_accuracy: 1.0000 - precision: 0.9914 - recall: 0.9909 - fmeasure: 0.9911 - val_loss: 1.8698 - val_acc: 0.7709 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.7852 - val_recall: 0.7655 - val_fmeasure: 0.7752\n",
            "Epoch 83/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0281 - acc: 0.9909 - top_k_categorical_accuracy: 1.0000 - precision: 0.9916 - recall: 0.9907 - fmeasure: 0.9911 - val_loss: 1.8785 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7812 - val_recall: 0.7635 - val_fmeasure: 0.7722\n",
            "Epoch 84/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0337 - acc: 0.9898 - top_k_categorical_accuracy: 0.9998 - precision: 0.9901 - recall: 0.9893 - fmeasure: 0.9897 - val_loss: 1.9351 - val_acc: 0.7551 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.7702 - val_recall: 0.7498 - val_fmeasure: 0.7598\n",
            "Epoch 85/100\n",
            "8307/8307 [==============================] - 1s 120us/step - loss: 0.0257 - acc: 0.9912 - top_k_categorical_accuracy: 0.9999 - precision: 0.9914 - recall: 0.9905 - fmeasure: 0.9910 - val_loss: 2.0371 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.7633 - val_recall: 0.7470 - val_fmeasure: 0.7550\n",
            "Epoch 86/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0475 - acc: 0.9848 - top_k_categorical_accuracy: 0.9998 - precision: 0.9852 - recall: 0.9837 - fmeasure: 0.9845 - val_loss: 1.9055 - val_acc: 0.7619 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7776 - val_recall: 0.7571 - val_fmeasure: 0.7671\n",
            "Epoch 87/100\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.0395 - acc: 0.9869 - top_k_categorical_accuracy: 1.0000 - precision: 0.9875 - recall: 0.9864 - fmeasure: 0.9869 - val_loss: 1.9185 - val_acc: 0.7585 - val_top_k_categorical_accuracy: 0.9101 - val_precision: 0.7712 - val_recall: 0.7532 - val_fmeasure: 0.7620\n",
            "Epoch 88/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0424 - acc: 0.9871 - top_k_categorical_accuracy: 1.0000 - precision: 0.9877 - recall: 0.9862 - fmeasure: 0.9869 - val_loss: 2.0854 - val_acc: 0.7473 - val_top_k_categorical_accuracy: 0.9037 - val_precision: 0.7613 - val_recall: 0.7422 - val_fmeasure: 0.7516\n",
            "Epoch 89/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0237 - acc: 0.9928 - top_k_categorical_accuracy: 1.0000 - precision: 0.9931 - recall: 0.9927 - fmeasure: 0.9929 - val_loss: 1.9846 - val_acc: 0.7672 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7773 - val_recall: 0.7627 - val_fmeasure: 0.7699\n",
            "Epoch 90/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0176 - acc: 0.9943 - top_k_categorical_accuracy: 1.0000 - precision: 0.9946 - recall: 0.9939 - fmeasure: 0.9942 - val_loss: 1.9196 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7836 - val_recall: 0.7658 - val_fmeasure: 0.7745\n",
            "Epoch 91/100\n",
            "8307/8307 [==============================] - 1s 113us/step - loss: 0.0371 - acc: 0.9887 - top_k_categorical_accuracy: 0.9999 - precision: 0.9892 - recall: 0.9883 - fmeasure: 0.9887 - val_loss: 1.9227 - val_acc: 0.7694 - val_top_k_categorical_accuracy: 0.9110 - val_precision: 0.7827 - val_recall: 0.7650 - val_fmeasure: 0.7737\n",
            "Epoch 92/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0303 - acc: 0.9911 - top_k_categorical_accuracy: 1.0000 - precision: 0.9920 - recall: 0.9907 - fmeasure: 0.9914 - val_loss: 1.9817 - val_acc: 0.7543 - val_top_k_categorical_accuracy: 0.9129 - val_precision: 0.7676 - val_recall: 0.7489 - val_fmeasure: 0.7581\n",
            "Epoch 93/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0243 - acc: 0.9924 - top_k_categorical_accuracy: 0.9999 - precision: 0.9929 - recall: 0.9923 - fmeasure: 0.9926 - val_loss: 1.8864 - val_acc: 0.7734 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7850 - val_recall: 0.7694 - val_fmeasure: 0.7771\n",
            "Epoch 94/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0189 - acc: 0.9954 - top_k_categorical_accuracy: 0.9999 - precision: 0.9955 - recall: 0.9953 - fmeasure: 0.9954 - val_loss: 1.9379 - val_acc: 0.7647 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.7756 - val_recall: 0.7607 - val_fmeasure: 0.7680\n",
            "Epoch 95/100\n",
            "8307/8307 [==============================] - 1s 116us/step - loss: 0.0339 - acc: 0.9909 - top_k_categorical_accuracy: 0.9999 - precision: 0.9916 - recall: 0.9898 - fmeasure: 0.9907 - val_loss: 1.9635 - val_acc: 0.7515 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7662 - val_recall: 0.7470 - val_fmeasure: 0.7564\n",
            "Epoch 96/100\n",
            "8307/8307 [==============================] - 1s 115us/step - loss: 0.0293 - acc: 0.9913 - top_k_categorical_accuracy: 1.0000 - precision: 0.9916 - recall: 0.9913 - fmeasure: 0.9915 - val_loss: 1.9481 - val_acc: 0.7562 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.7689 - val_recall: 0.7506 - val_fmeasure: 0.7596\n",
            "Epoch 97/100\n",
            "8307/8307 [==============================] - 1s 117us/step - loss: 0.0233 - acc: 0.9921 - top_k_categorical_accuracy: 1.0000 - precision: 0.9923 - recall: 0.9917 - fmeasure: 0.9920 - val_loss: 2.0551 - val_acc: 0.7607 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.7736 - val_recall: 0.7568 - val_fmeasure: 0.7651\n",
            "Epoch 98/100\n",
            "8307/8307 [==============================] - 1s 114us/step - loss: 0.0332 - acc: 0.9889 - top_k_categorical_accuracy: 1.0000 - precision: 0.9894 - recall: 0.9886 - fmeasure: 0.9890 - val_loss: 1.9796 - val_acc: 0.7557 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7683 - val_recall: 0.7518 - val_fmeasure: 0.7599\n",
            "Epoch 99/100\n",
            "8307/8307 [==============================] - 1s 112us/step - loss: 0.0253 - acc: 0.9917 - top_k_categorical_accuracy: 1.0000 - precision: 0.9921 - recall: 0.9916 - fmeasure: 0.9918 - val_loss: 2.0818 - val_acc: 0.7529 - val_top_k_categorical_accuracy: 0.9099 - val_precision: 0.7630 - val_recall: 0.7492 - val_fmeasure: 0.7560\n",
            "Epoch 100/100\n",
            "8307/8307 [==============================] - 1s 110us/step - loss: 0.0283 - acc: 0.9918 - top_k_categorical_accuracy: 1.0000 - precision: 0.9919 - recall: 0.9918 - fmeasure: 0.9919 - val_loss: 2.0409 - val_acc: 0.7619 - val_top_k_categorical_accuracy: 0.9079 - val_precision: 0.7726 - val_recall: 0.7591 - val_fmeasure: 0.7657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEMNvc6PntbC",
        "colab_type": "code",
        "outputId": "698fe84a-c739-42af-e7fe-f82f139c9a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#DNN               ############# test for noise adding  , function :: creat_data############\n",
        "\n",
        "history_DNN = []\n",
        "for i in range(NB_TECHS):\n",
        "    his = my_history()\n",
        "    X_temp,y_temp = random_launch(X_train_saved,y_train_saved,i)\n",
        "    X_temp = sequence.pad_sequences(X_temp, maxlen=maxlen,padding='post',truncating='post')\n",
        "    y_temp = np_utils.to_categorical(y_temp, NB_CLASSES)\n",
        "    X_train = sequence.pad_sequences(X_train_saved, maxlen=maxlen,padding='post',truncating='post')\n",
        "    y_train = np_utils.to_categorical(y_train_saved, NB_CLASSES)\n",
        "    X_test = sequence.pad_sequences(X_test_saved, maxlen=maxlen,padding='post',truncating='post')\n",
        "    y_test = np_utils.to_categorical(y_test_saved, NB_CLASSES)\n",
        "    model_DNN = DNN(maxlen,NB_CLASSES)\n",
        "    #model_DNN.summary()\n",
        "    model_DNN.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy','top_k_categorical_accuracy', precision, recall, fmeasure])\n",
        "    run_DNN(X_train,y_train,X_test,y_test,X_temp,y_temp,BATCH_SIZE,history = his)\n",
        "    history_DNN.append(his)\n",
        "\n",
        "\n",
        "print('the shape of x_train',X_train.shape)\n",
        "print('the shape of y_train',y_train.shape)\n",
        "print('the shape of x_test',X_test.shape)\n",
        "print('the shape of y_test',y_test.shape)\n",
        "\n",
        "print('base_line_now#######################################################################################################################################################################################################')\n",
        "model_DNN_org = DNN(maxlen,NB_CLASSES)\n",
        "model_DNN_org.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy','top_k_categorical_accuracy', precision, recall, fmeasure])\n",
        "history_DNN_org = model_DNN_org.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCHS,validation_data=(X_test,y_test),verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adding noise......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 4s 445us/step - loss: 4.0811 - acc: 0.1052 - top_k_categorical_accuracy: 0.3167 - precision: 0.2413 - recall: 0.0126 - fmeasure: 0.0236 - val_loss: 2.8959 - val_acc: 0.2926 - val_top_k_categorical_accuracy: 0.6116 - val_precision: 0.6953 - val_recall: 0.0868 - val_fmeasure: 0.1528\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 2.9166 - acc: 0.3010 - top_k_categorical_accuracy: 0.6185 - precision: 0.6070 - recall: 0.0965 - fmeasure: 0.1642 - val_loss: 2.4490 - val_acc: 0.3923 - val_top_k_categorical_accuracy: 0.7270 - val_precision: 0.6555 - val_recall: 0.2131 - val_fmeasure: 0.3198\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 2.3624 - acc: 0.4335 - top_k_categorical_accuracy: 0.7352 - precision: 0.7034 - recall: 0.2063 - fmeasure: 0.3159 - val_loss: 1.9529 - val_acc: 0.5378 - val_top_k_categorical_accuracy: 0.8040 - val_precision: 0.7185 - val_recall: 0.4016 - val_fmeasure: 0.5136\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.9962 - acc: 0.5187 - top_k_categorical_accuracy: 0.7966 - precision: 0.7451 - recall: 0.3047 - fmeasure: 0.4299 - val_loss: 2.0009 - val_acc: 0.5170 - val_top_k_categorical_accuracy: 0.8065 - val_precision: 0.6912 - val_recall: 0.4016 - val_fmeasure: 0.5070\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 1.7278 - acc: 0.5818 - top_k_categorical_accuracy: 0.8427 - precision: 0.7802 - recall: 0.3956 - fmeasure: 0.5233 - val_loss: 1.9339 - val_acc: 0.5437 - val_top_k_categorical_accuracy: 0.8107 - val_precision: 0.6991 - val_recall: 0.4302 - val_fmeasure: 0.5317\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 1.5855 - acc: 0.6172 - top_k_categorical_accuracy: 0.8543 - precision: 0.8060 - recall: 0.4530 - fmeasure: 0.5783 - val_loss: 1.7835 - val_acc: 0.5625 - val_top_k_categorical_accuracy: 0.8388 - val_precision: 0.7024 - val_recall: 0.4726 - val_fmeasure: 0.5639\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.4440 - acc: 0.6489 - top_k_categorical_accuracy: 0.8716 - precision: 0.8105 - recall: 0.5002 - fmeasure: 0.6173 - val_loss: 1.6553 - val_acc: 0.6215 - val_top_k_categorical_accuracy: 0.8453 - val_precision: 0.7476 - val_recall: 0.5423 - val_fmeasure: 0.6276\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.3204 - acc: 0.6774 - top_k_categorical_accuracy: 0.8918 - precision: 0.8217 - recall: 0.5415 - fmeasure: 0.6515 - val_loss: 1.5217 - val_acc: 0.6358 - val_top_k_categorical_accuracy: 0.8666 - val_precision: 0.7594 - val_recall: 0.5611 - val_fmeasure: 0.6447\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.2322 - acc: 0.6997 - top_k_categorical_accuracy: 0.9013 - precision: 0.8325 - recall: 0.5680 - fmeasure: 0.6742 - val_loss: 1.3948 - val_acc: 0.6874 - val_top_k_categorical_accuracy: 0.8784 - val_precision: 0.7856 - val_recall: 0.6274 - val_fmeasure: 0.6969\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.1572 - acc: 0.7083 - top_k_categorical_accuracy: 0.9098 - precision: 0.8428 - recall: 0.6007 - fmeasure: 0.7004 - val_loss: 1.3307 - val_acc: 0.7023 - val_top_k_categorical_accuracy: 0.8933 - val_precision: 0.7904 - val_recall: 0.6434 - val_fmeasure: 0.7088\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.0804 - acc: 0.7337 - top_k_categorical_accuracy: 0.9178 - precision: 0.8484 - recall: 0.6225 - fmeasure: 0.7173 - val_loss: 1.3401 - val_acc: 0.6947 - val_top_k_categorical_accuracy: 0.8958 - val_precision: 0.7897 - val_recall: 0.6375 - val_fmeasure: 0.7049\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.0004 - acc: 0.7489 - top_k_categorical_accuracy: 0.9286 - precision: 0.8600 - recall: 0.6544 - fmeasure: 0.7425 - val_loss: 1.2009 - val_acc: 0.7214 - val_top_k_categorical_accuracy: 0.9031 - val_precision: 0.8119 - val_recall: 0.6622 - val_fmeasure: 0.7288\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.9443 - acc: 0.7573 - top_k_categorical_accuracy: 0.9348 - precision: 0.8575 - recall: 0.6615 - fmeasure: 0.7459 - val_loss: 1.1944 - val_acc: 0.7284 - val_top_k_categorical_accuracy: 0.9020 - val_precision: 0.8125 - val_recall: 0.6782 - val_fmeasure: 0.7389\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.8918 - acc: 0.7736 - top_k_categorical_accuracy: 0.9408 - precision: 0.8690 - recall: 0.6870 - fmeasure: 0.7667 - val_loss: 1.2451 - val_acc: 0.7234 - val_top_k_categorical_accuracy: 0.9028 - val_precision: 0.7955 - val_recall: 0.6816 - val_fmeasure: 0.7337\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.8377 - acc: 0.7881 - top_k_categorical_accuracy: 0.9476 - precision: 0.8741 - recall: 0.7041 - fmeasure: 0.7792 - val_loss: 1.1999 - val_acc: 0.7248 - val_top_k_categorical_accuracy: 0.9087 - val_precision: 0.8097 - val_recall: 0.6698 - val_fmeasure: 0.7324\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.8047 - acc: 0.7901 - top_k_categorical_accuracy: 0.9478 - precision: 0.8721 - recall: 0.7096 - fmeasure: 0.7818 - val_loss: 1.4365 - val_acc: 0.6874 - val_top_k_categorical_accuracy: 0.8894 - val_precision: 0.7644 - val_recall: 0.6428 - val_fmeasure: 0.6979\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.7703 - acc: 0.7976 - top_k_categorical_accuracy: 0.9546 - precision: 0.8771 - recall: 0.7217 - fmeasure: 0.7912 - val_loss: 1.1744 - val_acc: 0.7504 - val_top_k_categorical_accuracy: 0.9079 - val_precision: 0.8120 - val_recall: 0.7133 - val_fmeasure: 0.7591\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.7150 - acc: 0.8061 - top_k_categorical_accuracy: 0.9593 - precision: 0.8827 - recall: 0.7371 - fmeasure: 0.8028 - val_loss: 1.2083 - val_acc: 0.7377 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7956 - val_recall: 0.7018 - val_fmeasure: 0.7452\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.7109 - acc: 0.8032 - top_k_categorical_accuracy: 0.9585 - precision: 0.8797 - recall: 0.7377 - fmeasure: 0.8019 - val_loss: 1.1508 - val_acc: 0.7445 - val_top_k_categorical_accuracy: 0.9076 - val_precision: 0.8123 - val_recall: 0.7040 - val_fmeasure: 0.7539\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.6486 - acc: 0.8232 - top_k_categorical_accuracy: 0.9617 - precision: 0.8940 - recall: 0.7642 - fmeasure: 0.8235 - val_loss: 1.2038 - val_acc: 0.7397 - val_top_k_categorical_accuracy: 0.9096 - val_precision: 0.8005 - val_recall: 0.7037 - val_fmeasure: 0.7485\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 233us/step - loss: 0.6422 - acc: 0.8263 - top_k_categorical_accuracy: 0.9682 - precision: 0.8924 - recall: 0.7636 - fmeasure: 0.8224 - val_loss: 1.3922 - val_acc: 0.6995 - val_top_k_categorical_accuracy: 0.8983 - val_precision: 0.7631 - val_recall: 0.6616 - val_fmeasure: 0.7083\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 2.5821 - acc: 0.3835 - top_k_categorical_accuracy: 0.7018 - precision: 0.5801 - recall: 0.2445 - fmeasure: 0.3418 - val_loss: 8.5452 - val_acc: 0.0657 - val_top_k_categorical_accuracy: 0.1789 - val_precision: 0.0727 - val_recall: 0.0447 - val_fmeasure: 0.0552\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 1.5836 - acc: 0.6029 - top_k_categorical_accuracy: 0.8470 - precision: 0.7469 - recall: 0.4732 - fmeasure: 0.5736 - val_loss: 1.2022 - val_acc: 0.7102 - val_top_k_categorical_accuracy: 0.9017 - val_precision: 0.8286 - val_recall: 0.6127 - val_fmeasure: 0.7034\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 1.7494 - acc: 0.5444 - top_k_categorical_accuracy: 0.8327 - precision: 0.7243 - recall: 0.4001 - fmeasure: 0.5133 - val_loss: 7.1999 - val_acc: 0.0657 - val_top_k_categorical_accuracy: 0.1963 - val_precision: 0.0773 - val_recall: 0.0407 - val_fmeasure: 0.0532\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.4779 - acc: 0.6267 - top_k_categorical_accuracy: 0.8664 - precision: 0.7527 - recall: 0.4962 - fmeasure: 0.5938 - val_loss: 1.1852 - val_acc: 0.7192 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.8161 - val_recall: 0.6487 - val_fmeasure: 0.7223\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 1.4320 - acc: 0.6200 - top_k_categorical_accuracy: 0.8789 - precision: 0.7744 - recall: 0.4865 - fmeasure: 0.5958 - val_loss: 9.0071 - val_acc: 0.0562 - val_top_k_categorical_accuracy: 0.1834 - val_precision: 0.0584 - val_recall: 0.0388 - val_fmeasure: 0.0465\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.4308 - acc: 0.6351 - top_k_categorical_accuracy: 0.8771 - precision: 0.7586 - recall: 0.5138 - fmeasure: 0.6096 - val_loss: 1.3439 - val_acc: 0.6759 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.7798 - val_recall: 0.6060 - val_fmeasure: 0.6813\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 1.2213 - acc: 0.6726 - top_k_categorical_accuracy: 0.9038 - precision: 0.8096 - recall: 0.5576 - fmeasure: 0.6587 - val_loss: 8.0793 - val_acc: 0.0663 - val_top_k_categorical_accuracy: 0.1940 - val_precision: 0.0775 - val_recall: 0.0500 - val_fmeasure: 0.0607\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.3619 - acc: 0.6541 - top_k_categorical_accuracy: 0.8836 - precision: 0.7758 - recall: 0.5452 - fmeasure: 0.6375 - val_loss: 1.5523 - val_acc: 0.6462 - val_top_k_categorical_accuracy: 0.8675 - val_precision: 0.7547 - val_recall: 0.5667 - val_fmeasure: 0.6466\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.0825 - acc: 0.7075 - top_k_categorical_accuracy: 0.9230 - precision: 0.8280 - recall: 0.5940 - fmeasure: 0.6900 - val_loss: 8.7658 - val_acc: 0.0691 - val_top_k_categorical_accuracy: 0.1876 - val_precision: 0.0723 - val_recall: 0.0475 - val_fmeasure: 0.0572\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 1.3204 - acc: 0.6586 - top_k_categorical_accuracy: 0.8921 - precision: 0.7750 - recall: 0.5590 - fmeasure: 0.6471 - val_loss: 1.3224 - val_acc: 0.7018 - val_top_k_categorical_accuracy: 0.8916 - val_precision: 0.7966 - val_recall: 0.6262 - val_fmeasure: 0.7005\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.9681 - acc: 0.7311 - top_k_categorical_accuracy: 0.9363 - precision: 0.8400 - recall: 0.6355 - fmeasure: 0.7222 - val_loss: 7.9705 - val_acc: 0.0668 - val_top_k_categorical_accuracy: 0.2081 - val_precision: 0.0736 - val_recall: 0.0444 - val_fmeasure: 0.0553\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.2194 - acc: 0.6853 - top_k_categorical_accuracy: 0.9121 - precision: 0.7815 - recall: 0.5881 - fmeasure: 0.6696 - val_loss: 1.5381 - val_acc: 0.6453 - val_top_k_categorical_accuracy: 0.8882 - val_precision: 0.7299 - val_recall: 0.5754 - val_fmeasure: 0.6428\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.8670 - acc: 0.7533 - top_k_categorical_accuracy: 0.9488 - precision: 0.8536 - recall: 0.6642 - fmeasure: 0.7461 - val_loss: 8.2354 - val_acc: 0.0677 - val_top_k_categorical_accuracy: 0.2002 - val_precision: 0.0789 - val_recall: 0.0522 - val_fmeasure: 0.0628\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 234us/step - loss: 1.1774 - acc: 0.6900 - top_k_categorical_accuracy: 0.9113 - precision: 0.7916 - recall: 0.6032 - fmeasure: 0.6830 - val_loss: 1.4218 - val_acc: 0.6816 - val_top_k_categorical_accuracy: 0.8882 - val_precision: 0.7748 - val_recall: 0.6259 - val_fmeasure: 0.6919\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 0.7859 - acc: 0.7740 - top_k_categorical_accuracy: 0.9574 - precision: 0.8650 - recall: 0.6930 - fmeasure: 0.7685 - val_loss: 8.8234 - val_acc: 0.0652 - val_top_k_categorical_accuracy: 0.1949 - val_precision: 0.0694 - val_recall: 0.0489 - val_fmeasure: 0.0572\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.1325 - acc: 0.7015 - top_k_categorical_accuracy: 0.9169 - precision: 0.7982 - recall: 0.6212 - fmeasure: 0.6973 - val_loss: 1.4012 - val_acc: 0.6751 - val_top_k_categorical_accuracy: 0.8947 - val_precision: 0.7603 - val_recall: 0.6299 - val_fmeasure: 0.6884\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 221us/step - loss: 0.7315 - acc: 0.7895 - top_k_categorical_accuracy: 0.9611 - precision: 0.8729 - recall: 0.7151 - fmeasure: 0.7853 - val_loss: 9.1677 - val_acc: 0.0576 - val_top_k_categorical_accuracy: 0.1918 - val_precision: 0.0668 - val_recall: 0.0494 - val_fmeasure: 0.0567\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.1018 - acc: 0.7098 - top_k_categorical_accuracy: 0.9246 - precision: 0.7958 - recall: 0.6351 - fmeasure: 0.7051 - val_loss: 1.4535 - val_acc: 0.6863 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.7680 - val_recall: 0.6335 - val_fmeasure: 0.6937\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.6750 - acc: 0.8024 - top_k_categorical_accuracy: 0.9661 - precision: 0.8792 - recall: 0.7335 - fmeasure: 0.7989 - val_loss: 9.2270 - val_acc: 0.0733 - val_top_k_categorical_accuracy: 0.2112 - val_precision: 0.0784 - val_recall: 0.0576 - val_fmeasure: 0.0663\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.0599 - acc: 0.7214 - top_k_categorical_accuracy: 0.9298 - precision: 0.8082 - recall: 0.6490 - fmeasure: 0.7186 - val_loss: 1.3799 - val_acc: 0.7043 - val_top_k_categorical_accuracy: 0.8997 - val_precision: 0.7686 - val_recall: 0.6689 - val_fmeasure: 0.7150\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.6263 - acc: 0.8148 - top_k_categorical_accuracy: 0.9702 - precision: 0.8864 - recall: 0.7535 - fmeasure: 0.8139 - val_loss: 9.8206 - val_acc: 0.0587 - val_top_k_categorical_accuracy: 0.1994 - val_precision: 0.0598 - val_recall: 0.0447 - val_fmeasure: 0.0510\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.0471 - acc: 0.7190 - top_k_categorical_accuracy: 0.9275 - precision: 0.8057 - recall: 0.6513 - fmeasure: 0.7194 - val_loss: 1.5186 - val_acc: 0.6740 - val_top_k_categorical_accuracy: 0.8863 - val_precision: 0.7538 - val_recall: 0.6231 - val_fmeasure: 0.6819\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 0.5950 - acc: 0.8220 - top_k_categorical_accuracy: 0.9745 - precision: 0.8869 - recall: 0.7636 - fmeasure: 0.8199 - val_loss: 10.0109 - val_acc: 0.0573 - val_top_k_categorical_accuracy: 0.1999 - val_precision: 0.0594 - val_recall: 0.0449 - val_fmeasure: 0.0511\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.9854 - acc: 0.7336 - top_k_categorical_accuracy: 0.9327 - precision: 0.8125 - recall: 0.6705 - fmeasure: 0.7337 - val_loss: 1.3168 - val_acc: 0.7186 - val_top_k_categorical_accuracy: 0.9076 - val_precision: 0.7810 - val_recall: 0.6734 - val_fmeasure: 0.7228\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.5459 - acc: 0.8372 - top_k_categorical_accuracy: 0.9780 - precision: 0.8967 - recall: 0.7837 - fmeasure: 0.8357 - val_loss: 10.5904 - val_acc: 0.0578 - val_top_k_categorical_accuracy: 0.2033 - val_precision: 0.0567 - val_recall: 0.0447 - val_fmeasure: 0.0499\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 233us/step - loss: 0.9659 - acc: 0.7354 - top_k_categorical_accuracy: 0.9403 - precision: 0.8135 - recall: 0.6755 - fmeasure: 0.7372 - val_loss: 1.2717 - val_acc: 0.7282 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7913 - val_recall: 0.6860 - val_fmeasure: 0.7345\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.5173 - acc: 0.8455 - top_k_categorical_accuracy: 0.9802 - precision: 0.9003 - recall: 0.7945 - fmeasure: 0.8435 - val_loss: 10.2615 - val_acc: 0.0578 - val_top_k_categorical_accuracy: 0.2072 - val_precision: 0.0635 - val_recall: 0.0486 - val_fmeasure: 0.0550\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 232us/step - loss: 0.9519 - acc: 0.7395 - top_k_categorical_accuracy: 0.9427 - precision: 0.8178 - recall: 0.6801 - fmeasure: 0.7417 - val_loss: 1.2934 - val_acc: 0.7203 - val_top_k_categorical_accuracy: 0.9073 - val_precision: 0.7889 - val_recall: 0.6830 - val_fmeasure: 0.7318\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 217us/step - loss: 0.4836 - acc: 0.8524 - top_k_categorical_accuracy: 0.9823 - precision: 0.9048 - recall: 0.8043 - fmeasure: 0.8510 - val_loss: 9.7674 - val_acc: 0.0640 - val_top_k_categorical_accuracy: 0.1921 - val_precision: 0.0690 - val_recall: 0.0520 - val_fmeasure: 0.0592\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.9172 - acc: 0.7500 - top_k_categorical_accuracy: 0.9449 - precision: 0.8203 - recall: 0.6947 - fmeasure: 0.7516 - val_loss: 1.4727 - val_acc: 0.6858 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.7513 - val_recall: 0.6383 - val_fmeasure: 0.6898\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 0.4695 - acc: 0.8572 - top_k_categorical_accuracy: 0.9835 - precision: 0.9059 - recall: 0.8118 - fmeasure: 0.8558 - val_loss: 9.9979 - val_acc: 0.0635 - val_top_k_categorical_accuracy: 0.1988 - val_precision: 0.0664 - val_recall: 0.0514 - val_fmeasure: 0.0579\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 231us/step - loss: 0.8930 - acc: 0.7532 - top_k_categorical_accuracy: 0.9487 - precision: 0.8258 - recall: 0.7017 - fmeasure: 0.7580 - val_loss: 1.3387 - val_acc: 0.7200 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.7702 - val_recall: 0.6846 - val_fmeasure: 0.7245\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.4487 - acc: 0.8648 - top_k_categorical_accuracy: 0.9839 - precision: 0.9117 - recall: 0.8209 - fmeasure: 0.8634 - val_loss: 9.7807 - val_acc: 0.0663 - val_top_k_categorical_accuracy: 0.2126 - val_precision: 0.0717 - val_recall: 0.0528 - val_fmeasure: 0.0607\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.8664 - acc: 0.7650 - top_k_categorical_accuracy: 0.9498 - precision: 0.8288 - recall: 0.7076 - fmeasure: 0.7628 - val_loss: 1.7289 - val_acc: 0.6389 - val_top_k_categorical_accuracy: 0.8773 - val_precision: 0.7040 - val_recall: 0.5967 - val_fmeasure: 0.6455\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 0.4302 - acc: 0.8666 - top_k_categorical_accuracy: 0.9856 - precision: 0.9111 - recall: 0.8291 - fmeasure: 0.8678 - val_loss: 10.0072 - val_acc: 0.0643 - val_top_k_categorical_accuracy: 0.2193 - val_precision: 0.0702 - val_recall: 0.0553 - val_fmeasure: 0.0618\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.8751 - acc: 0.7585 - top_k_categorical_accuracy: 0.9515 - precision: 0.8251 - recall: 0.7055 - fmeasure: 0.7600 - val_loss: 1.4467 - val_acc: 0.6953 - val_top_k_categorical_accuracy: 0.9009 - val_precision: 0.7551 - val_recall: 0.6602 - val_fmeasure: 0.7041\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 221us/step - loss: 0.4083 - acc: 0.8735 - top_k_categorical_accuracy: 0.9880 - precision: 0.9133 - recall: 0.8349 - fmeasure: 0.8719 - val_loss: 10.3328 - val_acc: 0.0663 - val_top_k_categorical_accuracy: 0.1963 - val_precision: 0.0667 - val_recall: 0.0522 - val_fmeasure: 0.0586\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.8342 - acc: 0.7661 - top_k_categorical_accuracy: 0.9529 - precision: 0.8331 - recall: 0.7192 - fmeasure: 0.7713 - val_loss: 1.5117 - val_acc: 0.6886 - val_top_k_categorical_accuracy: 0.9012 - val_precision: 0.7448 - val_recall: 0.6535 - val_fmeasure: 0.6959\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.3855 - acc: 0.8799 - top_k_categorical_accuracy: 0.9885 - precision: 0.9218 - recall: 0.8443 - fmeasure: 0.8809 - val_loss: 11.1316 - val_acc: 0.0576 - val_top_k_categorical_accuracy: 0.1881 - val_precision: 0.0625 - val_recall: 0.0508 - val_fmeasure: 0.0560\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.8402 - acc: 0.7633 - top_k_categorical_accuracy: 0.9544 - precision: 0.8279 - recall: 0.7176 - fmeasure: 0.7682 - val_loss: 1.5299 - val_acc: 0.6787 - val_top_k_categorical_accuracy: 0.9070 - val_precision: 0.7268 - val_recall: 0.6476 - val_fmeasure: 0.6846\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.3711 - acc: 0.8848 - top_k_categorical_accuracy: 0.9885 - precision: 0.9230 - recall: 0.8492 - fmeasure: 0.8842 - val_loss: 10.8872 - val_acc: 0.0710 - val_top_k_categorical_accuracy: 0.2154 - val_precision: 0.0726 - val_recall: 0.0607 - val_fmeasure: 0.0660\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.8229 - acc: 0.7689 - top_k_categorical_accuracy: 0.9556 - precision: 0.8299 - recall: 0.7242 - fmeasure: 0.7729 - val_loss: 1.3266 - val_acc: 0.7206 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.7832 - val_recall: 0.6947 - val_fmeasure: 0.7360\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.3516 - acc: 0.8915 - top_k_categorical_accuracy: 0.9890 - precision: 0.9274 - recall: 0.8589 - fmeasure: 0.8915 - val_loss: 10.6252 - val_acc: 0.0691 - val_top_k_categorical_accuracy: 0.2112 - val_precision: 0.0643 - val_recall: 0.0517 - val_fmeasure: 0.0573\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.7912 - acc: 0.7742 - top_k_categorical_accuracy: 0.9608 - precision: 0.8360 - recall: 0.7312 - fmeasure: 0.7795 - val_loss: 1.5467 - val_acc: 0.6816 - val_top_k_categorical_accuracy: 0.9059 - val_precision: 0.7400 - val_recall: 0.6523 - val_fmeasure: 0.6930\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 221us/step - loss: 0.3490 - acc: 0.8923 - top_k_categorical_accuracy: 0.9910 - precision: 0.9251 - recall: 0.8614 - fmeasure: 0.8918 - val_loss: 11.3464 - val_acc: 0.0629 - val_top_k_categorical_accuracy: 0.1969 - val_precision: 0.0662 - val_recall: 0.0556 - val_fmeasure: 0.0604\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.7442 - acc: 0.7866 - top_k_categorical_accuracy: 0.9659 - precision: 0.8404 - recall: 0.7414 - fmeasure: 0.7874 - val_loss: 1.5050 - val_acc: 0.7001 - val_top_k_categorical_accuracy: 0.8955 - val_precision: 0.7500 - val_recall: 0.6669 - val_fmeasure: 0.7056\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.3283 - acc: 0.8964 - top_k_categorical_accuracy: 0.9908 - precision: 0.9299 - recall: 0.8672 - fmeasure: 0.8972 - val_loss: 10.2013 - val_acc: 0.0688 - val_top_k_categorical_accuracy: 0.1994 - val_precision: 0.0770 - val_recall: 0.0609 - val_fmeasure: 0.0680\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.7498 - acc: 0.7834 - top_k_categorical_accuracy: 0.9648 - precision: 0.8408 - recall: 0.7430 - fmeasure: 0.7884 - val_loss: 1.6273 - val_acc: 0.6664 - val_top_k_categorical_accuracy: 0.8933 - val_precision: 0.7266 - val_recall: 0.6341 - val_fmeasure: 0.6768\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 228us/step - loss: 0.3268 - acc: 0.8980 - top_k_categorical_accuracy: 0.9913 - precision: 0.9296 - recall: 0.8688 - fmeasure: 0.8978 - val_loss: 9.9621 - val_acc: 0.0764 - val_top_k_categorical_accuracy: 0.2238 - val_precision: 0.0860 - val_recall: 0.0671 - val_fmeasure: 0.0753\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.7073 - acc: 0.7921 - top_k_categorical_accuracy: 0.9675 - precision: 0.8477 - recall: 0.7526 - fmeasure: 0.7969 - val_loss: 1.5360 - val_acc: 0.6874 - val_top_k_categorical_accuracy: 0.8989 - val_precision: 0.7415 - val_recall: 0.6459 - val_fmeasure: 0.6900\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 218us/step - loss: 0.3194 - acc: 0.9002 - top_k_categorical_accuracy: 0.9921 - precision: 0.9294 - recall: 0.8715 - fmeasure: 0.8992 - val_loss: 10.4367 - val_acc: 0.0727 - val_top_k_categorical_accuracy: 0.2235 - val_precision: 0.0784 - val_recall: 0.0643 - val_fmeasure: 0.0706\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.7012 - acc: 0.7935 - top_k_categorical_accuracy: 0.9671 - precision: 0.8515 - recall: 0.7536 - fmeasure: 0.7992 - val_loss: 1.3973 - val_acc: 0.7206 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7611 - val_recall: 0.6900 - val_fmeasure: 0.7235\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.2950 - acc: 0.9070 - top_k_categorical_accuracy: 0.9922 - precision: 0.9347 - recall: 0.8816 - fmeasure: 0.9071 - val_loss: 11.0996 - val_acc: 0.0688 - val_top_k_categorical_accuracy: 0.2056 - val_precision: 0.0693 - val_recall: 0.0576 - val_fmeasure: 0.0628\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.7068 - acc: 0.7992 - top_k_categorical_accuracy: 0.9670 - precision: 0.8532 - recall: 0.7589 - fmeasure: 0.8028 - val_loss: 1.3824 - val_acc: 0.7183 - val_top_k_categorical_accuracy: 0.9115 - val_precision: 0.7712 - val_recall: 0.6883 - val_fmeasure: 0.7270\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.2977 - acc: 0.9080 - top_k_categorical_accuracy: 0.9926 - precision: 0.9347 - recall: 0.8819 - fmeasure: 0.9073 - val_loss: 10.3528 - val_acc: 0.0629 - val_top_k_categorical_accuracy: 0.2207 - val_precision: 0.0691 - val_recall: 0.0559 - val_fmeasure: 0.0617\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 234us/step - loss: 0.6836 - acc: 0.7988 - top_k_categorical_accuracy: 0.9700 - precision: 0.8467 - recall: 0.7608 - fmeasure: 0.8010 - val_loss: 1.3571 - val_acc: 0.7254 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7672 - val_recall: 0.7023 - val_fmeasure: 0.7331\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.2865 - acc: 0.9106 - top_k_categorical_accuracy: 0.9933 - precision: 0.9359 - recall: 0.8866 - fmeasure: 0.9103 - val_loss: 10.3558 - val_acc: 0.0710 - val_top_k_categorical_accuracy: 0.2176 - val_precision: 0.0752 - val_recall: 0.0618 - val_fmeasure: 0.0678\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 233us/step - loss: 0.6564 - acc: 0.8087 - top_k_categorical_accuracy: 0.9718 - precision: 0.8553 - recall: 0.7725 - fmeasure: 0.8114 - val_loss: 1.3921 - val_acc: 0.7169 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.7638 - val_recall: 0.6956 - val_fmeasure: 0.7279\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.2716 - acc: 0.9156 - top_k_categorical_accuracy: 0.9936 - precision: 0.9413 - recall: 0.8920 - fmeasure: 0.9157 - val_loss: 11.1430 - val_acc: 0.0646 - val_top_k_categorical_accuracy: 0.2070 - val_precision: 0.0648 - val_recall: 0.0556 - val_fmeasure: 0.0598\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.6753 - acc: 0.8052 - top_k_categorical_accuracy: 0.9736 - precision: 0.8535 - recall: 0.7672 - fmeasure: 0.8076 - val_loss: 1.5044 - val_acc: 0.7009 - val_top_k_categorical_accuracy: 0.9059 - val_precision: 0.7435 - val_recall: 0.6740 - val_fmeasure: 0.7069\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.4966 - acc: 0.8507 - top_k_categorical_accuracy: 0.9829 - precision: 0.8910 - recall: 0.8180 - fmeasure: 0.8527 - val_loss: 1.0361 - val_acc: 0.8023 - val_top_k_categorical_accuracy: 0.9416 - val_precision: 0.8395 - val_recall: 0.7863 - val_fmeasure: 0.8119\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.4627 - acc: 0.8529 - top_k_categorical_accuracy: 0.9836 - precision: 0.8924 - recall: 0.8261 - fmeasure: 0.8576 - val_loss: 1.0028 - val_acc: 0.8043 - val_top_k_categorical_accuracy: 0.9430 - val_precision: 0.8333 - val_recall: 0.7866 - val_fmeasure: 0.8091\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.4188 - acc: 0.8685 - top_k_categorical_accuracy: 0.9876 - precision: 0.9030 - recall: 0.8393 - fmeasure: 0.8698 - val_loss: 0.9637 - val_acc: 0.8079 - val_top_k_categorical_accuracy: 0.9444 - val_precision: 0.8468 - val_recall: 0.7928 - val_fmeasure: 0.8187\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.3867 - acc: 0.8771 - top_k_categorical_accuracy: 0.9898 - precision: 0.9124 - recall: 0.8477 - fmeasure: 0.8786 - val_loss: 0.9908 - val_acc: 0.8127 - val_top_k_categorical_accuracy: 0.9424 - val_precision: 0.8427 - val_recall: 0.7956 - val_fmeasure: 0.8182\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3835 - acc: 0.8795 - top_k_categorical_accuracy: 0.9902 - precision: 0.9076 - recall: 0.8501 - fmeasure: 0.8777 - val_loss: 1.0393 - val_acc: 0.8017 - val_top_k_categorical_accuracy: 0.9444 - val_precision: 0.8303 - val_recall: 0.7863 - val_fmeasure: 0.8075\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.3739 - acc: 0.8785 - top_k_categorical_accuracy: 0.9892 - precision: 0.9109 - recall: 0.8518 - fmeasure: 0.8801 - val_loss: 1.0189 - val_acc: 0.8074 - val_top_k_categorical_accuracy: 0.9444 - val_precision: 0.8362 - val_recall: 0.7871 - val_fmeasure: 0.8107\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3630 - acc: 0.8803 - top_k_categorical_accuracy: 0.9910 - precision: 0.9117 - recall: 0.8517 - fmeasure: 0.8805 - val_loss: 1.0101 - val_acc: 0.8082 - val_top_k_categorical_accuracy: 0.9430 - val_precision: 0.8412 - val_recall: 0.7930 - val_fmeasure: 0.8162\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.3335 - acc: 0.8901 - top_k_categorical_accuracy: 0.9930 - precision: 0.9151 - recall: 0.8677 - fmeasure: 0.8906 - val_loss: 0.9806 - val_acc: 0.8149 - val_top_k_categorical_accuracy: 0.9466 - val_precision: 0.8422 - val_recall: 0.8040 - val_fmeasure: 0.8225\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.3353 - acc: 0.8864 - top_k_categorical_accuracy: 0.9918 - precision: 0.9165 - recall: 0.8618 - fmeasure: 0.8881 - val_loss: 0.9989 - val_acc: 0.8054 - val_top_k_categorical_accuracy: 0.9455 - val_precision: 0.8396 - val_recall: 0.7852 - val_fmeasure: 0.8113\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.3295 - acc: 0.8878 - top_k_categorical_accuracy: 0.9948 - precision: 0.9152 - recall: 0.8642 - fmeasure: 0.8888 - val_loss: 0.9428 - val_acc: 0.8180 - val_top_k_categorical_accuracy: 0.9469 - val_precision: 0.8494 - val_recall: 0.8051 - val_fmeasure: 0.8265\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.3100 - acc: 0.8971 - top_k_categorical_accuracy: 0.9949 - precision: 0.9223 - recall: 0.8731 - fmeasure: 0.8968 - val_loss: 1.0300 - val_acc: 0.8113 - val_top_k_categorical_accuracy: 0.9424 - val_precision: 0.8393 - val_recall: 0.7936 - val_fmeasure: 0.8156\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3047 - acc: 0.8982 - top_k_categorical_accuracy: 0.9954 - precision: 0.9247 - recall: 0.8801 - fmeasure: 0.9016 - val_loss: 0.9895 - val_acc: 0.8180 - val_top_k_categorical_accuracy: 0.9452 - val_precision: 0.8453 - val_recall: 0.8037 - val_fmeasure: 0.8238\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3126 - acc: 0.8960 - top_k_categorical_accuracy: 0.9935 - precision: 0.9229 - recall: 0.8735 - fmeasure: 0.8974 - val_loss: 0.9899 - val_acc: 0.8147 - val_top_k_categorical_accuracy: 0.9469 - val_precision: 0.8398 - val_recall: 0.8034 - val_fmeasure: 0.8211\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.2877 - acc: 0.9083 - top_k_categorical_accuracy: 0.9952 - precision: 0.9320 - recall: 0.8864 - fmeasure: 0.9085 - val_loss: 0.9634 - val_acc: 0.8169 - val_top_k_categorical_accuracy: 0.9486 - val_precision: 0.8473 - val_recall: 0.7981 - val_fmeasure: 0.8218\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.2813 - acc: 0.9077 - top_k_categorical_accuracy: 0.9941 - precision: 0.9293 - recall: 0.8842 - fmeasure: 0.9060 - val_loss: 1.0033 - val_acc: 0.8102 - val_top_k_categorical_accuracy: 0.9455 - val_precision: 0.8438 - val_recall: 0.7984 - val_fmeasure: 0.8203\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.2977 - acc: 0.8991 - top_k_categorical_accuracy: 0.9953 - precision: 0.9246 - recall: 0.8775 - fmeasure: 0.9002 - val_loss: 1.0168 - val_acc: 0.8135 - val_top_k_categorical_accuracy: 0.9438 - val_precision: 0.8410 - val_recall: 0.7964 - val_fmeasure: 0.8180\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.2764 - acc: 0.9048 - top_k_categorical_accuracy: 0.9959 - precision: 0.9274 - recall: 0.8865 - fmeasure: 0.9063 - val_loss: 1.0298 - val_acc: 0.8068 - val_top_k_categorical_accuracy: 0.9430 - val_precision: 0.8318 - val_recall: 0.7899 - val_fmeasure: 0.8102\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2663 - acc: 0.9127 - top_k_categorical_accuracy: 0.9967 - precision: 0.9328 - recall: 0.8919 - fmeasure: 0.9117 - val_loss: 1.0048 - val_acc: 0.8147 - val_top_k_categorical_accuracy: 0.9455 - val_precision: 0.8478 - val_recall: 0.8003 - val_fmeasure: 0.8232\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2508 - acc: 0.9145 - top_k_categorical_accuracy: 0.9965 - precision: 0.9348 - recall: 0.8967 - fmeasure: 0.9152 - val_loss: 0.9996 - val_acc: 0.8253 - val_top_k_categorical_accuracy: 0.9464 - val_precision: 0.8479 - val_recall: 0.8175 - val_fmeasure: 0.8322\n",
            "deleting......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 4s 469us/step - loss: 4.0703 - acc: 0.1071 - top_k_categorical_accuracy: 0.3190 - precision: 0.2142 - recall: 0.0105 - fmeasure: 0.0197 - val_loss: 2.9889 - val_acc: 0.2912 - val_top_k_categorical_accuracy: 0.5875 - val_precision: 0.6819 - val_recall: 0.0713 - val_fmeasure: 0.1276\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 2.9372 - acc: 0.3029 - top_k_categorical_accuracy: 0.6084 - precision: 0.5908 - recall: 0.0939 - fmeasure: 0.1601 - val_loss: 2.1888 - val_acc: 0.4774 - val_top_k_categorical_accuracy: 0.7523 - val_precision: 0.8138 - val_recall: 0.2665 - val_fmeasure: 0.3995\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 2.3513 - acc: 0.4353 - top_k_categorical_accuracy: 0.7354 - precision: 0.6986 - recall: 0.2071 - fmeasure: 0.3155 - val_loss: 1.9075 - val_acc: 0.5571 - val_top_k_categorical_accuracy: 0.7942 - val_precision: 0.7786 - val_recall: 0.4041 - val_fmeasure: 0.5307\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.9889 - acc: 0.5251 - top_k_categorical_accuracy: 0.7950 - precision: 0.7545 - recall: 0.3158 - fmeasure: 0.4436 - val_loss: 1.8399 - val_acc: 0.5695 - val_top_k_categorical_accuracy: 0.8189 - val_precision: 0.7352 - val_recall: 0.4617 - val_fmeasure: 0.5662\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.7485 - acc: 0.5825 - top_k_categorical_accuracy: 0.8360 - precision: 0.7787 - recall: 0.3883 - fmeasure: 0.5167 - val_loss: 1.6761 - val_acc: 0.6111 - val_top_k_categorical_accuracy: 0.8349 - val_precision: 0.7409 - val_recall: 0.5122 - val_fmeasure: 0.6044\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.5561 - acc: 0.6293 - top_k_categorical_accuracy: 0.8599 - precision: 0.8054 - recall: 0.4566 - fmeasure: 0.5816 - val_loss: 1.7724 - val_acc: 0.5872 - val_top_k_categorical_accuracy: 0.8256 - val_precision: 0.7314 - val_recall: 0.5066 - val_fmeasure: 0.5978\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.4236 - acc: 0.6552 - top_k_categorical_accuracy: 0.8766 - precision: 0.8227 - recall: 0.5021 - fmeasure: 0.6222 - val_loss: 1.4272 - val_acc: 0.6793 - val_top_k_categorical_accuracy: 0.8630 - val_precision: 0.8020 - val_recall: 0.5996 - val_fmeasure: 0.6852\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.3302 - acc: 0.6718 - top_k_categorical_accuracy: 0.8896 - precision: 0.8225 - recall: 0.5363 - fmeasure: 0.6480 - val_loss: 1.4414 - val_acc: 0.6599 - val_top_k_categorical_accuracy: 0.8705 - val_precision: 0.7923 - val_recall: 0.5743 - val_fmeasure: 0.6651\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.2282 - acc: 0.6927 - top_k_categorical_accuracy: 0.9023 - precision: 0.8319 - recall: 0.5729 - fmeasure: 0.6774 - val_loss: 1.5019 - val_acc: 0.6498 - val_top_k_categorical_accuracy: 0.8728 - val_precision: 0.7500 - val_recall: 0.5920 - val_fmeasure: 0.6609\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.1409 - acc: 0.7170 - top_k_categorical_accuracy: 0.9091 - precision: 0.8474 - recall: 0.6023 - fmeasure: 0.7032 - val_loss: 1.2763 - val_acc: 0.7116 - val_top_k_categorical_accuracy: 0.8950 - val_precision: 0.8130 - val_recall: 0.6344 - val_fmeasure: 0.7119\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 1.0675 - acc: 0.7353 - top_k_categorical_accuracy: 0.9205 - precision: 0.8511 - recall: 0.6278 - fmeasure: 0.7217 - val_loss: 1.2718 - val_acc: 0.7074 - val_top_k_categorical_accuracy: 0.8958 - val_precision: 0.8057 - val_recall: 0.6439 - val_fmeasure: 0.7151\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.9921 - acc: 0.7505 - top_k_categorical_accuracy: 0.9275 - precision: 0.8609 - recall: 0.6480 - fmeasure: 0.7386 - val_loss: 1.3714 - val_acc: 0.6855 - val_top_k_categorical_accuracy: 0.8792 - val_precision: 0.7864 - val_recall: 0.6209 - val_fmeasure: 0.6934\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.9660 - acc: 0.7535 - top_k_categorical_accuracy: 0.9301 - precision: 0.8584 - recall: 0.6596 - fmeasure: 0.7449 - val_loss: 1.2491 - val_acc: 0.7113 - val_top_k_categorical_accuracy: 0.8975 - val_precision: 0.7987 - val_recall: 0.6563 - val_fmeasure: 0.7199\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 234us/step - loss: 0.8908 - acc: 0.7704 - top_k_categorical_accuracy: 0.9427 - precision: 0.8642 - recall: 0.6770 - fmeasure: 0.7584 - val_loss: 1.2013 - val_acc: 0.7195 - val_top_k_categorical_accuracy: 0.9040 - val_precision: 0.8155 - val_recall: 0.6709 - val_fmeasure: 0.7357\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.8577 - acc: 0.7775 - top_k_categorical_accuracy: 0.9461 - precision: 0.8688 - recall: 0.6971 - fmeasure: 0.7729 - val_loss: 1.1955 - val_acc: 0.7259 - val_top_k_categorical_accuracy: 0.9054 - val_precision: 0.8168 - val_recall: 0.6757 - val_fmeasure: 0.7391\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.8256 - acc: 0.7838 - top_k_categorical_accuracy: 0.9475 - precision: 0.8745 - recall: 0.7086 - fmeasure: 0.7822 - val_loss: 1.1633 - val_acc: 0.7433 - val_top_k_categorical_accuracy: 0.9118 - val_precision: 0.8176 - val_recall: 0.6939 - val_fmeasure: 0.7502\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.7644 - acc: 0.7980 - top_k_categorical_accuracy: 0.9540 - precision: 0.8768 - recall: 0.7251 - fmeasure: 0.7931 - val_loss: 1.2276 - val_acc: 0.7301 - val_top_k_categorical_accuracy: 0.9062 - val_precision: 0.7978 - val_recall: 0.6931 - val_fmeasure: 0.7412\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.7525 - acc: 0.7966 - top_k_categorical_accuracy: 0.9575 - precision: 0.8786 - recall: 0.7255 - fmeasure: 0.7941 - val_loss: 1.1393 - val_acc: 0.7478 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.8181 - val_recall: 0.7012 - val_fmeasure: 0.7547\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.7041 - acc: 0.8106 - top_k_categorical_accuracy: 0.9591 - precision: 0.8850 - recall: 0.7500 - fmeasure: 0.8114 - val_loss: 1.1327 - val_acc: 0.7470 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.8186 - val_recall: 0.7026 - val_fmeasure: 0.7558\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6707 - acc: 0.8171 - top_k_categorical_accuracy: 0.9615 - precision: 0.8918 - recall: 0.7556 - fmeasure: 0.8175 - val_loss: 1.1794 - val_acc: 0.7380 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.8021 - val_recall: 0.6998 - val_fmeasure: 0.7471\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6309 - acc: 0.8258 - top_k_categorical_accuracy: 0.9675 - precision: 0.8903 - recall: 0.7662 - fmeasure: 0.8231 - val_loss: 1.1327 - val_acc: 0.7565 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.8119 - val_recall: 0.7178 - val_fmeasure: 0.7617\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 2.3861 - acc: 0.4317 - top_k_categorical_accuracy: 0.7393 - precision: 0.6015 - recall: 0.2901 - fmeasure: 0.3877 - val_loss: 4.9866 - val_acc: 0.0980 - val_top_k_categorical_accuracy: 0.3260 - val_precision: 0.1360 - val_recall: 0.0578 - val_fmeasure: 0.0809\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 1.6369 - acc: 0.5936 - top_k_categorical_accuracy: 0.8436 - precision: 0.7409 - recall: 0.4629 - fmeasure: 0.5641 - val_loss: 1.1075 - val_acc: 0.7386 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.8579 - val_recall: 0.6588 - val_fmeasure: 0.7446\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.6442 - acc: 0.5749 - top_k_categorical_accuracy: 0.8529 - precision: 0.7303 - recall: 0.4371 - fmeasure: 0.5447 - val_loss: 5.1588 - val_acc: 0.0932 - val_top_k_categorical_accuracy: 0.3061 - val_precision: 0.1280 - val_recall: 0.0654 - val_fmeasure: 0.0863\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.5761 - acc: 0.6039 - top_k_categorical_accuracy: 0.8557 - precision: 0.7469 - recall: 0.4819 - fmeasure: 0.5825 - val_loss: 1.2260 - val_acc: 0.7099 - val_top_k_categorical_accuracy: 0.8992 - val_precision: 0.8164 - val_recall: 0.6282 - val_fmeasure: 0.7093\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.3990 - acc: 0.6340 - top_k_categorical_accuracy: 0.8852 - precision: 0.7689 - recall: 0.5075 - fmeasure: 0.6095 - val_loss: 4.5082 - val_acc: 0.1143 - val_top_k_categorical_accuracy: 0.4159 - val_precision: 0.1403 - val_recall: 0.0694 - val_fmeasure: 0.0926\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 1.4623 - acc: 0.6324 - top_k_categorical_accuracy: 0.8653 - precision: 0.7686 - recall: 0.5132 - fmeasure: 0.6119 - val_loss: 1.1668 - val_acc: 0.7293 - val_top_k_categorical_accuracy: 0.9068 - val_precision: 0.8393 - val_recall: 0.6622 - val_fmeasure: 0.7394\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.2278 - acc: 0.6750 - top_k_categorical_accuracy: 0.9068 - precision: 0.8011 - recall: 0.5604 - fmeasure: 0.6576 - val_loss: 4.3554 - val_acc: 0.1188 - val_top_k_categorical_accuracy: 0.4619 - val_precision: 0.1444 - val_recall: 0.0803 - val_fmeasure: 0.1030\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 1.4077 - acc: 0.6398 - top_k_categorical_accuracy: 0.8779 - precision: 0.7700 - recall: 0.5322 - fmeasure: 0.6261 - val_loss: 1.3691 - val_acc: 0.6793 - val_top_k_categorical_accuracy: 0.8835 - val_precision: 0.7823 - val_recall: 0.6201 - val_fmeasure: 0.6913\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.1174 - acc: 0.6986 - top_k_categorical_accuracy: 0.9203 - precision: 0.8171 - recall: 0.5929 - fmeasure: 0.6853 - val_loss: 3.9748 - val_acc: 0.1679 - val_top_k_categorical_accuracy: 0.5285 - val_precision: 0.1968 - val_recall: 0.1081 - val_fmeasure: 0.1392\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 1.3359 - acc: 0.6596 - top_k_categorical_accuracy: 0.8883 - precision: 0.7787 - recall: 0.5486 - fmeasure: 0.6413 - val_loss: 1.0600 - val_acc: 0.7596 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.8404 - val_recall: 0.7049 - val_fmeasure: 0.7660\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 1.0285 - acc: 0.7207 - top_k_categorical_accuracy: 0.9326 - precision: 0.8243 - recall: 0.6232 - fmeasure: 0.7081 - val_loss: 3.8592 - val_acc: 0.1862 - val_top_k_categorical_accuracy: 0.5782 - val_precision: 0.2210 - val_recall: 0.1275 - val_fmeasure: 0.1612\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 1.2746 - acc: 0.6706 - top_k_categorical_accuracy: 0.8959 - precision: 0.7881 - recall: 0.5600 - fmeasure: 0.6526 - val_loss: 1.3806 - val_acc: 0.6866 - val_top_k_categorical_accuracy: 0.8910 - val_precision: 0.7792 - val_recall: 0.6206 - val_fmeasure: 0.6903\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 227us/step - loss: 0.9637 - acc: 0.7372 - top_k_categorical_accuracy: 0.9388 - precision: 0.8344 - recall: 0.6465 - fmeasure: 0.7272 - val_loss: 3.5942 - val_acc: 0.2373 - val_top_k_categorical_accuracy: 0.6186 - val_precision: 0.2710 - val_recall: 0.1665 - val_fmeasure: 0.2059\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 253us/step - loss: 1.1948 - acc: 0.6836 - top_k_categorical_accuracy: 0.9059 - precision: 0.7957 - recall: 0.5783 - fmeasure: 0.6677 - val_loss: 1.1071 - val_acc: 0.7487 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.8338 - val_recall: 0.6973 - val_fmeasure: 0.7589\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 0.8956 - acc: 0.7530 - top_k_categorical_accuracy: 0.9484 - precision: 0.8436 - recall: 0.6657 - fmeasure: 0.7429 - val_loss: 3.6605 - val_acc: 0.2235 - val_top_k_categorical_accuracy: 0.6282 - val_precision: 0.2443 - val_recall: 0.1528 - val_fmeasure: 0.1876\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 1.1830 - acc: 0.6942 - top_k_categorical_accuracy: 0.9110 - precision: 0.8033 - recall: 0.5922 - fmeasure: 0.6795 - val_loss: 1.1748 - val_acc: 0.7357 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.8158 - val_recall: 0.6942 - val_fmeasure: 0.7497\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.8462 - acc: 0.7643 - top_k_categorical_accuracy: 0.9518 - precision: 0.8477 - recall: 0.6853 - fmeasure: 0.7568 - val_loss: 3.6137 - val_acc: 0.2241 - val_top_k_categorical_accuracy: 0.6161 - val_precision: 0.2586 - val_recall: 0.1528 - val_fmeasure: 0.1916\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 1.1300 - acc: 0.7025 - top_k_categorical_accuracy: 0.9166 - precision: 0.8037 - recall: 0.6053 - fmeasure: 0.6887 - val_loss: 1.1785 - val_acc: 0.7313 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.8139 - val_recall: 0.6866 - val_fmeasure: 0.7443\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 219us/step - loss: 0.8095 - acc: 0.7716 - top_k_categorical_accuracy: 0.9551 - precision: 0.8524 - recall: 0.6954 - fmeasure: 0.7648 - val_loss: 3.2161 - val_acc: 0.2926 - val_top_k_categorical_accuracy: 0.6759 - val_precision: 0.3357 - val_recall: 0.2061 - val_fmeasure: 0.2549\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 1.0667 - acc: 0.7176 - top_k_categorical_accuracy: 0.9245 - precision: 0.8170 - recall: 0.6292 - fmeasure: 0.7088 - val_loss: 1.1146 - val_acc: 0.7512 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.8198 - val_recall: 0.7046 - val_fmeasure: 0.7572\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.7623 - acc: 0.7839 - top_k_categorical_accuracy: 0.9612 - precision: 0.8594 - recall: 0.7110 - fmeasure: 0.7772 - val_loss: 3.2054 - val_acc: 0.3075 - val_top_k_categorical_accuracy: 0.6897 - val_precision: 0.3717 - val_recall: 0.2395 - val_fmeasure: 0.2906\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.0505 - acc: 0.7196 - top_k_categorical_accuracy: 0.9236 - precision: 0.8183 - recall: 0.6307 - fmeasure: 0.7107 - val_loss: 1.0148 - val_acc: 0.7815 - val_top_k_categorical_accuracy: 0.9315 - val_precision: 0.8434 - val_recall: 0.7445 - val_fmeasure: 0.7904\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.7329 - acc: 0.7903 - top_k_categorical_accuracy: 0.9642 - precision: 0.8637 - recall: 0.7238 - fmeasure: 0.7866 - val_loss: 3.1349 - val_acc: 0.3227 - val_top_k_categorical_accuracy: 0.7051 - val_precision: 0.3889 - val_recall: 0.2640 - val_fmeasure: 0.3140\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 1.0302 - acc: 0.7246 - top_k_categorical_accuracy: 0.9304 - precision: 0.8209 - recall: 0.6433 - fmeasure: 0.7200 - val_loss: 1.0337 - val_acc: 0.7756 - val_top_k_categorical_accuracy: 0.9298 - val_precision: 0.8451 - val_recall: 0.7293 - val_fmeasure: 0.7826\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.6956 - acc: 0.7979 - top_k_categorical_accuracy: 0.9680 - precision: 0.8693 - recall: 0.7317 - fmeasure: 0.7937 - val_loss: 2.9397 - val_acc: 0.3477 - val_top_k_categorical_accuracy: 0.7377 - val_precision: 0.3992 - val_recall: 0.2693 - val_fmeasure: 0.3210\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.9577 - acc: 0.7403 - top_k_categorical_accuracy: 0.9345 - precision: 0.8299 - recall: 0.6627 - fmeasure: 0.7359 - val_loss: 0.9578 - val_acc: 0.7911 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8590 - val_recall: 0.7529 - val_fmeasure: 0.8020\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.6693 - acc: 0.8053 - top_k_categorical_accuracy: 0.9681 - precision: 0.8717 - recall: 0.7435 - fmeasure: 0.8017 - val_loss: 3.2858 - val_acc: 0.3176 - val_top_k_categorical_accuracy: 0.6987 - val_precision: 0.3637 - val_recall: 0.2541 - val_fmeasure: 0.2987\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.9646 - acc: 0.7372 - top_k_categorical_accuracy: 0.9364 - precision: 0.8269 - recall: 0.6634 - fmeasure: 0.7348 - val_loss: 1.0309 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9315 - val_precision: 0.8355 - val_recall: 0.7363 - val_fmeasure: 0.7824\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.6538 - acc: 0.8109 - top_k_categorical_accuracy: 0.9713 - precision: 0.8766 - recall: 0.7519 - fmeasure: 0.8086 - val_loss: 3.0790 - val_acc: 0.3448 - val_top_k_categorical_accuracy: 0.7349 - val_precision: 0.3908 - val_recall: 0.2777 - val_fmeasure: 0.3240\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.9321 - acc: 0.7423 - top_k_categorical_accuracy: 0.9441 - precision: 0.8314 - recall: 0.6687 - fmeasure: 0.7400 - val_loss: 1.0259 - val_acc: 0.7700 - val_top_k_categorical_accuracy: 0.9332 - val_precision: 0.8331 - val_recall: 0.7363 - val_fmeasure: 0.7814\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 0.6309 - acc: 0.8127 - top_k_categorical_accuracy: 0.9722 - precision: 0.8764 - recall: 0.7544 - fmeasure: 0.8100 - val_loss: 3.0816 - val_acc: 0.3589 - val_top_k_categorical_accuracy: 0.7127 - val_precision: 0.4174 - val_recall: 0.2918 - val_fmeasure: 0.3429\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.9200 - acc: 0.7473 - top_k_categorical_accuracy: 0.9431 - precision: 0.8317 - recall: 0.6789 - fmeasure: 0.7465 - val_loss: 1.1643 - val_acc: 0.7456 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8104 - val_recall: 0.7110 - val_fmeasure: 0.7569\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.6117 - acc: 0.8166 - top_k_categorical_accuracy: 0.9750 - precision: 0.8774 - recall: 0.7647 - fmeasure: 0.8165 - val_loss: 2.9331 - val_acc: 0.3625 - val_top_k_categorical_accuracy: 0.7467 - val_precision: 0.4250 - val_recall: 0.3008 - val_fmeasure: 0.3517\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.8922 - acc: 0.7518 - top_k_categorical_accuracy: 0.9468 - precision: 0.8367 - recall: 0.6815 - fmeasure: 0.7504 - val_loss: 1.2359 - val_acc: 0.7335 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7971 - val_recall: 0.6956 - val_fmeasure: 0.7424\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 0.5899 - acc: 0.8239 - top_k_categorical_accuracy: 0.9776 - precision: 0.8808 - recall: 0.7661 - fmeasure: 0.8187 - val_loss: 2.9530 - val_acc: 0.3808 - val_top_k_categorical_accuracy: 0.7473 - val_precision: 0.4399 - val_recall: 0.3249 - val_fmeasure: 0.3732\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.9201 - acc: 0.7512 - top_k_categorical_accuracy: 0.9413 - precision: 0.8298 - recall: 0.6871 - fmeasure: 0.7509 - val_loss: 1.1564 - val_acc: 0.7495 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.8185 - val_recall: 0.7167 - val_fmeasure: 0.7639\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.5807 - acc: 0.8250 - top_k_categorical_accuracy: 0.9785 - precision: 0.8808 - recall: 0.7738 - fmeasure: 0.8232 - val_loss: 2.8922 - val_acc: 0.3920 - val_top_k_categorical_accuracy: 0.7543 - val_precision: 0.4348 - val_recall: 0.3193 - val_fmeasure: 0.3677\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.8442 - acc: 0.7696 - top_k_categorical_accuracy: 0.9499 - precision: 0.8466 - recall: 0.7011 - fmeasure: 0.7662 - val_loss: 0.9913 - val_acc: 0.7866 - val_top_k_categorical_accuracy: 0.9351 - val_precision: 0.8468 - val_recall: 0.7548 - val_fmeasure: 0.7979\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.5571 - acc: 0.8329 - top_k_categorical_accuracy: 0.9788 - precision: 0.8846 - recall: 0.7826 - fmeasure: 0.8298 - val_loss: 2.9508 - val_acc: 0.3901 - val_top_k_categorical_accuracy: 0.7509 - val_precision: 0.4333 - val_recall: 0.3280 - val_fmeasure: 0.3726\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.8489 - acc: 0.7633 - top_k_categorical_accuracy: 0.9493 - precision: 0.8435 - recall: 0.7041 - fmeasure: 0.7667 - val_loss: 0.9884 - val_acc: 0.7885 - val_top_k_categorical_accuracy: 0.9329 - val_precision: 0.8446 - val_recall: 0.7562 - val_fmeasure: 0.7977\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.5463 - acc: 0.8346 - top_k_categorical_accuracy: 0.9804 - precision: 0.8870 - recall: 0.7867 - fmeasure: 0.8332 - val_loss: 2.8377 - val_acc: 0.4019 - val_top_k_categorical_accuracy: 0.7582 - val_precision: 0.4610 - val_recall: 0.3387 - val_fmeasure: 0.3898\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.8140 - acc: 0.7715 - top_k_categorical_accuracy: 0.9544 - precision: 0.8463 - recall: 0.7088 - fmeasure: 0.7705 - val_loss: 1.0431 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9329 - val_precision: 0.8378 - val_recall: 0.7489 - val_fmeasure: 0.7906\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.5348 - acc: 0.8383 - top_k_categorical_accuracy: 0.9817 - precision: 0.8878 - recall: 0.7918 - fmeasure: 0.8365 - val_loss: 3.0283 - val_acc: 0.3811 - val_top_k_categorical_accuracy: 0.7523 - val_precision: 0.4285 - val_recall: 0.3286 - val_fmeasure: 0.3716\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.7949 - acc: 0.7739 - top_k_categorical_accuracy: 0.9567 - precision: 0.8479 - recall: 0.7182 - fmeasure: 0.7769 - val_loss: 1.0273 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9309 - val_precision: 0.8337 - val_recall: 0.7456 - val_fmeasure: 0.7868\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.5254 - acc: 0.8408 - top_k_categorical_accuracy: 0.9821 - precision: 0.8894 - recall: 0.7948 - fmeasure: 0.8388 - val_loss: 2.7220 - val_acc: 0.4297 - val_top_k_categorical_accuracy: 0.7801 - val_precision: 0.4887 - val_recall: 0.3704 - val_fmeasure: 0.4209\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.7754 - acc: 0.7839 - top_k_categorical_accuracy: 0.9596 - precision: 0.8538 - recall: 0.7238 - fmeasure: 0.7826 - val_loss: 1.0457 - val_acc: 0.7737 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8354 - val_recall: 0.7372 - val_fmeasure: 0.7828\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.5070 - acc: 0.8445 - top_k_categorical_accuracy: 0.9831 - precision: 0.8927 - recall: 0.8012 - fmeasure: 0.8439 - val_loss: 2.9697 - val_acc: 0.4136 - val_top_k_categorical_accuracy: 0.7669 - val_precision: 0.4642 - val_recall: 0.3600 - val_fmeasure: 0.4051\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.7759 - acc: 0.7811 - top_k_categorical_accuracy: 0.9604 - precision: 0.8495 - recall: 0.7246 - fmeasure: 0.7815 - val_loss: 1.0008 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8396 - val_recall: 0.7607 - val_fmeasure: 0.7979\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.5011 - acc: 0.8435 - top_k_categorical_accuracy: 0.9836 - precision: 0.8926 - recall: 0.8020 - fmeasure: 0.8444 - val_loss: 2.8263 - val_acc: 0.4212 - val_top_k_categorical_accuracy: 0.7720 - val_precision: 0.4834 - val_recall: 0.3639 - val_fmeasure: 0.4147\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.7555 - acc: 0.7852 - top_k_categorical_accuracy: 0.9628 - precision: 0.8476 - recall: 0.7288 - fmeasure: 0.7831 - val_loss: 1.1575 - val_acc: 0.7568 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8072 - val_recall: 0.7245 - val_fmeasure: 0.7633\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.4892 - acc: 0.8484 - top_k_categorical_accuracy: 0.9841 - precision: 0.8943 - recall: 0.8088 - fmeasure: 0.8490 - val_loss: 2.7688 - val_acc: 0.4356 - val_top_k_categorical_accuracy: 0.7753 - val_precision: 0.4940 - val_recall: 0.3839 - val_fmeasure: 0.4316\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.7475 - acc: 0.7895 - top_k_categorical_accuracy: 0.9611 - precision: 0.8559 - recall: 0.7381 - fmeasure: 0.7919 - val_loss: 1.1255 - val_acc: 0.7669 - val_top_k_categorical_accuracy: 0.9295 - val_precision: 0.8226 - val_recall: 0.7357 - val_fmeasure: 0.7765\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.4794 - acc: 0.8524 - top_k_categorical_accuracy: 0.9862 - precision: 0.8984 - recall: 0.8102 - fmeasure: 0.8516 - val_loss: 2.6439 - val_acc: 0.4336 - val_top_k_categorical_accuracy: 0.7995 - val_precision: 0.4972 - val_recall: 0.3828 - val_fmeasure: 0.4319\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.7160 - acc: 0.7929 - top_k_categorical_accuracy: 0.9651 - precision: 0.8619 - recall: 0.7372 - fmeasure: 0.7940 - val_loss: 1.0202 - val_acc: 0.7840 - val_top_k_categorical_accuracy: 0.9343 - val_precision: 0.8451 - val_recall: 0.7509 - val_fmeasure: 0.7948\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.4665 - acc: 0.8546 - top_k_categorical_accuracy: 0.9878 - precision: 0.8965 - recall: 0.8144 - fmeasure: 0.8530 - val_loss: 2.4393 - val_acc: 0.4914 - val_top_k_categorical_accuracy: 0.8124 - val_precision: 0.5452 - val_recall: 0.4440 - val_fmeasure: 0.4889\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.7142 - acc: 0.7961 - top_k_categorical_accuracy: 0.9652 - precision: 0.8578 - recall: 0.7384 - fmeasure: 0.7928 - val_loss: 1.0196 - val_acc: 0.7796 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8380 - val_recall: 0.7562 - val_fmeasure: 0.7946\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.4546 - acc: 0.8588 - top_k_categorical_accuracy: 0.9872 - precision: 0.8992 - recall: 0.8221 - fmeasure: 0.8585 - val_loss: 2.6703 - val_acc: 0.4502 - val_top_k_categorical_accuracy: 0.7978 - val_precision: 0.5059 - val_recall: 0.3965 - val_fmeasure: 0.4443\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6914 - acc: 0.7958 - top_k_categorical_accuracy: 0.9674 - precision: 0.8587 - recall: 0.7426 - fmeasure: 0.7959 - val_loss: 1.1021 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9309 - val_precision: 0.8182 - val_recall: 0.7380 - val_fmeasure: 0.7757\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.4613 - acc: 0.8564 - top_k_categorical_accuracy: 0.9853 - precision: 0.8987 - recall: 0.8212 - fmeasure: 0.8578 - val_loss: 2.6693 - val_acc: 0.4591 - val_top_k_categorical_accuracy: 0.7984 - val_precision: 0.5237 - val_recall: 0.4170 - val_fmeasure: 0.4640\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.6937 - acc: 0.8025 - top_k_categorical_accuracy: 0.9662 - precision: 0.8652 - recall: 0.7520 - fmeasure: 0.8042 - val_loss: 1.0210 - val_acc: 0.7877 - val_top_k_categorical_accuracy: 0.9365 - val_precision: 0.8382 - val_recall: 0.7596 - val_fmeasure: 0.7967\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.5197 - acc: 0.8425 - top_k_categorical_accuracy: 0.9805 - precision: 0.8945 - recall: 0.8035 - fmeasure: 0.8463 - val_loss: 0.8719 - val_acc: 0.8203 - val_top_k_categorical_accuracy: 0.9475 - val_precision: 0.8682 - val_recall: 0.7970 - val_fmeasure: 0.8307\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.4747 - acc: 0.8553 - top_k_categorical_accuracy: 0.9831 - precision: 0.9020 - recall: 0.8175 - fmeasure: 0.8573 - val_loss: 0.8916 - val_acc: 0.8206 - val_top_k_categorical_accuracy: 0.9466 - val_precision: 0.8603 - val_recall: 0.7989 - val_fmeasure: 0.8283\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.4471 - acc: 0.8595 - top_k_categorical_accuracy: 0.9853 - precision: 0.9056 - recall: 0.8252 - fmeasure: 0.8632 - val_loss: 0.8955 - val_acc: 0.8152 - val_top_k_categorical_accuracy: 0.9422 - val_precision: 0.8627 - val_recall: 0.7914 - val_fmeasure: 0.8253\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.4336 - acc: 0.8616 - top_k_categorical_accuracy: 0.9864 - precision: 0.9050 - recall: 0.8267 - fmeasure: 0.8637 - val_loss: 0.8877 - val_acc: 0.8200 - val_top_k_categorical_accuracy: 0.9461 - val_precision: 0.8655 - val_recall: 0.8017 - val_fmeasure: 0.8321\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3985 - acc: 0.8753 - top_k_categorical_accuracy: 0.9877 - precision: 0.9143 - recall: 0.8381 - fmeasure: 0.8742 - val_loss: 0.8980 - val_acc: 0.8144 - val_top_k_categorical_accuracy: 0.9450 - val_precision: 0.8553 - val_recall: 0.7975 - val_fmeasure: 0.8252\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.3826 - acc: 0.8795 - top_k_categorical_accuracy: 0.9902 - precision: 0.9182 - recall: 0.8443 - fmeasure: 0.8794 - val_loss: 0.8629 - val_acc: 0.8239 - val_top_k_categorical_accuracy: 0.9500 - val_precision: 0.8618 - val_recall: 0.8029 - val_fmeasure: 0.8311\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3722 - acc: 0.8836 - top_k_categorical_accuracy: 0.9888 - precision: 0.9202 - recall: 0.8534 - fmeasure: 0.8853 - val_loss: 0.8713 - val_acc: 0.8273 - val_top_k_categorical_accuracy: 0.9472 - val_precision: 0.8644 - val_recall: 0.8085 - val_fmeasure: 0.8353\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.3588 - acc: 0.8838 - top_k_categorical_accuracy: 0.9902 - precision: 0.9198 - recall: 0.8540 - fmeasure: 0.8855 - val_loss: 0.9611 - val_acc: 0.8057 - val_top_k_categorical_accuracy: 0.9413 - val_precision: 0.8470 - val_recall: 0.7818 - val_fmeasure: 0.8129\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3633 - acc: 0.8884 - top_k_categorical_accuracy: 0.9925 - precision: 0.9190 - recall: 0.8553 - fmeasure: 0.8858 - val_loss: 0.8916 - val_acc: 0.8211 - val_top_k_categorical_accuracy: 0.9478 - val_precision: 0.8573 - val_recall: 0.8037 - val_fmeasure: 0.8294\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.3392 - acc: 0.8903 - top_k_categorical_accuracy: 0.9919 - precision: 0.9231 - recall: 0.8626 - fmeasure: 0.8916 - val_loss: 0.9884 - val_acc: 0.7995 - val_top_k_categorical_accuracy: 0.9436 - val_precision: 0.8375 - val_recall: 0.7787 - val_fmeasure: 0.8069\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3272 - acc: 0.8931 - top_k_categorical_accuracy: 0.9922 - precision: 0.9236 - recall: 0.8670 - fmeasure: 0.8941 - val_loss: 0.9110 - val_acc: 0.8239 - val_top_k_categorical_accuracy: 0.9466 - val_precision: 0.8574 - val_recall: 0.8062 - val_fmeasure: 0.8309\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.3187 - acc: 0.8943 - top_k_categorical_accuracy: 0.9928 - precision: 0.9225 - recall: 0.8672 - fmeasure: 0.8938 - val_loss: 0.9379 - val_acc: 0.8119 - val_top_k_categorical_accuracy: 0.9464 - val_precision: 0.8499 - val_recall: 0.7894 - val_fmeasure: 0.8183\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.3218 - acc: 0.8944 - top_k_categorical_accuracy: 0.9931 - precision: 0.9221 - recall: 0.8688 - fmeasure: 0.8945 - val_loss: 0.9108 - val_acc: 0.8265 - val_top_k_categorical_accuracy: 0.9483 - val_precision: 0.8547 - val_recall: 0.8121 - val_fmeasure: 0.8328\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.3105 - acc: 0.8985 - top_k_categorical_accuracy: 0.9946 - precision: 0.9252 - recall: 0.8755 - fmeasure: 0.8994 - val_loss: 0.9624 - val_acc: 0.8158 - val_top_k_categorical_accuracy: 0.9452 - val_precision: 0.8520 - val_recall: 0.8020 - val_fmeasure: 0.8261\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2837 - acc: 0.9091 - top_k_categorical_accuracy: 0.9947 - precision: 0.9316 - recall: 0.8834 - fmeasure: 0.9067 - val_loss: 0.9174 - val_acc: 0.8152 - val_top_k_categorical_accuracy: 0.9472 - val_precision: 0.8467 - val_recall: 0.8057 - val_fmeasure: 0.8255\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 235us/step - loss: 0.2875 - acc: 0.9039 - top_k_categorical_accuracy: 0.9960 - precision: 0.9286 - recall: 0.8831 - fmeasure: 0.9051 - val_loss: 0.9465 - val_acc: 0.8155 - val_top_k_categorical_accuracy: 0.9478 - val_precision: 0.8432 - val_recall: 0.8048 - val_fmeasure: 0.8234\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.2766 - acc: 0.9097 - top_k_categorical_accuracy: 0.9946 - precision: 0.9315 - recall: 0.8842 - fmeasure: 0.9070 - val_loss: 0.9845 - val_acc: 0.8124 - val_top_k_categorical_accuracy: 0.9441 - val_precision: 0.8450 - val_recall: 0.7936 - val_fmeasure: 0.8183\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.2681 - acc: 0.9073 - top_k_categorical_accuracy: 0.9955 - precision: 0.9293 - recall: 0.8871 - fmeasure: 0.9076 - val_loss: 0.9567 - val_acc: 0.8144 - val_top_k_categorical_accuracy: 0.9480 - val_precision: 0.8454 - val_recall: 0.8037 - val_fmeasure: 0.8239\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.2697 - acc: 0.9061 - top_k_categorical_accuracy: 0.9955 - precision: 0.9330 - recall: 0.8844 - fmeasure: 0.9078 - val_loss: 0.9080 - val_acc: 0.8225 - val_top_k_categorical_accuracy: 0.9509 - val_precision: 0.8501 - val_recall: 0.8051 - val_fmeasure: 0.8268\n",
            "shuffling......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 4s 516us/step - loss: 4.0686 - acc: 0.1095 - top_k_categorical_accuracy: 0.3164 - precision: 0.2236 - recall: 0.0147 - fmeasure: 0.0271 - val_loss: 2.8222 - val_acc: 0.3193 - val_top_k_categorical_accuracy: 0.6344 - val_precision: 0.7291 - val_recall: 0.0941 - val_fmeasure: 0.1645\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 2.8963 - acc: 0.3054 - top_k_categorical_accuracy: 0.6196 - precision: 0.6215 - recall: 0.1024 - fmeasure: 0.1736 - val_loss: 2.3616 - val_acc: 0.4389 - val_top_k_categorical_accuracy: 0.7307 - val_precision: 0.7420 - val_recall: 0.2350 - val_fmeasure: 0.3549\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 2.3070 - acc: 0.4447 - top_k_categorical_accuracy: 0.7440 - precision: 0.7271 - recall: 0.2229 - fmeasure: 0.3386 - val_loss: 1.9259 - val_acc: 0.5605 - val_top_k_categorical_accuracy: 0.8012 - val_precision: 0.7904 - val_recall: 0.4061 - val_fmeasure: 0.5350\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.9683 - acc: 0.5277 - top_k_categorical_accuracy: 0.8045 - precision: 0.7553 - recall: 0.3118 - fmeasure: 0.4396 - val_loss: 1.7375 - val_acc: 0.6043 - val_top_k_categorical_accuracy: 0.8239 - val_precision: 0.7790 - val_recall: 0.4768 - val_fmeasure: 0.5901\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.7377 - acc: 0.5807 - top_k_categorical_accuracy: 0.8374 - precision: 0.7830 - recall: 0.3941 - fmeasure: 0.5222 - val_loss: 1.7482 - val_acc: 0.5951 - val_top_k_categorical_accuracy: 0.8309 - val_precision: 0.7421 - val_recall: 0.4912 - val_fmeasure: 0.5898\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 1.5814 - acc: 0.6213 - top_k_categorical_accuracy: 0.8547 - precision: 0.8016 - recall: 0.4570 - fmeasure: 0.5807 - val_loss: 1.5123 - val_acc: 0.6501 - val_top_k_categorical_accuracy: 0.8537 - val_precision: 0.7884 - val_recall: 0.5574 - val_fmeasure: 0.6522\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 1.4405 - acc: 0.6508 - top_k_categorical_accuracy: 0.8735 - precision: 0.8238 - recall: 0.4978 - fmeasure: 0.6192 - val_loss: 1.4081 - val_acc: 0.6759 - val_top_k_categorical_accuracy: 0.8728 - val_precision: 0.8012 - val_recall: 0.5928 - val_fmeasure: 0.6807\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 1.3149 - acc: 0.6820 - top_k_categorical_accuracy: 0.8889 - precision: 0.8303 - recall: 0.5451 - fmeasure: 0.6570 - val_loss: 1.3555 - val_acc: 0.6919 - val_top_k_categorical_accuracy: 0.8843 - val_precision: 0.7999 - val_recall: 0.6172 - val_fmeasure: 0.6958\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 1.2460 - acc: 0.6965 - top_k_categorical_accuracy: 0.8964 - precision: 0.8366 - recall: 0.5669 - fmeasure: 0.6746 - val_loss: 1.4218 - val_acc: 0.6818 - val_top_k_categorical_accuracy: 0.8722 - val_precision: 0.7915 - val_recall: 0.6212 - val_fmeasure: 0.6955\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.1638 - acc: 0.7107 - top_k_categorical_accuracy: 0.9069 - precision: 0.8444 - recall: 0.5972 - fmeasure: 0.6987 - val_loss: 1.2968 - val_acc: 0.7108 - val_top_k_categorical_accuracy: 0.8905 - val_precision: 0.8065 - val_recall: 0.6293 - val_fmeasure: 0.7063\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.0717 - acc: 0.7313 - top_k_categorical_accuracy: 0.9174 - precision: 0.8486 - recall: 0.6247 - fmeasure: 0.7187 - val_loss: 1.3581 - val_acc: 0.6947 - val_top_k_categorical_accuracy: 0.8854 - val_precision: 0.7913 - val_recall: 0.6332 - val_fmeasure: 0.7028\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.0047 - acc: 0.7507 - top_k_categorical_accuracy: 0.9272 - precision: 0.8612 - recall: 0.6438 - fmeasure: 0.7359 - val_loss: 1.2187 - val_acc: 0.7265 - val_top_k_categorical_accuracy: 0.9037 - val_precision: 0.8022 - val_recall: 0.6796 - val_fmeasure: 0.7353\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.9748 - acc: 0.7500 - top_k_categorical_accuracy: 0.9321 - precision: 0.8588 - recall: 0.6520 - fmeasure: 0.7405 - val_loss: 1.2799 - val_acc: 0.7085 - val_top_k_categorical_accuracy: 0.8905 - val_precision: 0.7928 - val_recall: 0.6532 - val_fmeasure: 0.7157\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.9176 - acc: 0.7672 - top_k_categorical_accuracy: 0.9352 - precision: 0.8666 - recall: 0.6798 - fmeasure: 0.7611 - val_loss: 1.2453 - val_acc: 0.7094 - val_top_k_categorical_accuracy: 0.9034 - val_precision: 0.8036 - val_recall: 0.6507 - val_fmeasure: 0.7184\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.8692 - acc: 0.7768 - top_k_categorical_accuracy: 0.9419 - precision: 0.8720 - recall: 0.6944 - fmeasure: 0.7724 - val_loss: 1.2761 - val_acc: 0.7113 - val_top_k_categorical_accuracy: 0.9017 - val_precision: 0.7880 - val_recall: 0.6630 - val_fmeasure: 0.7195\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.8161 - acc: 0.7838 - top_k_categorical_accuracy: 0.9491 - precision: 0.8716 - recall: 0.7076 - fmeasure: 0.7803 - val_loss: 1.0987 - val_acc: 0.7582 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.8378 - val_recall: 0.7094 - val_fmeasure: 0.7679\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.7671 - acc: 0.7950 - top_k_categorical_accuracy: 0.9537 - precision: 0.8787 - recall: 0.7242 - fmeasure: 0.7934 - val_loss: 1.2169 - val_acc: 0.7209 - val_top_k_categorical_accuracy: 0.9068 - val_precision: 0.8021 - val_recall: 0.6771 - val_fmeasure: 0.7337\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.7253 - acc: 0.8090 - top_k_categorical_accuracy: 0.9559 - precision: 0.8866 - recall: 0.7385 - fmeasure: 0.8051 - val_loss: 1.1162 - val_acc: 0.7593 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.8394 - val_recall: 0.7152 - val_fmeasure: 0.7721\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.7045 - acc: 0.8079 - top_k_categorical_accuracy: 0.9579 - precision: 0.8858 - recall: 0.7418 - fmeasure: 0.8070 - val_loss: 1.2030 - val_acc: 0.7279 - val_top_k_categorical_accuracy: 0.9101 - val_precision: 0.8050 - val_recall: 0.6804 - val_fmeasure: 0.7370\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6662 - acc: 0.8162 - top_k_categorical_accuracy: 0.9638 - precision: 0.8921 - recall: 0.7505 - fmeasure: 0.8146 - val_loss: 1.0678 - val_acc: 0.7709 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.8340 - val_recall: 0.7391 - val_fmeasure: 0.7834\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.6246 - acc: 0.8267 - top_k_categorical_accuracy: 0.9682 - precision: 0.8976 - recall: 0.7661 - fmeasure: 0.8261 - val_loss: 1.2723 - val_acc: 0.7343 - val_top_k_categorical_accuracy: 0.9073 - val_precision: 0.7882 - val_recall: 0.6973 - val_fmeasure: 0.7396\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.5370 - acc: 0.6117 - top_k_categorical_accuracy: 0.8582 - precision: 0.7566 - recall: 0.5143 - fmeasure: 0.6114 - val_loss: 1.2259 - val_acc: 0.7307 - val_top_k_categorical_accuracy: 0.9068 - val_precision: 0.8045 - val_recall: 0.6877 - val_fmeasure: 0.7410\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6676 - acc: 0.8170 - top_k_categorical_accuracy: 0.9635 - precision: 0.8957 - recall: 0.7465 - fmeasure: 0.8136 - val_loss: 1.0073 - val_acc: 0.7807 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8448 - val_recall: 0.7405 - val_fmeasure: 0.7889\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.1870 - acc: 0.6865 - top_k_categorical_accuracy: 0.9039 - precision: 0.8094 - recall: 0.5949 - fmeasure: 0.6849 - val_loss: 1.1650 - val_acc: 0.7405 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.8117 - val_recall: 0.7020 - val_fmeasure: 0.7525\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.6240 - acc: 0.8282 - top_k_categorical_accuracy: 0.9682 - precision: 0.8966 - recall: 0.7554 - fmeasure: 0.8193 - val_loss: 1.0136 - val_acc: 0.7840 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8406 - val_recall: 0.7504 - val_fmeasure: 0.7925\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.0212 - acc: 0.7222 - top_k_categorical_accuracy: 0.9270 - precision: 0.8291 - recall: 0.6408 - fmeasure: 0.7221 - val_loss: 1.1544 - val_acc: 0.7416 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.8053 - val_recall: 0.7105 - val_fmeasure: 0.7546\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.5730 - acc: 0.8422 - top_k_categorical_accuracy: 0.9697 - precision: 0.9080 - recall: 0.7814 - fmeasure: 0.8395 - val_loss: 0.9748 - val_acc: 0.7880 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8422 - val_recall: 0.7520 - val_fmeasure: 0.7942\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 238us/step - loss: 0.8806 - acc: 0.7529 - top_k_categorical_accuracy: 0.9440 - precision: 0.8471 - recall: 0.6816 - fmeasure: 0.7547 - val_loss: 1.0676 - val_acc: 0.7602 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8246 - val_recall: 0.7245 - val_fmeasure: 0.7710\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.5497 - acc: 0.8480 - top_k_categorical_accuracy: 0.9729 - precision: 0.9077 - recall: 0.7933 - fmeasure: 0.8463 - val_loss: 1.0114 - val_acc: 0.7745 - val_top_k_categorical_accuracy: 0.9301 - val_precision: 0.8370 - val_recall: 0.7453 - val_fmeasure: 0.7881\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 0.7773 - acc: 0.7801 - top_k_categorical_accuracy: 0.9545 - precision: 0.8617 - recall: 0.7144 - fmeasure: 0.7806 - val_loss: 1.2092 - val_acc: 0.7414 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.8007 - val_recall: 0.7102 - val_fmeasure: 0.7523\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.5162 - acc: 0.8506 - top_k_categorical_accuracy: 0.9770 - precision: 0.9095 - recall: 0.7994 - fmeasure: 0.8505 - val_loss: 0.9869 - val_acc: 0.7818 - val_top_k_categorical_accuracy: 0.9332 - val_precision: 0.8335 - val_recall: 0.7526 - val_fmeasure: 0.7907\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.6889 - acc: 0.7999 - top_k_categorical_accuracy: 0.9638 - precision: 0.8728 - recall: 0.7405 - fmeasure: 0.8007 - val_loss: 1.2269 - val_acc: 0.7492 - val_top_k_categorical_accuracy: 0.9135 - val_precision: 0.8025 - val_recall: 0.7223 - val_fmeasure: 0.7599\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.4812 - acc: 0.8563 - top_k_categorical_accuracy: 0.9805 - precision: 0.9100 - recall: 0.8161 - fmeasure: 0.8601 - val_loss: 1.1733 - val_acc: 0.7478 - val_top_k_categorical_accuracy: 0.9132 - val_precision: 0.8047 - val_recall: 0.7169 - val_fmeasure: 0.7579\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 228us/step - loss: 0.6200 - acc: 0.8198 - top_k_categorical_accuracy: 0.9692 - precision: 0.8848 - recall: 0.7661 - fmeasure: 0.8207 - val_loss: 1.1839 - val_acc: 0.7374 - val_top_k_categorical_accuracy: 0.9191 - val_precision: 0.7935 - val_recall: 0.7102 - val_fmeasure: 0.7492\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.4642 - acc: 0.8616 - top_k_categorical_accuracy: 0.9827 - precision: 0.9071 - recall: 0.8232 - fmeasure: 0.8628 - val_loss: 1.1141 - val_acc: 0.7686 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.8152 - val_recall: 0.7467 - val_fmeasure: 0.7792\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 0.5777 - acc: 0.8306 - top_k_categorical_accuracy: 0.9720 - precision: 0.8884 - recall: 0.7820 - fmeasure: 0.8315 - val_loss: 1.1407 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8135 - val_recall: 0.7461 - val_fmeasure: 0.7781\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.4425 - acc: 0.8664 - top_k_categorical_accuracy: 0.9833 - precision: 0.9080 - recall: 0.8307 - fmeasure: 0.8673 - val_loss: 1.0474 - val_acc: 0.7762 - val_top_k_categorical_accuracy: 0.9304 - val_precision: 0.8296 - val_recall: 0.7518 - val_fmeasure: 0.7884\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 0.5198 - acc: 0.8427 - top_k_categorical_accuracy: 0.9783 - precision: 0.8967 - recall: 0.7973 - fmeasure: 0.8437 - val_loss: 1.2845 - val_acc: 0.7492 - val_top_k_categorical_accuracy: 0.9149 - val_precision: 0.7890 - val_recall: 0.7324 - val_fmeasure: 0.7594\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.4154 - acc: 0.8736 - top_k_categorical_accuracy: 0.9854 - precision: 0.9136 - recall: 0.8389 - fmeasure: 0.8744 - val_loss: 1.0418 - val_acc: 0.7944 - val_top_k_categorical_accuracy: 0.9377 - val_precision: 0.8287 - val_recall: 0.7793 - val_fmeasure: 0.8031\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 0.4907 - acc: 0.8497 - top_k_categorical_accuracy: 0.9806 - precision: 0.8977 - recall: 0.8086 - fmeasure: 0.8505 - val_loss: 1.2957 - val_acc: 0.7425 - val_top_k_categorical_accuracy: 0.9099 - val_precision: 0.7941 - val_recall: 0.7183 - val_fmeasure: 0.7541\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3873 - acc: 0.8800 - top_k_categorical_accuracy: 0.9850 - precision: 0.9194 - recall: 0.8476 - fmeasure: 0.8818 - val_loss: 1.1503 - val_acc: 0.7697 - val_top_k_categorical_accuracy: 0.9273 - val_precision: 0.8131 - val_recall: 0.7520 - val_fmeasure: 0.7811\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 0.4511 - acc: 0.8630 - top_k_categorical_accuracy: 0.9829 - precision: 0.9067 - recall: 0.8249 - fmeasure: 0.8635 - val_loss: 1.2351 - val_acc: 0.7509 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.7963 - val_recall: 0.7284 - val_fmeasure: 0.7607\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3873 - acc: 0.8787 - top_k_categorical_accuracy: 0.9894 - precision: 0.9144 - recall: 0.8494 - fmeasure: 0.8804 - val_loss: 1.2917 - val_acc: 0.7616 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.7977 - val_recall: 0.7464 - val_fmeasure: 0.7710\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.4150 - acc: 0.8712 - top_k_categorical_accuracy: 0.9862 - precision: 0.9121 - recall: 0.8380 - fmeasure: 0.8732 - val_loss: 1.2954 - val_acc: 0.7532 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7939 - val_recall: 0.7335 - val_fmeasure: 0.7622\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.3697 - acc: 0.8834 - top_k_categorical_accuracy: 0.9887 - precision: 0.9183 - recall: 0.8540 - fmeasure: 0.8846 - val_loss: 1.2331 - val_acc: 0.7647 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.8092 - val_recall: 0.7456 - val_fmeasure: 0.7759\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 0.3970 - acc: 0.8768 - top_k_categorical_accuracy: 0.9864 - precision: 0.9144 - recall: 0.8441 - fmeasure: 0.8776 - val_loss: 1.2927 - val_acc: 0.7616 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.8021 - val_recall: 0.7456 - val_fmeasure: 0.7726\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3616 - acc: 0.8870 - top_k_categorical_accuracy: 0.9876 - precision: 0.9199 - recall: 0.8616 - fmeasure: 0.8895 - val_loss: 1.2087 - val_acc: 0.7683 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8060 - val_recall: 0.7492 - val_fmeasure: 0.7763\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 0.3694 - acc: 0.8854 - top_k_categorical_accuracy: 0.9880 - precision: 0.9220 - recall: 0.8551 - fmeasure: 0.8870 - val_loss: 1.2203 - val_acc: 0.7762 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.8107 - val_recall: 0.7610 - val_fmeasure: 0.7849\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.3411 - acc: 0.8918 - top_k_categorical_accuracy: 0.9889 - precision: 0.9234 - recall: 0.8665 - fmeasure: 0.8939 - val_loss: 1.2144 - val_acc: 0.7630 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.8092 - val_recall: 0.7439 - val_fmeasure: 0.7749\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 0.3551 - acc: 0.8876 - top_k_categorical_accuracy: 0.9899 - precision: 0.9198 - recall: 0.8609 - fmeasure: 0.8891 - val_loss: 1.2329 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.8056 - val_recall: 0.7464 - val_fmeasure: 0.7747\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3368 - acc: 0.8908 - top_k_categorical_accuracy: 0.9905 - precision: 0.9208 - recall: 0.8689 - fmeasure: 0.8939 - val_loss: 1.1582 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.8158 - val_recall: 0.7641 - val_fmeasure: 0.7889\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 0.3381 - acc: 0.8904 - top_k_categorical_accuracy: 0.9898 - precision: 0.9223 - recall: 0.8637 - fmeasure: 0.8918 - val_loss: 1.3181 - val_acc: 0.7694 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.7998 - val_recall: 0.7607 - val_fmeasure: 0.7796\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3083 - acc: 0.9002 - top_k_categorical_accuracy: 0.9919 - precision: 0.9267 - recall: 0.8783 - fmeasure: 0.9017 - val_loss: 1.1860 - val_acc: 0.7810 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.8170 - val_recall: 0.7683 - val_fmeasure: 0.7917\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 0.3278 - acc: 0.8960 - top_k_categorical_accuracy: 0.9914 - precision: 0.9244 - recall: 0.8709 - fmeasure: 0.8966 - val_loss: 1.4131 - val_acc: 0.7394 - val_top_k_categorical_accuracy: 0.9110 - val_precision: 0.7761 - val_recall: 0.7206 - val_fmeasure: 0.7471\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3118 - acc: 0.9003 - top_k_categorical_accuracy: 0.9924 - precision: 0.9265 - recall: 0.8787 - fmeasure: 0.9017 - val_loss: 1.3102 - val_acc: 0.7638 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7987 - val_recall: 0.7487 - val_fmeasure: 0.7728\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 227us/step - loss: 0.3046 - acc: 0.9018 - top_k_categorical_accuracy: 0.9926 - precision: 0.9296 - recall: 0.8784 - fmeasure: 0.9031 - val_loss: 1.2765 - val_acc: 0.7680 - val_top_k_categorical_accuracy: 0.9287 - val_precision: 0.8028 - val_recall: 0.7565 - val_fmeasure: 0.7788\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.2996 - acc: 0.9029 - top_k_categorical_accuracy: 0.9937 - precision: 0.9265 - recall: 0.8831 - fmeasure: 0.9041 - val_loss: 1.1853 - val_acc: 0.7835 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8156 - val_recall: 0.7700 - val_fmeasure: 0.7919\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.2960 - acc: 0.9027 - top_k_categorical_accuracy: 0.9927 - precision: 0.9295 - recall: 0.8803 - fmeasure: 0.9040 - val_loss: 1.4008 - val_acc: 0.7557 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.7918 - val_recall: 0.7439 - val_fmeasure: 0.7669\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3007 - acc: 0.9037 - top_k_categorical_accuracy: 0.9917 - precision: 0.9305 - recall: 0.8829 - fmeasure: 0.9059 - val_loss: 1.1915 - val_acc: 0.7787 - val_top_k_categorical_accuracy: 0.9295 - val_precision: 0.8162 - val_recall: 0.7650 - val_fmeasure: 0.7894\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 0.2801 - acc: 0.9090 - top_k_categorical_accuracy: 0.9939 - precision: 0.9345 - recall: 0.8882 - fmeasure: 0.9106 - val_loss: 1.3248 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.7981 - val_recall: 0.7532 - val_fmeasure: 0.7748\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.2801 - acc: 0.9049 - top_k_categorical_accuracy: 0.9942 - precision: 0.9290 - recall: 0.8889 - fmeasure: 0.9084 - val_loss: 1.3888 - val_acc: 0.7588 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.7948 - val_recall: 0.7481 - val_fmeasure: 0.7706\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.2639 - acc: 0.9145 - top_k_categorical_accuracy: 0.9948 - precision: 0.9366 - recall: 0.8939 - fmeasure: 0.9146 - val_loss: 1.4054 - val_acc: 0.7602 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7917 - val_recall: 0.7475 - val_fmeasure: 0.7689\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.2787 - acc: 0.9094 - top_k_categorical_accuracy: 0.9937 - precision: 0.9317 - recall: 0.8893 - fmeasure: 0.9098 - val_loss: 1.2874 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.7976 - val_recall: 0.7543 - val_fmeasure: 0.7752\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 0.2508 - acc: 0.9177 - top_k_categorical_accuracy: 0.9951 - precision: 0.9389 - recall: 0.8984 - fmeasure: 0.9180 - val_loss: 1.4478 - val_acc: 0.7447 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7722 - val_recall: 0.7318 - val_fmeasure: 0.7514\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.2757 - acc: 0.9081 - top_k_categorical_accuracy: 0.9949 - precision: 0.9292 - recall: 0.8923 - fmeasure: 0.9102 - val_loss: 1.2851 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8038 - val_recall: 0.7633 - val_fmeasure: 0.7828\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.2514 - acc: 0.9164 - top_k_categorical_accuracy: 0.9953 - precision: 0.9363 - recall: 0.8987 - fmeasure: 0.9170 - val_loss: 1.3908 - val_acc: 0.7638 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.7990 - val_recall: 0.7473 - val_fmeasure: 0.7721\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.2557 - acc: 0.9165 - top_k_categorical_accuracy: 0.9954 - precision: 0.9362 - recall: 0.9025 - fmeasure: 0.9189 - val_loss: 1.2509 - val_acc: 0.7855 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8117 - val_recall: 0.7725 - val_fmeasure: 0.7914\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.2494 - acc: 0.9194 - top_k_categorical_accuracy: 0.9946 - precision: 0.9384 - recall: 0.9019 - fmeasure: 0.9197 - val_loss: 1.3682 - val_acc: 0.7664 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.7972 - val_recall: 0.7579 - val_fmeasure: 0.7769\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2557 - acc: 0.9162 - top_k_categorical_accuracy: 0.9945 - precision: 0.9352 - recall: 0.8994 - fmeasure: 0.9168 - val_loss: 1.3141 - val_acc: 0.7725 - val_top_k_categorical_accuracy: 0.9275 - val_precision: 0.7988 - val_recall: 0.7633 - val_fmeasure: 0.7805\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 0.2347 - acc: 0.9218 - top_k_categorical_accuracy: 0.9952 - precision: 0.9413 - recall: 0.9063 - fmeasure: 0.9233 - val_loss: 1.4513 - val_acc: 0.7658 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.7926 - val_recall: 0.7557 - val_fmeasure: 0.7736\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.2352 - acc: 0.9230 - top_k_categorical_accuracy: 0.9960 - precision: 0.9396 - recall: 0.9074 - fmeasure: 0.9231 - val_loss: 1.4440 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.7862 - val_recall: 0.7478 - val_fmeasure: 0.7664\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 0.2250 - acc: 0.9242 - top_k_categorical_accuracy: 0.9961 - precision: 0.9424 - recall: 0.9088 - fmeasure: 0.9252 - val_loss: 1.3912 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.7937 - val_recall: 0.7585 - val_fmeasure: 0.7756\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.2417 - acc: 0.9201 - top_k_categorical_accuracy: 0.9958 - precision: 0.9364 - recall: 0.9053 - fmeasure: 0.9205 - val_loss: 1.3368 - val_acc: 0.7734 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.8025 - val_recall: 0.7619 - val_fmeasure: 0.7815\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 0.2104 - acc: 0.9293 - top_k_categorical_accuracy: 0.9963 - precision: 0.9462 - recall: 0.9165 - fmeasure: 0.9310 - val_loss: 1.4327 - val_acc: 0.7630 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7943 - val_recall: 0.7526 - val_fmeasure: 0.7727\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.2246 - acc: 0.9268 - top_k_categorical_accuracy: 0.9963 - precision: 0.9430 - recall: 0.9127 - fmeasure: 0.9275 - val_loss: 1.3199 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9315 - val_precision: 0.8053 - val_recall: 0.7714 - val_fmeasure: 0.7879\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 0.2148 - acc: 0.9296 - top_k_categorical_accuracy: 0.9960 - precision: 0.9457 - recall: 0.9159 - fmeasure: 0.9304 - val_loss: 1.5098 - val_acc: 0.7596 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.7839 - val_recall: 0.7484 - val_fmeasure: 0.7656\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.2305 - acc: 0.9246 - top_k_categorical_accuracy: 0.9946 - precision: 0.9393 - recall: 0.9114 - fmeasure: 0.9251 - val_loss: 1.5994 - val_acc: 0.7456 - val_top_k_categorical_accuracy: 0.9129 - val_precision: 0.7747 - val_recall: 0.7369 - val_fmeasure: 0.7552\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.2069 - acc: 0.9324 - top_k_categorical_accuracy: 0.9960 - precision: 0.9483 - recall: 0.9195 - fmeasure: 0.9335 - val_loss: 1.4494 - val_acc: 0.7602 - val_top_k_categorical_accuracy: 0.9228 - val_precision: 0.7907 - val_recall: 0.7475 - val_fmeasure: 0.7683\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2327 - acc: 0.9238 - top_k_categorical_accuracy: 0.9955 - precision: 0.9379 - recall: 0.9118 - fmeasure: 0.9245 - val_loss: 1.4208 - val_acc: 0.7650 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.7964 - val_recall: 0.7534 - val_fmeasure: 0.7741\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 0.1924 - acc: 0.9364 - top_k_categorical_accuracy: 0.9963 - precision: 0.9516 - recall: 0.9244 - fmeasure: 0.9377 - val_loss: 1.5503 - val_acc: 0.7495 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.7764 - val_recall: 0.7405 - val_fmeasure: 0.7579\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 237us/step - loss: 0.2243 - acc: 0.9283 - top_k_categorical_accuracy: 0.9972 - precision: 0.9436 - recall: 0.9151 - fmeasure: 0.9290 - val_loss: 1.4375 - val_acc: 0.7655 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.7911 - val_recall: 0.7560 - val_fmeasure: 0.7730\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.2090 - acc: 0.9308 - top_k_categorical_accuracy: 0.9965 - precision: 0.9434 - recall: 0.9174 - fmeasure: 0.9301 - val_loss: 1.3407 - val_acc: 0.7739 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.8042 - val_recall: 0.7652 - val_fmeasure: 0.7841\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.1985 - acc: 0.9334 - top_k_categorical_accuracy: 0.9972 - precision: 0.9471 - recall: 0.9232 - fmeasure: 0.9349 - val_loss: 1.3836 - val_acc: 0.7593 - val_top_k_categorical_accuracy: 0.9228 - val_precision: 0.7921 - val_recall: 0.7504 - val_fmeasure: 0.7705\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.1778 - acc: 0.9439 - top_k_categorical_accuracy: 0.9974 - precision: 0.9541 - recall: 0.9322 - fmeasure: 0.9430 - val_loss: 1.3446 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8049 - val_recall: 0.7616 - val_fmeasure: 0.7825\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.1744 - acc: 0.9403 - top_k_categorical_accuracy: 0.9988 - precision: 0.9538 - recall: 0.9286 - fmeasure: 0.9410 - val_loss: 1.2506 - val_acc: 0.7832 - val_top_k_categorical_accuracy: 0.9343 - val_precision: 0.8091 - val_recall: 0.7745 - val_fmeasure: 0.7913\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.1772 - acc: 0.9392 - top_k_categorical_accuracy: 0.9986 - precision: 0.9503 - recall: 0.9283 - fmeasure: 0.9391 - val_loss: 1.6298 - val_acc: 0.7425 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.7636 - val_recall: 0.7343 - val_fmeasure: 0.7486\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.1749 - acc: 0.9403 - top_k_categorical_accuracy: 0.9978 - precision: 0.9527 - recall: 0.9273 - fmeasure: 0.9397 - val_loss: 1.4467 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9174 - val_precision: 0.7908 - val_recall: 0.7529 - val_fmeasure: 0.7712\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.1689 - acc: 0.9411 - top_k_categorical_accuracy: 0.9981 - precision: 0.9517 - recall: 0.9310 - fmeasure: 0.9411 - val_loss: 1.3650 - val_acc: 0.7700 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.7981 - val_recall: 0.7582 - val_fmeasure: 0.7775\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.1807 - acc: 0.9374 - top_k_categorical_accuracy: 0.9983 - precision: 0.9488 - recall: 0.9273 - fmeasure: 0.9379 - val_loss: 1.3770 - val_acc: 0.7619 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.7891 - val_recall: 0.7520 - val_fmeasure: 0.7699\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.1676 - acc: 0.9427 - top_k_categorical_accuracy: 0.9982 - precision: 0.9533 - recall: 0.9320 - fmeasure: 0.9424 - val_loss: 1.3228 - val_acc: 0.7894 - val_top_k_categorical_accuracy: 0.9267 - val_precision: 0.8131 - val_recall: 0.7776 - val_fmeasure: 0.7948\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.1670 - acc: 0.9435 - top_k_categorical_accuracy: 0.9984 - precision: 0.9541 - recall: 0.9342 - fmeasure: 0.9439 - val_loss: 1.3422 - val_acc: 0.7829 - val_top_k_categorical_accuracy: 0.9309 - val_precision: 0.8070 - val_recall: 0.7703 - val_fmeasure: 0.7881\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.1683 - acc: 0.9453 - top_k_categorical_accuracy: 0.9983 - precision: 0.9540 - recall: 0.9337 - fmeasure: 0.9436 - val_loss: 1.3859 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8006 - val_recall: 0.7700 - val_fmeasure: 0.7849\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.1589 - acc: 0.9478 - top_k_categorical_accuracy: 0.9983 - precision: 0.9566 - recall: 0.9390 - fmeasure: 0.9476 - val_loss: 1.3958 - val_acc: 0.7745 - val_top_k_categorical_accuracy: 0.9306 - val_precision: 0.7941 - val_recall: 0.7630 - val_fmeasure: 0.7781\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.1477 - acc: 0.9488 - top_k_categorical_accuracy: 0.9983 - precision: 0.9597 - recall: 0.9393 - fmeasure: 0.9493 - val_loss: 1.3880 - val_acc: 0.7790 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8022 - val_recall: 0.7675 - val_fmeasure: 0.7843\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.1469 - acc: 0.9487 - top_k_categorical_accuracy: 0.9984 - precision: 0.9579 - recall: 0.9396 - fmeasure: 0.9486 - val_loss: 1.3310 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9320 - val_precision: 0.8071 - val_recall: 0.7762 - val_fmeasure: 0.7912\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.1474 - acc: 0.9467 - top_k_categorical_accuracy: 0.9989 - precision: 0.9571 - recall: 0.9397 - fmeasure: 0.9482 - val_loss: 1.4240 - val_acc: 0.7725 - val_top_k_categorical_accuracy: 0.9270 - val_precision: 0.7966 - val_recall: 0.7630 - val_fmeasure: 0.7793\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.1420 - acc: 0.9506 - top_k_categorical_accuracy: 0.9990 - precision: 0.9585 - recall: 0.9422 - fmeasure: 0.9502 - val_loss: 1.3288 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9334 - val_precision: 0.8053 - val_recall: 0.7720 - val_fmeasure: 0.7881\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.1462 - acc: 0.9506 - top_k_categorical_accuracy: 0.9992 - precision: 0.9577 - recall: 0.9446 - fmeasure: 0.9511 - val_loss: 1.3585 - val_acc: 0.7773 - val_top_k_categorical_accuracy: 0.9290 - val_precision: 0.8020 - val_recall: 0.7703 - val_fmeasure: 0.7857\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.1380 - acc: 0.9506 - top_k_categorical_accuracy: 0.9988 - precision: 0.9585 - recall: 0.9433 - fmeasure: 0.9508 - val_loss: 1.4427 - val_acc: 0.7709 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.7947 - val_recall: 0.7610 - val_fmeasure: 0.7774\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.1408 - acc: 0.9540 - top_k_categorical_accuracy: 0.9982 - precision: 0.9617 - recall: 0.9459 - fmeasure: 0.9537 - val_loss: 1.3621 - val_acc: 0.7843 - val_top_k_categorical_accuracy: 0.9306 - val_precision: 0.8059 - val_recall: 0.7765 - val_fmeasure: 0.7908\n",
            "transplanting......\n",
            "When the process freezing, please check that datatype_Close has been set correctly\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 5s 570us/step - loss: 4.0490 - acc: 0.1153 - top_k_categorical_accuracy: 0.3295 - precision: 0.2831 - recall: 0.0163 - fmeasure: 0.0302 - val_loss: 2.9176 - val_acc: 0.2777 - val_top_k_categorical_accuracy: 0.6181 - val_precision: 0.6751 - val_recall: 0.0736 - val_fmeasure: 0.1309\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 2.9059 - acc: 0.3025 - top_k_categorical_accuracy: 0.6188 - precision: 0.5835 - recall: 0.0935 - fmeasure: 0.1591 - val_loss: 2.4128 - val_acc: 0.4271 - val_top_k_categorical_accuracy: 0.7200 - val_precision: 0.7420 - val_recall: 0.2019 - val_fmeasure: 0.3155\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 2.3225 - acc: 0.4354 - top_k_categorical_accuracy: 0.7423 - precision: 0.7076 - recall: 0.2184 - fmeasure: 0.3309 - val_loss: 1.8620 - val_acc: 0.5574 - val_top_k_categorical_accuracy: 0.8138 - val_precision: 0.8075 - val_recall: 0.3830 - val_fmeasure: 0.5176\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 1.9859 - acc: 0.5162 - top_k_categorical_accuracy: 0.8059 - precision: 0.7481 - recall: 0.3090 - fmeasure: 0.4358 - val_loss: 1.9504 - val_acc: 0.5316 - val_top_k_categorical_accuracy: 0.8065 - val_precision: 0.7316 - val_recall: 0.3606 - val_fmeasure: 0.4809\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 1.7446 - acc: 0.5859 - top_k_categorical_accuracy: 0.8359 - precision: 0.7909 - recall: 0.3997 - fmeasure: 0.5294 - val_loss: 1.5159 - val_acc: 0.6523 - val_top_k_categorical_accuracy: 0.8551 - val_precision: 0.8014 - val_recall: 0.5437 - val_fmeasure: 0.6469\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 256us/step - loss: 1.5376 - acc: 0.6254 - top_k_categorical_accuracy: 0.8652 - precision: 0.8015 - recall: 0.4648 - fmeasure: 0.5869 - val_loss: 1.4967 - val_acc: 0.6608 - val_top_k_categorical_accuracy: 0.8593 - val_precision: 0.7780 - val_recall: 0.5754 - val_fmeasure: 0.6609\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 256us/step - loss: 1.4235 - acc: 0.6572 - top_k_categorical_accuracy: 0.8746 - precision: 0.8216 - recall: 0.5031 - fmeasure: 0.6227 - val_loss: 1.3841 - val_acc: 0.6866 - val_top_k_categorical_accuracy: 0.8809 - val_precision: 0.7966 - val_recall: 0.6024 - val_fmeasure: 0.6851\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 1.3163 - acc: 0.6729 - top_k_categorical_accuracy: 0.8901 - precision: 0.8237 - recall: 0.5416 - fmeasure: 0.6523 - val_loss: 1.4602 - val_acc: 0.6712 - val_top_k_categorical_accuracy: 0.8649 - val_precision: 0.7983 - val_recall: 0.5872 - val_fmeasure: 0.6760\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 1.2287 - acc: 0.6940 - top_k_categorical_accuracy: 0.9003 - precision: 0.8373 - recall: 0.5710 - fmeasure: 0.6773 - val_loss: 1.2587 - val_acc: 0.7119 - val_top_k_categorical_accuracy: 0.8894 - val_precision: 0.8200 - val_recall: 0.6417 - val_fmeasure: 0.7192\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.1196 - acc: 0.7217 - top_k_categorical_accuracy: 0.9104 - precision: 0.8472 - recall: 0.6109 - fmeasure: 0.7091 - val_loss: 1.4435 - val_acc: 0.6653 - val_top_k_categorical_accuracy: 0.8736 - val_precision: 0.7704 - val_recall: 0.5993 - val_fmeasure: 0.6734\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 1.0546 - acc: 0.7372 - top_k_categorical_accuracy: 0.9226 - precision: 0.8571 - recall: 0.6314 - fmeasure: 0.7261 - val_loss: 1.2171 - val_acc: 0.7206 - val_top_k_categorical_accuracy: 0.9000 - val_precision: 0.8132 - val_recall: 0.6684 - val_fmeasure: 0.7330\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.0032 - acc: 0.7521 - top_k_categorical_accuracy: 0.9277 - precision: 0.8584 - recall: 0.6527 - fmeasure: 0.7407 - val_loss: 1.3102 - val_acc: 0.6990 - val_top_k_categorical_accuracy: 0.8877 - val_precision: 0.7963 - val_recall: 0.6420 - val_fmeasure: 0.7102\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.9406 - acc: 0.7579 - top_k_categorical_accuracy: 0.9379 - precision: 0.8604 - recall: 0.6676 - fmeasure: 0.7510 - val_loss: 1.3368 - val_acc: 0.6998 - val_top_k_categorical_accuracy: 0.8894 - val_precision: 0.7775 - val_recall: 0.6526 - val_fmeasure: 0.7088\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.8886 - acc: 0.7720 - top_k_categorical_accuracy: 0.9401 - precision: 0.8649 - recall: 0.6881 - fmeasure: 0.7657 - val_loss: 1.2045 - val_acc: 0.7290 - val_top_k_categorical_accuracy: 0.9017 - val_precision: 0.8112 - val_recall: 0.6641 - val_fmeasure: 0.7299\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.8382 - acc: 0.7808 - top_k_categorical_accuracy: 0.9459 - precision: 0.8743 - recall: 0.6989 - fmeasure: 0.7760 - val_loss: 1.2102 - val_acc: 0.7287 - val_top_k_categorical_accuracy: 0.9073 - val_precision: 0.8000 - val_recall: 0.6801 - val_fmeasure: 0.7348\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.7852 - acc: 0.7909 - top_k_categorical_accuracy: 0.9524 - precision: 0.8759 - recall: 0.7141 - fmeasure: 0.7860 - val_loss: 1.2304 - val_acc: 0.7206 - val_top_k_categorical_accuracy: 0.9070 - val_precision: 0.7954 - val_recall: 0.6801 - val_fmeasure: 0.7329\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7656 - acc: 0.7975 - top_k_categorical_accuracy: 0.9540 - precision: 0.8744 - recall: 0.7305 - fmeasure: 0.7954 - val_loss: 1.2213 - val_acc: 0.7209 - val_top_k_categorical_accuracy: 0.9110 - val_precision: 0.7970 - val_recall: 0.6703 - val_fmeasure: 0.7277\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7346 - acc: 0.8049 - top_k_categorical_accuracy: 0.9567 - precision: 0.8804 - recall: 0.7341 - fmeasure: 0.8002 - val_loss: 1.0856 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.8214 - val_recall: 0.7214 - val_fmeasure: 0.7677\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.6843 - acc: 0.8151 - top_k_categorical_accuracy: 0.9629 - precision: 0.8870 - recall: 0.7494 - fmeasure: 0.8119 - val_loss: 1.3048 - val_acc: 0.6984 - val_top_k_categorical_accuracy: 0.9096 - val_precision: 0.7676 - val_recall: 0.6428 - val_fmeasure: 0.6992\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.6738 - acc: 0.8182 - top_k_categorical_accuracy: 0.9648 - precision: 0.8879 - recall: 0.7501 - fmeasure: 0.8127 - val_loss: 1.0814 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8233 - val_recall: 0.7369 - val_fmeasure: 0.7771\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.6376 - acc: 0.8254 - top_k_categorical_accuracy: 0.9668 - precision: 0.8907 - recall: 0.7665 - fmeasure: 0.8234 - val_loss: 1.0746 - val_acc: 0.7714 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.8274 - val_recall: 0.7450 - val_fmeasure: 0.7836\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 3.8017 - acc: 0.2264 - top_k_categorical_accuracy: 0.4527 - precision: 0.4964 - recall: 0.1159 - fmeasure: 0.1855 - val_loss: 1.7680 - val_acc: 0.5981 - val_top_k_categorical_accuracy: 0.8354 - val_precision: 0.8037 - val_recall: 0.3625 - val_fmeasure: 0.4970\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.1214 - acc: 0.7275 - top_k_categorical_accuracy: 0.9156 - precision: 0.8705 - recall: 0.5686 - fmeasure: 0.6791 - val_loss: 1.0205 - val_acc: 0.7680 - val_top_k_categorical_accuracy: 0.9169 - val_precision: 0.8604 - val_recall: 0.6950 - val_fmeasure: 0.7684\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 3.1004 - acc: 0.3100 - top_k_categorical_accuracy: 0.5637 - precision: 0.6138 - recall: 0.1755 - fmeasure: 0.2711 - val_loss: 1.6818 - val_acc: 0.6220 - val_top_k_categorical_accuracy: 0.8419 - val_precision: 0.8211 - val_recall: 0.4078 - val_fmeasure: 0.5430\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 1.1145 - acc: 0.7305 - top_k_categorical_accuracy: 0.9212 - precision: 0.8736 - recall: 0.5668 - fmeasure: 0.6800 - val_loss: 1.0709 - val_acc: 0.7425 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.8599 - val_recall: 0.6611 - val_fmeasure: 0.7467\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 228us/step - loss: 2.8081 - acc: 0.3625 - top_k_categorical_accuracy: 0.6175 - precision: 0.6612 - recall: 0.2168 - fmeasure: 0.3249 - val_loss: 1.5098 - val_acc: 0.6535 - val_top_k_categorical_accuracy: 0.8630 - val_precision: 0.8410 - val_recall: 0.4650 - val_fmeasure: 0.5971\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 1.0834 - acc: 0.7453 - top_k_categorical_accuracy: 0.9224 - precision: 0.8809 - recall: 0.5799 - fmeasure: 0.6948 - val_loss: 1.0513 - val_acc: 0.7515 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.8596 - val_recall: 0.6726 - val_fmeasure: 0.7539\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 229us/step - loss: 2.5903 - acc: 0.3998 - top_k_categorical_accuracy: 0.6525 - precision: 0.6933 - recall: 0.2539 - fmeasure: 0.3699 - val_loss: 1.5342 - val_acc: 0.6431 - val_top_k_categorical_accuracy: 0.8610 - val_precision: 0.8288 - val_recall: 0.4538 - val_fmeasure: 0.5850\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.0516 - acc: 0.7453 - top_k_categorical_accuracy: 0.9245 - precision: 0.8844 - recall: 0.5912 - fmeasure: 0.7044 - val_loss: 1.0044 - val_acc: 0.7672 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.8559 - val_recall: 0.6973 - val_fmeasure: 0.7679\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 2.4272 - acc: 0.4302 - top_k_categorical_accuracy: 0.6827 - precision: 0.7157 - recall: 0.2876 - fmeasure: 0.4089 - val_loss: 1.3438 - val_acc: 0.6877 - val_top_k_categorical_accuracy: 0.8832 - val_precision: 0.8603 - val_recall: 0.5338 - val_fmeasure: 0.6577\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.9880 - acc: 0.7645 - top_k_categorical_accuracy: 0.9333 - precision: 0.8931 - recall: 0.6172 - fmeasure: 0.7265 - val_loss: 0.9676 - val_acc: 0.7790 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.8670 - val_recall: 0.7197 - val_fmeasure: 0.7859\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 226us/step - loss: 2.2951 - acc: 0.4554 - top_k_categorical_accuracy: 0.7088 - precision: 0.7338 - recall: 0.3106 - fmeasure: 0.4348 - val_loss: 1.3373 - val_acc: 0.6928 - val_top_k_categorical_accuracy: 0.8860 - val_precision: 0.8595 - val_recall: 0.5431 - val_fmeasure: 0.6643\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.9620 - acc: 0.7656 - top_k_categorical_accuracy: 0.9376 - precision: 0.8942 - recall: 0.6255 - fmeasure: 0.7340 - val_loss: 0.9374 - val_acc: 0.7821 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.8639 - val_recall: 0.7268 - val_fmeasure: 0.7889\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 2.2092 - acc: 0.4760 - top_k_categorical_accuracy: 0.7204 - precision: 0.7449 - recall: 0.3352 - fmeasure: 0.4607 - val_loss: 1.3283 - val_acc: 0.6860 - val_top_k_categorical_accuracy: 0.8857 - val_precision: 0.8641 - val_recall: 0.5541 - val_fmeasure: 0.6739\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.9280 - acc: 0.7734 - top_k_categorical_accuracy: 0.9388 - precision: 0.8979 - recall: 0.6404 - fmeasure: 0.7453 - val_loss: 0.9430 - val_acc: 0.7852 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.8736 - val_recall: 0.7324 - val_fmeasure: 0.7962\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 2.1040 - acc: 0.4924 - top_k_categorical_accuracy: 0.7391 - precision: 0.7571 - recall: 0.3564 - fmeasure: 0.4830 - val_loss: 1.3022 - val_acc: 0.6900 - val_top_k_categorical_accuracy: 0.8905 - val_precision: 0.8272 - val_recall: 0.5855 - val_fmeasure: 0.6844\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.9021 - acc: 0.7759 - top_k_categorical_accuracy: 0.9447 - precision: 0.8879 - recall: 0.6469 - fmeasure: 0.7464 - val_loss: 0.9095 - val_acc: 0.7855 - val_top_k_categorical_accuracy: 0.9377 - val_precision: 0.8598 - val_recall: 0.7394 - val_fmeasure: 0.7946\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 226us/step - loss: 2.0355 - acc: 0.5044 - top_k_categorical_accuracy: 0.7535 - precision: 0.7549 - recall: 0.3720 - fmeasure: 0.4970 - val_loss: 1.2775 - val_acc: 0.6931 - val_top_k_categorical_accuracy: 0.8910 - val_precision: 0.8435 - val_recall: 0.5757 - val_fmeasure: 0.6828\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.8429 - acc: 0.7863 - top_k_categorical_accuracy: 0.9500 - precision: 0.8992 - recall: 0.6649 - fmeasure: 0.7627 - val_loss: 0.9725 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8474 - val_recall: 0.7209 - val_fmeasure: 0.7786\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 1.9781 - acc: 0.5192 - top_k_categorical_accuracy: 0.7627 - precision: 0.7671 - recall: 0.3890 - fmeasure: 0.5147 - val_loss: 1.2955 - val_acc: 0.6925 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.8244 - val_recall: 0.5970 - val_fmeasure: 0.6915\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.8346 - acc: 0.7927 - top_k_categorical_accuracy: 0.9490 - precision: 0.8968 - recall: 0.6716 - fmeasure: 0.7666 - val_loss: 0.9030 - val_acc: 0.7902 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.8596 - val_recall: 0.7456 - val_fmeasure: 0.7981\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.9170 - acc: 0.5314 - top_k_categorical_accuracy: 0.7692 - precision: 0.7791 - recall: 0.4044 - fmeasure: 0.5310 - val_loss: 1.1704 - val_acc: 0.7273 - val_top_k_categorical_accuracy: 0.9079 - val_precision: 0.8520 - val_recall: 0.6352 - val_fmeasure: 0.7266\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7903 - acc: 0.8025 - top_k_categorical_accuracy: 0.9532 - precision: 0.9026 - recall: 0.6906 - fmeasure: 0.7812 - val_loss: 0.9089 - val_acc: 0.7877 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.8613 - val_recall: 0.7470 - val_fmeasure: 0.7996\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.8446 - acc: 0.5467 - top_k_categorical_accuracy: 0.7834 - precision: 0.7845 - recall: 0.4198 - fmeasure: 0.5457 - val_loss: 1.2394 - val_acc: 0.7035 - val_top_k_categorical_accuracy: 0.8975 - val_precision: 0.8332 - val_recall: 0.5962 - val_fmeasure: 0.6943\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7828 - acc: 0.7964 - top_k_categorical_accuracy: 0.9565 - precision: 0.8951 - recall: 0.6856 - fmeasure: 0.7752 - val_loss: 0.9123 - val_acc: 0.7855 - val_top_k_categorical_accuracy: 0.9365 - val_precision: 0.8620 - val_recall: 0.7453 - val_fmeasure: 0.7989\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.8106 - acc: 0.5509 - top_k_categorical_accuracy: 0.7887 - precision: 0.7913 - recall: 0.4317 - fmeasure: 0.5575 - val_loss: 1.2249 - val_acc: 0.7169 - val_top_k_categorical_accuracy: 0.9040 - val_precision: 0.8333 - val_recall: 0.6201 - val_fmeasure: 0.7101\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7580 - acc: 0.8080 - top_k_categorical_accuracy: 0.9571 - precision: 0.9040 - recall: 0.7003 - fmeasure: 0.7879 - val_loss: 0.9406 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9329 - val_precision: 0.8685 - val_recall: 0.7352 - val_fmeasure: 0.7958\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 227us/step - loss: 1.7555 - acc: 0.5593 - top_k_categorical_accuracy: 0.8001 - precision: 0.7898 - recall: 0.4419 - fmeasure: 0.5654 - val_loss: 1.1326 - val_acc: 0.7343 - val_top_k_categorical_accuracy: 0.9104 - val_precision: 0.8524 - val_recall: 0.6568 - val_fmeasure: 0.7410\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.7506 - acc: 0.8068 - top_k_categorical_accuracy: 0.9602 - precision: 0.9009 - recall: 0.7035 - fmeasure: 0.7888 - val_loss: 0.8841 - val_acc: 0.7995 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8740 - val_recall: 0.7557 - val_fmeasure: 0.8102\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 226us/step - loss: 1.7274 - acc: 0.5665 - top_k_categorical_accuracy: 0.8038 - precision: 0.7920 - recall: 0.4482 - fmeasure: 0.5712 - val_loss: 1.1208 - val_acc: 0.7366 - val_top_k_categorical_accuracy: 0.9048 - val_precision: 0.8549 - val_recall: 0.6560 - val_fmeasure: 0.7412\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.7229 - acc: 0.8097 - top_k_categorical_accuracy: 0.9598 - precision: 0.9029 - recall: 0.7145 - fmeasure: 0.7966 - val_loss: 0.8916 - val_acc: 0.7944 - val_top_k_categorical_accuracy: 0.9379 - val_precision: 0.8601 - val_recall: 0.7574 - val_fmeasure: 0.8050\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 1.6816 - acc: 0.5779 - top_k_categorical_accuracy: 0.8089 - precision: 0.7989 - recall: 0.4588 - fmeasure: 0.5816 - val_loss: 1.1184 - val_acc: 0.7402 - val_top_k_categorical_accuracy: 0.9090 - val_precision: 0.8485 - val_recall: 0.6554 - val_fmeasure: 0.7387\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.7046 - acc: 0.8151 - top_k_categorical_accuracy: 0.9646 - precision: 0.9037 - recall: 0.7196 - fmeasure: 0.8003 - val_loss: 0.9093 - val_acc: 0.7933 - val_top_k_categorical_accuracy: 0.9363 - val_precision: 0.8530 - val_recall: 0.7574 - val_fmeasure: 0.8020\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.6548 - acc: 0.5833 - top_k_categorical_accuracy: 0.8132 - precision: 0.8006 - recall: 0.4694 - fmeasure: 0.5906 - val_loss: 1.1737 - val_acc: 0.7211 - val_top_k_categorical_accuracy: 0.8992 - val_precision: 0.8471 - val_recall: 0.6330 - val_fmeasure: 0.7239\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.6921 - acc: 0.8141 - top_k_categorical_accuracy: 0.9657 - precision: 0.9051 - recall: 0.7317 - fmeasure: 0.8082 - val_loss: 0.9392 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9312 - val_precision: 0.8555 - val_recall: 0.7363 - val_fmeasure: 0.7910\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 228us/step - loss: 1.6169 - acc: 0.5913 - top_k_categorical_accuracy: 0.8208 - precision: 0.8047 - recall: 0.4801 - fmeasure: 0.6002 - val_loss: 1.1682 - val_acc: 0.7197 - val_top_k_categorical_accuracy: 0.9070 - val_precision: 0.8314 - val_recall: 0.6523 - val_fmeasure: 0.7302\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.6722 - acc: 0.8226 - top_k_categorical_accuracy: 0.9662 - precision: 0.9012 - recall: 0.7282 - fmeasure: 0.8045 - val_loss: 0.9589 - val_acc: 0.7832 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.8531 - val_recall: 0.7453 - val_fmeasure: 0.7950\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.5827 - acc: 0.5981 - top_k_categorical_accuracy: 0.8230 - precision: 0.8086 - recall: 0.4873 - fmeasure: 0.6070 - val_loss: 1.2180 - val_acc: 0.7242 - val_top_k_categorical_accuracy: 0.9012 - val_precision: 0.8377 - val_recall: 0.6375 - val_fmeasure: 0.7228\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.6720 - acc: 0.8175 - top_k_categorical_accuracy: 0.9642 - precision: 0.9056 - recall: 0.7335 - fmeasure: 0.8098 - val_loss: 0.9162 - val_acc: 0.7908 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.8597 - val_recall: 0.7557 - val_fmeasure: 0.8039\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 1.5493 - acc: 0.6013 - top_k_categorical_accuracy: 0.8287 - precision: 0.8108 - recall: 0.4931 - fmeasure: 0.6121 - val_loss: 1.1700 - val_acc: 0.7273 - val_top_k_categorical_accuracy: 0.8992 - val_precision: 0.8317 - val_recall: 0.6549 - val_fmeasure: 0.7320\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6676 - acc: 0.8200 - top_k_categorical_accuracy: 0.9640 - precision: 0.9036 - recall: 0.7368 - fmeasure: 0.8109 - val_loss: 0.9201 - val_acc: 0.7950 - val_top_k_categorical_accuracy: 0.9340 - val_precision: 0.8593 - val_recall: 0.7554 - val_fmeasure: 0.8036\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 227us/step - loss: 1.5214 - acc: 0.6040 - top_k_categorical_accuracy: 0.8352 - precision: 0.8120 - recall: 0.5015 - fmeasure: 0.6189 - val_loss: 1.1742 - val_acc: 0.7287 - val_top_k_categorical_accuracy: 0.9045 - val_precision: 0.8379 - val_recall: 0.6552 - val_fmeasure: 0.7347\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6400 - acc: 0.8258 - top_k_categorical_accuracy: 0.9676 - precision: 0.9081 - recall: 0.7425 - fmeasure: 0.8160 - val_loss: 0.9224 - val_acc: 0.7978 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8651 - val_recall: 0.7616 - val_fmeasure: 0.8097\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 226us/step - loss: 1.4896 - acc: 0.6145 - top_k_categorical_accuracy: 0.8384 - precision: 0.8154 - recall: 0.5086 - fmeasure: 0.6254 - val_loss: 1.1284 - val_acc: 0.7445 - val_top_k_categorical_accuracy: 0.9051 - val_precision: 0.8411 - val_recall: 0.6773 - val_fmeasure: 0.7497\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.6098 - acc: 0.8333 - top_k_categorical_accuracy: 0.9739 - precision: 0.9069 - recall: 0.7511 - fmeasure: 0.8210 - val_loss: 0.9244 - val_acc: 0.7925 - val_top_k_categorical_accuracy: 0.9337 - val_precision: 0.8662 - val_recall: 0.7621 - val_fmeasure: 0.8104\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.4835 - acc: 0.6189 - top_k_categorical_accuracy: 0.8393 - precision: 0.8151 - recall: 0.5141 - fmeasure: 0.6295 - val_loss: 1.0905 - val_acc: 0.7475 - val_top_k_categorical_accuracy: 0.9099 - val_precision: 0.8555 - val_recall: 0.6745 - val_fmeasure: 0.7535\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.6027 - acc: 0.8350 - top_k_categorical_accuracy: 0.9736 - precision: 0.9088 - recall: 0.7538 - fmeasure: 0.8234 - val_loss: 0.9176 - val_acc: 0.7995 - val_top_k_categorical_accuracy: 0.9304 - val_precision: 0.8650 - val_recall: 0.7661 - val_fmeasure: 0.8121\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.4508 - acc: 0.6249 - top_k_categorical_accuracy: 0.8454 - precision: 0.8191 - recall: 0.5182 - fmeasure: 0.6337 - val_loss: 1.1599 - val_acc: 0.7318 - val_top_k_categorical_accuracy: 0.9118 - val_precision: 0.8254 - val_recall: 0.6748 - val_fmeasure: 0.7419\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.6039 - acc: 0.8352 - top_k_categorical_accuracy: 0.9734 - precision: 0.9084 - recall: 0.7562 - fmeasure: 0.8245 - val_loss: 0.9122 - val_acc: 0.8062 - val_top_k_categorical_accuracy: 0.9363 - val_precision: 0.8658 - val_recall: 0.7706 - val_fmeasure: 0.8151\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.4346 - acc: 0.6258 - top_k_categorical_accuracy: 0.8493 - precision: 0.8182 - recall: 0.5237 - fmeasure: 0.6375 - val_loss: 1.1018 - val_acc: 0.7546 - val_top_k_categorical_accuracy: 0.9135 - val_precision: 0.8460 - val_recall: 0.6956 - val_fmeasure: 0.7628\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.5812 - acc: 0.8364 - top_k_categorical_accuracy: 0.9764 - precision: 0.9085 - recall: 0.7631 - fmeasure: 0.8287 - val_loss: 0.9294 - val_acc: 0.7908 - val_top_k_categorical_accuracy: 0.9354 - val_precision: 0.8591 - val_recall: 0.7571 - val_fmeasure: 0.8045\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 229us/step - loss: 1.3976 - acc: 0.6336 - top_k_categorical_accuracy: 0.8563 - precision: 0.8264 - recall: 0.5356 - fmeasure: 0.6488 - val_loss: 1.1236 - val_acc: 0.7422 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.8373 - val_recall: 0.6860 - val_fmeasure: 0.7533\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.5760 - acc: 0.8419 - top_k_categorical_accuracy: 0.9770 - precision: 0.9087 - recall: 0.7655 - fmeasure: 0.8304 - val_loss: 0.9552 - val_acc: 0.7888 - val_top_k_categorical_accuracy: 0.9312 - val_precision: 0.8571 - val_recall: 0.7577 - val_fmeasure: 0.8040\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.3805 - acc: 0.6373 - top_k_categorical_accuracy: 0.8588 - precision: 0.8225 - recall: 0.5390 - fmeasure: 0.6502 - val_loss: 1.0736 - val_acc: 0.7579 - val_top_k_categorical_accuracy: 0.9124 - val_precision: 0.8558 - val_recall: 0.6998 - val_fmeasure: 0.7693\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.5757 - acc: 0.8399 - top_k_categorical_accuracy: 0.9726 - precision: 0.9116 - recall: 0.7663 - fmeasure: 0.8322 - val_loss: 0.9293 - val_acc: 0.7956 - val_top_k_categorical_accuracy: 0.9323 - val_precision: 0.8543 - val_recall: 0.7599 - val_fmeasure: 0.8039\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 226us/step - loss: 1.3664 - acc: 0.6399 - top_k_categorical_accuracy: 0.8582 - precision: 0.8243 - recall: 0.5426 - fmeasure: 0.6532 - val_loss: 1.0757 - val_acc: 0.7644 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.8524 - val_recall: 0.7138 - val_fmeasure: 0.7764\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.5435 - acc: 0.8478 - top_k_categorical_accuracy: 0.9782 - precision: 0.9145 - recall: 0.7765 - fmeasure: 0.8391 - val_loss: 0.9281 - val_acc: 0.8023 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.8551 - val_recall: 0.7666 - val_fmeasure: 0.8082\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.3270 - acc: 0.6503 - top_k_categorical_accuracy: 0.8604 - precision: 0.8346 - recall: 0.5564 - fmeasure: 0.6668 - val_loss: 1.1026 - val_acc: 0.7543 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.8436 - val_recall: 0.6953 - val_fmeasure: 0.7617\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.5363 - acc: 0.8489 - top_k_categorical_accuracy: 0.9801 - precision: 0.9089 - recall: 0.7797 - fmeasure: 0.8387 - val_loss: 0.9229 - val_acc: 0.7936 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8528 - val_recall: 0.7689 - val_fmeasure: 0.8083\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 228us/step - loss: 1.3254 - acc: 0.6482 - top_k_categorical_accuracy: 0.8626 - precision: 0.8290 - recall: 0.5550 - fmeasure: 0.6638 - val_loss: 1.1047 - val_acc: 0.7574 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.8436 - val_recall: 0.7035 - val_fmeasure: 0.7666\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.5261 - acc: 0.8522 - top_k_categorical_accuracy: 0.9787 - precision: 0.9119 - recall: 0.7811 - fmeasure: 0.8409 - val_loss: 0.9748 - val_acc: 0.7928 - val_top_k_categorical_accuracy: 0.9306 - val_precision: 0.8540 - val_recall: 0.7635 - val_fmeasure: 0.8059\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.4482 - acc: 0.8712 - top_k_categorical_accuracy: 0.9854 - precision: 0.9193 - recall: 0.8182 - fmeasure: 0.8655 - val_loss: 0.9406 - val_acc: 0.7998 - val_top_k_categorical_accuracy: 0.9340 - val_precision: 0.8548 - val_recall: 0.7742 - val_fmeasure: 0.8122\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.4012 - acc: 0.8819 - top_k_categorical_accuracy: 0.9887 - precision: 0.9271 - recall: 0.8362 - fmeasure: 0.8789 - val_loss: 0.9143 - val_acc: 0.8065 - val_top_k_categorical_accuracy: 0.9332 - val_precision: 0.8583 - val_recall: 0.7818 - val_fmeasure: 0.8180\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.3834 - acc: 0.8878 - top_k_categorical_accuracy: 0.9899 - precision: 0.9253 - recall: 0.8439 - fmeasure: 0.8824 - val_loss: 0.8945 - val_acc: 0.8102 - val_top_k_categorical_accuracy: 0.9391 - val_precision: 0.8648 - val_recall: 0.7869 - val_fmeasure: 0.8236\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.3659 - acc: 0.8880 - top_k_categorical_accuracy: 0.9904 - precision: 0.9274 - recall: 0.8502 - fmeasure: 0.8869 - val_loss: 0.8872 - val_acc: 0.8079 - val_top_k_categorical_accuracy: 0.9391 - val_precision: 0.8601 - val_recall: 0.7790 - val_fmeasure: 0.8173\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.3491 - acc: 0.8929 - top_k_categorical_accuracy: 0.9940 - precision: 0.9259 - recall: 0.8570 - fmeasure: 0.8899 - val_loss: 0.9425 - val_acc: 0.8057 - val_top_k_categorical_accuracy: 0.9365 - val_precision: 0.8553 - val_recall: 0.7835 - val_fmeasure: 0.8175\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3406 - acc: 0.8932 - top_k_categorical_accuracy: 0.9917 - precision: 0.9270 - recall: 0.8565 - fmeasure: 0.8901 - val_loss: 0.8977 - val_acc: 0.8085 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.8574 - val_recall: 0.7824 - val_fmeasure: 0.8179\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.3211 - acc: 0.8997 - top_k_categorical_accuracy: 0.9946 - precision: 0.9291 - recall: 0.8682 - fmeasure: 0.8974 - val_loss: 0.9243 - val_acc: 0.7975 - val_top_k_categorical_accuracy: 0.9416 - val_precision: 0.8389 - val_recall: 0.7798 - val_fmeasure: 0.8081\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.3175 - acc: 0.8986 - top_k_categorical_accuracy: 0.9940 - precision: 0.9266 - recall: 0.8643 - fmeasure: 0.8941 - val_loss: 0.9214 - val_acc: 0.8034 - val_top_k_categorical_accuracy: 0.9399 - val_precision: 0.8472 - val_recall: 0.7840 - val_fmeasure: 0.8141\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2894 - acc: 0.9081 - top_k_categorical_accuracy: 0.9953 - precision: 0.9364 - recall: 0.8782 - fmeasure: 0.9062 - val_loss: 0.9405 - val_acc: 0.8037 - val_top_k_categorical_accuracy: 0.9416 - val_precision: 0.8475 - val_recall: 0.7840 - val_fmeasure: 0.8143\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.2936 - acc: 0.9081 - top_k_categorical_accuracy: 0.9949 - precision: 0.9348 - recall: 0.8771 - fmeasure: 0.9049 - val_loss: 0.9564 - val_acc: 0.7950 - val_top_k_categorical_accuracy: 0.9337 - val_precision: 0.8467 - val_recall: 0.7700 - val_fmeasure: 0.8062\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.2722 - acc: 0.9126 - top_k_categorical_accuracy: 0.9964 - precision: 0.9378 - recall: 0.8872 - fmeasure: 0.9116 - val_loss: 0.9607 - val_acc: 0.8048 - val_top_k_categorical_accuracy: 0.9368 - val_precision: 0.8463 - val_recall: 0.7846 - val_fmeasure: 0.8140\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.2595 - acc: 0.9199 - top_k_categorical_accuracy: 0.9969 - precision: 0.9424 - recall: 0.8935 - fmeasure: 0.9171 - val_loss: 1.0162 - val_acc: 0.7849 - val_top_k_categorical_accuracy: 0.9298 - val_precision: 0.8374 - val_recall: 0.7652 - val_fmeasure: 0.7994\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.2705 - acc: 0.9134 - top_k_categorical_accuracy: 0.9967 - precision: 0.9334 - recall: 0.8882 - fmeasure: 0.9101 - val_loss: 0.9286 - val_acc: 0.8085 - val_top_k_categorical_accuracy: 0.9413 - val_precision: 0.8455 - val_recall: 0.7916 - val_fmeasure: 0.8175\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.2427 - acc: 0.9185 - top_k_categorical_accuracy: 0.9971 - precision: 0.9393 - recall: 0.8943 - fmeasure: 0.9161 - val_loss: 0.9345 - val_acc: 0.8062 - val_top_k_categorical_accuracy: 0.9422 - val_precision: 0.8439 - val_recall: 0.7922 - val_fmeasure: 0.8170\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.2646 - acc: 0.9113 - top_k_categorical_accuracy: 0.9964 - precision: 0.9326 - recall: 0.8900 - fmeasure: 0.9107 - val_loss: 0.9693 - val_acc: 0.8048 - val_top_k_categorical_accuracy: 0.9399 - val_precision: 0.8479 - val_recall: 0.7888 - val_fmeasure: 0.8171\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.2317 - acc: 0.9226 - top_k_categorical_accuracy: 0.9975 - precision: 0.9399 - recall: 0.9032 - fmeasure: 0.9210 - val_loss: 0.9893 - val_acc: 0.7970 - val_top_k_categorical_accuracy: 0.9391 - val_precision: 0.8333 - val_recall: 0.7804 - val_fmeasure: 0.8056\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2287 - acc: 0.9246 - top_k_categorical_accuracy: 0.9974 - precision: 0.9447 - recall: 0.9051 - fmeasure: 0.9244 - val_loss: 0.9683 - val_acc: 0.8045 - val_top_k_categorical_accuracy: 0.9444 - val_precision: 0.8405 - val_recall: 0.7908 - val_fmeasure: 0.8147\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.2300 - acc: 0.9224 - top_k_categorical_accuracy: 0.9972 - precision: 0.9415 - recall: 0.9054 - fmeasure: 0.9230 - val_loss: 0.9881 - val_acc: 0.8074 - val_top_k_categorical_accuracy: 0.9410 - val_precision: 0.8401 - val_recall: 0.7956 - val_fmeasure: 0.8171\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2220 - acc: 0.9220 - top_k_categorical_accuracy: 0.9986 - precision: 0.9399 - recall: 0.9020 - fmeasure: 0.9204 - val_loss: 0.9715 - val_acc: 0.8076 - val_top_k_categorical_accuracy: 0.9422 - val_precision: 0.8395 - val_recall: 0.7942 - val_fmeasure: 0.8160\n",
            "mixup......\n",
            "When the process freezing, please check that datatype_Close has been set correctly\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 5s 653us/step - loss: 4.0847 - acc: 0.1145 - top_k_categorical_accuracy: 0.3148 - precision: 0.2318 - recall: 0.0130 - fmeasure: 0.0243 - val_loss: 2.9848 - val_acc: 0.2589 - val_top_k_categorical_accuracy: 0.5892 - val_precision: 0.6658 - val_recall: 0.0612 - val_fmeasure: 0.1108\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 2.8904 - acc: 0.3105 - top_k_categorical_accuracy: 0.6192 - precision: 0.6165 - recall: 0.0985 - fmeasure: 0.1674 - val_loss: 2.3073 - val_acc: 0.4386 - val_top_k_categorical_accuracy: 0.7473 - val_precision: 0.6855 - val_recall: 0.2522 - val_fmeasure: 0.3664\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 2.3306 - acc: 0.4376 - top_k_categorical_accuracy: 0.7409 - precision: 0.7269 - recall: 0.2192 - fmeasure: 0.3349 - val_loss: 1.9286 - val_acc: 0.5566 - val_top_k_categorical_accuracy: 0.7995 - val_precision: 0.7771 - val_recall: 0.3752 - val_fmeasure: 0.5040\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.9798 - acc: 0.5241 - top_k_categorical_accuracy: 0.8014 - precision: 0.7563 - recall: 0.3220 - fmeasure: 0.4489 - val_loss: 1.6910 - val_acc: 0.6029 - val_top_k_categorical_accuracy: 0.8377 - val_precision: 0.7795 - val_recall: 0.4813 - val_fmeasure: 0.5937\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.7660 - acc: 0.5733 - top_k_categorical_accuracy: 0.8313 - precision: 0.7791 - recall: 0.3880 - fmeasure: 0.5166 - val_loss: 1.7563 - val_acc: 0.5799 - val_top_k_categorical_accuracy: 0.8307 - val_precision: 0.7350 - val_recall: 0.4813 - val_fmeasure: 0.5806\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 1.5766 - acc: 0.6195 - top_k_categorical_accuracy: 0.8560 - precision: 0.7979 - recall: 0.4483 - fmeasure: 0.5725 - val_loss: 1.4829 - val_acc: 0.6611 - val_top_k_categorical_accuracy: 0.8602 - val_precision: 0.7967 - val_recall: 0.5602 - val_fmeasure: 0.6569\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 1.4201 - acc: 0.6545 - top_k_categorical_accuracy: 0.8771 - precision: 0.8143 - recall: 0.5011 - fmeasure: 0.6191 - val_loss: 1.3577 - val_acc: 0.6877 - val_top_k_categorical_accuracy: 0.8790 - val_precision: 0.8088 - val_recall: 0.5998 - val_fmeasure: 0.6877\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 1.3351 - acc: 0.6777 - top_k_categorical_accuracy: 0.8899 - precision: 0.8181 - recall: 0.5316 - fmeasure: 0.6431 - val_loss: 1.4860 - val_acc: 0.6442 - val_top_k_categorical_accuracy: 0.8703 - val_precision: 0.7585 - val_recall: 0.5557 - val_fmeasure: 0.6409\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 1.2439 - acc: 0.6933 - top_k_categorical_accuracy: 0.8976 - precision: 0.8346 - recall: 0.5670 - fmeasure: 0.6742 - val_loss: 1.6143 - val_acc: 0.6344 - val_top_k_categorical_accuracy: 0.8559 - val_precision: 0.7372 - val_recall: 0.5706 - val_fmeasure: 0.6426\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 1.1664 - acc: 0.7082 - top_k_categorical_accuracy: 0.9081 - precision: 0.8385 - recall: 0.5929 - fmeasure: 0.6937 - val_loss: 1.3192 - val_acc: 0.6950 - val_top_k_categorical_accuracy: 0.8916 - val_precision: 0.7951 - val_recall: 0.6231 - val_fmeasure: 0.6980\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 1.0739 - acc: 0.7364 - top_k_categorical_accuracy: 0.9202 - precision: 0.8487 - recall: 0.6286 - fmeasure: 0.7213 - val_loss: 1.3024 - val_acc: 0.7026 - val_top_k_categorical_accuracy: 0.8871 - val_precision: 0.8061 - val_recall: 0.6397 - val_fmeasure: 0.7124\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.0232 - acc: 0.7471 - top_k_categorical_accuracy: 0.9238 - precision: 0.8597 - recall: 0.6475 - fmeasure: 0.7377 - val_loss: 1.3350 - val_acc: 0.6821 - val_top_k_categorical_accuracy: 0.8874 - val_precision: 0.7837 - val_recall: 0.6175 - val_fmeasure: 0.6900\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.9525 - acc: 0.7560 - top_k_categorical_accuracy: 0.9354 - precision: 0.8609 - recall: 0.6678 - fmeasure: 0.7514 - val_loss: 1.3660 - val_acc: 0.6883 - val_top_k_categorical_accuracy: 0.8843 - val_precision: 0.7703 - val_recall: 0.6310 - val_fmeasure: 0.6930\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.9110 - acc: 0.7659 - top_k_categorical_accuracy: 0.9369 - precision: 0.8663 - recall: 0.6797 - fmeasure: 0.7610 - val_loss: 1.2988 - val_acc: 0.7023 - val_top_k_categorical_accuracy: 0.8975 - val_precision: 0.7889 - val_recall: 0.6526 - val_fmeasure: 0.7138\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.8549 - acc: 0.7777 - top_k_categorical_accuracy: 0.9409 - precision: 0.8715 - recall: 0.6997 - fmeasure: 0.7755 - val_loss: 1.2129 - val_acc: 0.7262 - val_top_k_categorical_accuracy: 0.9000 - val_precision: 0.8016 - val_recall: 0.6785 - val_fmeasure: 0.7346\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.8235 - acc: 0.7816 - top_k_categorical_accuracy: 0.9481 - precision: 0.8707 - recall: 0.7086 - fmeasure: 0.7807 - val_loss: 1.3269 - val_acc: 0.6964 - val_top_k_categorical_accuracy: 0.8950 - val_precision: 0.7746 - val_recall: 0.6501 - val_fmeasure: 0.7064\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7711 - acc: 0.7976 - top_k_categorical_accuracy: 0.9531 - precision: 0.8844 - recall: 0.7258 - fmeasure: 0.7965 - val_loss: 1.1785 - val_acc: 0.7402 - val_top_k_categorical_accuracy: 0.9138 - val_precision: 0.8077 - val_recall: 0.7035 - val_fmeasure: 0.7517\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.7336 - acc: 0.8051 - top_k_categorical_accuracy: 0.9585 - precision: 0.8815 - recall: 0.7323 - fmeasure: 0.7994 - val_loss: 1.2474 - val_acc: 0.7217 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.7949 - val_recall: 0.6754 - val_fmeasure: 0.7299\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.6949 - acc: 0.8151 - top_k_categorical_accuracy: 0.9591 - precision: 0.8909 - recall: 0.7495 - fmeasure: 0.8135 - val_loss: 1.1739 - val_acc: 0.7377 - val_top_k_categorical_accuracy: 0.9099 - val_precision: 0.8148 - val_recall: 0.6877 - val_fmeasure: 0.7454\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.6747 - acc: 0.8144 - top_k_categorical_accuracy: 0.9640 - precision: 0.8850 - recall: 0.7520 - fmeasure: 0.8124 - val_loss: 1.2054 - val_acc: 0.7436 - val_top_k_categorical_accuracy: 0.9040 - val_precision: 0.8016 - val_recall: 0.7049 - val_fmeasure: 0.7498\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6482 - acc: 0.8188 - top_k_categorical_accuracy: 0.9663 - precision: 0.8927 - recall: 0.7583 - fmeasure: 0.8196 - val_loss: 1.1497 - val_acc: 0.7591 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.8098 - val_recall: 0.7220 - val_fmeasure: 0.7630\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 3.2111 - acc: 0.3186 - top_k_categorical_accuracy: 0.5600 - precision: 0.5843 - recall: 0.2020 - fmeasure: 0.2980 - val_loss: 1.4445 - val_acc: 0.6709 - val_top_k_categorical_accuracy: 0.8677 - val_precision: 0.8556 - val_recall: 0.4996 - val_fmeasure: 0.6284\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.9938 - acc: 0.7598 - top_k_categorical_accuracy: 0.9303 - precision: 0.8878 - recall: 0.6277 - fmeasure: 0.7311 - val_loss: 0.9773 - val_acc: 0.7731 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.8699 - val_recall: 0.7195 - val_fmeasure: 0.7869\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 2.6192 - acc: 0.4044 - top_k_categorical_accuracy: 0.6495 - precision: 0.6913 - recall: 0.2703 - fmeasure: 0.3867 - val_loss: 1.4316 - val_acc: 0.6700 - val_top_k_categorical_accuracy: 0.8770 - val_precision: 0.8413 - val_recall: 0.5128 - val_fmeasure: 0.6353\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.9661 - acc: 0.7633 - top_k_categorical_accuracy: 0.9374 - precision: 0.8877 - recall: 0.6207 - fmeasure: 0.7271 - val_loss: 0.9380 - val_acc: 0.7874 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.8688 - val_recall: 0.7355 - val_fmeasure: 0.7959\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 2.3630 - acc: 0.4479 - top_k_categorical_accuracy: 0.7011 - precision: 0.7145 - recall: 0.3115 - fmeasure: 0.4323 - val_loss: 1.3042 - val_acc: 0.7088 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.8682 - val_recall: 0.5442 - val_fmeasure: 0.6678\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.9662 - acc: 0.7666 - top_k_categorical_accuracy: 0.9360 - precision: 0.8866 - recall: 0.6310 - fmeasure: 0.7346 - val_loss: 0.9358 - val_acc: 0.7829 - val_top_k_categorical_accuracy: 0.9253 - val_precision: 0.8658 - val_recall: 0.7296 - val_fmeasure: 0.7913\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 2.1698 - acc: 0.4830 - top_k_categorical_accuracy: 0.7266 - precision: 0.7472 - recall: 0.3526 - fmeasure: 0.4776 - val_loss: 1.2760 - val_acc: 0.7108 - val_top_k_categorical_accuracy: 0.8913 - val_precision: 0.8712 - val_recall: 0.5636 - val_fmeasure: 0.6825\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.8892 - acc: 0.7836 - top_k_categorical_accuracy: 0.9404 - precision: 0.8939 - recall: 0.6560 - fmeasure: 0.7545 - val_loss: 0.9257 - val_acc: 0.7843 - val_top_k_categorical_accuracy: 0.9298 - val_precision: 0.8740 - val_recall: 0.7206 - val_fmeasure: 0.7893\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 2.0224 - acc: 0.5119 - top_k_categorical_accuracy: 0.7544 - precision: 0.7596 - recall: 0.3846 - fmeasure: 0.5093 - val_loss: 1.3196 - val_acc: 0.6874 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.8503 - val_recall: 0.5619 - val_fmeasure: 0.6750\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.8524 - acc: 0.7909 - top_k_categorical_accuracy: 0.9468 - precision: 0.9006 - recall: 0.6705 - fmeasure: 0.7668 - val_loss: 0.8814 - val_acc: 0.7978 - val_top_k_categorical_accuracy: 0.9332 - val_precision: 0.8741 - val_recall: 0.7515 - val_fmeasure: 0.8077\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.9167 - acc: 0.5365 - top_k_categorical_accuracy: 0.7731 - precision: 0.7757 - recall: 0.4101 - fmeasure: 0.5351 - val_loss: 1.0885 - val_acc: 0.7518 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.8799 - val_recall: 0.6560 - val_fmeasure: 0.7507\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 239us/step - loss: 0.8096 - acc: 0.7994 - top_k_categorical_accuracy: 0.9512 - precision: 0.9005 - recall: 0.6940 - fmeasure: 0.7822 - val_loss: 0.8640 - val_acc: 0.8065 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8820 - val_recall: 0.7591 - val_fmeasure: 0.8154\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.8138 - acc: 0.5579 - top_k_categorical_accuracy: 0.7911 - precision: 0.7871 - recall: 0.4322 - fmeasure: 0.5568 - val_loss: 1.1463 - val_acc: 0.7341 - val_top_k_categorical_accuracy: 0.9009 - val_precision: 0.8698 - val_recall: 0.6332 - val_fmeasure: 0.7316\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.7722 - acc: 0.8045 - top_k_categorical_accuracy: 0.9539 - precision: 0.9018 - recall: 0.6993 - fmeasure: 0.7863 - val_loss: 0.9063 - val_acc: 0.7899 - val_top_k_categorical_accuracy: 0.9340 - val_precision: 0.8643 - val_recall: 0.7492 - val_fmeasure: 0.8021\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 1.7429 - acc: 0.5693 - top_k_categorical_accuracy: 0.8007 - precision: 0.7937 - recall: 0.4505 - fmeasure: 0.5735 - val_loss: 1.1122 - val_acc: 0.7402 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.8734 - val_recall: 0.6487 - val_fmeasure: 0.7432\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.7518 - acc: 0.8091 - top_k_categorical_accuracy: 0.9585 - precision: 0.8984 - recall: 0.7083 - fmeasure: 0.7910 - val_loss: 0.8529 - val_acc: 0.8037 - val_top_k_categorical_accuracy: 0.9368 - val_precision: 0.8681 - val_recall: 0.7706 - val_fmeasure: 0.8160\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 224us/step - loss: 1.6856 - acc: 0.5818 - top_k_categorical_accuracy: 0.8112 - precision: 0.7976 - recall: 0.4660 - fmeasure: 0.5870 - val_loss: 1.0705 - val_acc: 0.7489 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.8622 - val_recall: 0.6723 - val_fmeasure: 0.7546\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.7124 - acc: 0.8218 - top_k_categorical_accuracy: 0.9586 - precision: 0.9084 - recall: 0.7309 - fmeasure: 0.8090 - val_loss: 0.8278 - val_acc: 0.8166 - val_top_k_categorical_accuracy: 0.9379 - val_precision: 0.8844 - val_recall: 0.7753 - val_fmeasure: 0.8259\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.6075 - acc: 0.5934 - top_k_categorical_accuracy: 0.8241 - precision: 0.8070 - recall: 0.4827 - fmeasure: 0.6028 - val_loss: 1.0627 - val_acc: 0.7464 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.8643 - val_recall: 0.6768 - val_fmeasure: 0.7582\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.7071 - acc: 0.8202 - top_k_categorical_accuracy: 0.9612 - precision: 0.9042 - recall: 0.7263 - fmeasure: 0.8045 - val_loss: 0.8387 - val_acc: 0.8133 - val_top_k_categorical_accuracy: 0.9407 - val_precision: 0.8718 - val_recall: 0.7801 - val_fmeasure: 0.8231\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.5454 - acc: 0.6080 - top_k_categorical_accuracy: 0.8327 - precision: 0.8097 - recall: 0.4983 - fmeasure: 0.6158 - val_loss: 1.0507 - val_acc: 0.7577 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.8546 - val_recall: 0.6796 - val_fmeasure: 0.7562\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.6937 - acc: 0.8167 - top_k_categorical_accuracy: 0.9630 - precision: 0.9061 - recall: 0.7326 - fmeasure: 0.8092 - val_loss: 0.8565 - val_acc: 0.8102 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8806 - val_recall: 0.7711 - val_fmeasure: 0.8216\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 1.5177 - acc: 0.6133 - top_k_categorical_accuracy: 0.8378 - precision: 0.8123 - recall: 0.5058 - fmeasure: 0.6222 - val_loss: 1.0599 - val_acc: 0.7520 - val_top_k_categorical_accuracy: 0.9155 - val_precision: 0.8648 - val_recall: 0.6771 - val_fmeasure: 0.7584\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.6523 - acc: 0.8276 - top_k_categorical_accuracy: 0.9662 - precision: 0.9066 - recall: 0.7455 - fmeasure: 0.8174 - val_loss: 0.8677 - val_acc: 0.7992 - val_top_k_categorical_accuracy: 0.9360 - val_precision: 0.8593 - val_recall: 0.7675 - val_fmeasure: 0.8104\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.4551 - acc: 0.6293 - top_k_categorical_accuracy: 0.8464 - precision: 0.8227 - recall: 0.5248 - fmeasure: 0.6397 - val_loss: 1.0237 - val_acc: 0.7711 - val_top_k_categorical_accuracy: 0.9186 - val_precision: 0.8671 - val_recall: 0.7091 - val_fmeasure: 0.7792\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.6389 - acc: 0.8267 - top_k_categorical_accuracy: 0.9680 - precision: 0.9039 - recall: 0.7529 - fmeasure: 0.8208 - val_loss: 0.9029 - val_acc: 0.7978 - val_top_k_categorical_accuracy: 0.9351 - val_precision: 0.8615 - val_recall: 0.7638 - val_fmeasure: 0.8093\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.4098 - acc: 0.6363 - top_k_categorical_accuracy: 0.8559 - precision: 0.8244 - recall: 0.5338 - fmeasure: 0.6470 - val_loss: 1.0832 - val_acc: 0.7548 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.8563 - val_recall: 0.6903 - val_fmeasure: 0.7636\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.6319 - acc: 0.8351 - top_k_categorical_accuracy: 0.9694 - precision: 0.9069 - recall: 0.7548 - fmeasure: 0.8231 - val_loss: 0.8698 - val_acc: 0.8012 - val_top_k_categorical_accuracy: 0.9385 - val_precision: 0.8654 - val_recall: 0.7714 - val_fmeasure: 0.8154\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.3700 - acc: 0.6468 - top_k_categorical_accuracy: 0.8612 - precision: 0.8286 - recall: 0.5454 - fmeasure: 0.6568 - val_loss: 1.1117 - val_acc: 0.7439 - val_top_k_categorical_accuracy: 0.9076 - val_precision: 0.8527 - val_recall: 0.6852 - val_fmeasure: 0.7591\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.6065 - acc: 0.8358 - top_k_categorical_accuracy: 0.9712 - precision: 0.9081 - recall: 0.7647 - fmeasure: 0.8295 - val_loss: 0.8534 - val_acc: 0.8141 - val_top_k_categorical_accuracy: 0.9424 - val_precision: 0.8768 - val_recall: 0.7826 - val_fmeasure: 0.8266\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 221us/step - loss: 1.3600 - acc: 0.6479 - top_k_categorical_accuracy: 0.8624 - precision: 0.8298 - recall: 0.5519 - fmeasure: 0.6620 - val_loss: 1.0623 - val_acc: 0.7588 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.8666 - val_recall: 0.6950 - val_fmeasure: 0.7704\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.5752 - acc: 0.8504 - top_k_categorical_accuracy: 0.9733 - precision: 0.9104 - recall: 0.7746 - fmeasure: 0.8364 - val_loss: 0.8614 - val_acc: 0.8023 - val_top_k_categorical_accuracy: 0.9377 - val_precision: 0.8621 - val_recall: 0.7689 - val_fmeasure: 0.8125\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.3072 - acc: 0.6602 - top_k_categorical_accuracy: 0.8697 - precision: 0.8314 - recall: 0.5615 - fmeasure: 0.6693 - val_loss: 1.0694 - val_acc: 0.7478 - val_top_k_categorical_accuracy: 0.9194 - val_precision: 0.8470 - val_recall: 0.6976 - val_fmeasure: 0.7643\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.5800 - acc: 0.8431 - top_k_categorical_accuracy: 0.9720 - precision: 0.9159 - recall: 0.7767 - fmeasure: 0.8400 - val_loss: 0.8529 - val_acc: 0.8116 - val_top_k_categorical_accuracy: 0.9430 - val_precision: 0.8728 - val_recall: 0.7801 - val_fmeasure: 0.8236\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.2771 - acc: 0.6668 - top_k_categorical_accuracy: 0.8728 - precision: 0.8387 - recall: 0.5692 - fmeasure: 0.6771 - val_loss: 1.0912 - val_acc: 0.7526 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.8534 - val_recall: 0.7091 - val_fmeasure: 0.7739\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.5539 - acc: 0.8423 - top_k_categorical_accuracy: 0.9744 - precision: 0.9113 - recall: 0.7727 - fmeasure: 0.8357 - val_loss: 0.8706 - val_acc: 0.8062 - val_top_k_categorical_accuracy: 0.9371 - val_precision: 0.8684 - val_recall: 0.7748 - val_fmeasure: 0.8185\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.2533 - acc: 0.6684 - top_k_categorical_accuracy: 0.8757 - precision: 0.8373 - recall: 0.5767 - fmeasure: 0.6821 - val_loss: 1.0773 - val_acc: 0.7638 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.8534 - val_recall: 0.7192 - val_fmeasure: 0.7800\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.5301 - acc: 0.8548 - top_k_categorical_accuracy: 0.9762 - precision: 0.9156 - recall: 0.7909 - fmeasure: 0.8481 - val_loss: 0.9271 - val_acc: 0.7939 - val_top_k_categorical_accuracy: 0.9312 - val_precision: 0.8505 - val_recall: 0.7621 - val_fmeasure: 0.8036\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 1.2175 - acc: 0.6787 - top_k_categorical_accuracy: 0.8838 - precision: 0.8399 - recall: 0.5868 - fmeasure: 0.6899 - val_loss: 1.0605 - val_acc: 0.7543 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.8575 - val_recall: 0.7060 - val_fmeasure: 0.7738\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 236us/step - loss: 0.5372 - acc: 0.8504 - top_k_categorical_accuracy: 0.9757 - precision: 0.9149 - recall: 0.7903 - fmeasure: 0.8474 - val_loss: 0.8997 - val_acc: 0.8037 - val_top_k_categorical_accuracy: 0.9385 - val_precision: 0.8637 - val_recall: 0.7717 - val_fmeasure: 0.8148\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.1962 - acc: 0.6877 - top_k_categorical_accuracy: 0.8847 - precision: 0.8447 - recall: 0.5955 - fmeasure: 0.6977 - val_loss: 1.0898 - val_acc: 0.7537 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.8483 - val_recall: 0.7054 - val_fmeasure: 0.7697\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.5241 - acc: 0.8533 - top_k_categorical_accuracy: 0.9786 - precision: 0.9106 - recall: 0.7884 - fmeasure: 0.8446 - val_loss: 0.8865 - val_acc: 0.7984 - val_top_k_categorical_accuracy: 0.9382 - val_precision: 0.8640 - val_recall: 0.7706 - val_fmeasure: 0.8142\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.1760 - acc: 0.6866 - top_k_categorical_accuracy: 0.8897 - precision: 0.8414 - recall: 0.5980 - fmeasure: 0.6982 - val_loss: 1.0569 - val_acc: 0.7560 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.8482 - val_recall: 0.7049 - val_fmeasure: 0.7693\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.5029 - acc: 0.8578 - top_k_categorical_accuracy: 0.9798 - precision: 0.9133 - recall: 0.7961 - fmeasure: 0.8501 - val_loss: 0.9076 - val_acc: 0.8054 - val_top_k_categorical_accuracy: 0.9368 - val_precision: 0.8658 - val_recall: 0.7745 - val_fmeasure: 0.8173\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.1455 - acc: 0.6949 - top_k_categorical_accuracy: 0.8917 - precision: 0.8475 - recall: 0.6101 - fmeasure: 0.7086 - val_loss: 1.0421 - val_acc: 0.7562 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8533 - val_recall: 0.7124 - val_fmeasure: 0.7759\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.5150 - acc: 0.8551 - top_k_categorical_accuracy: 0.9793 - precision: 0.9147 - recall: 0.7927 - fmeasure: 0.8489 - val_loss: 0.9006 - val_acc: 0.7984 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.8672 - val_recall: 0.7683 - val_fmeasure: 0.8143\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 222us/step - loss: 1.1069 - acc: 0.7026 - top_k_categorical_accuracy: 0.8980 - precision: 0.8530 - recall: 0.6152 - fmeasure: 0.7140 - val_loss: 1.0779 - val_acc: 0.7515 - val_top_k_categorical_accuracy: 0.9143 - val_precision: 0.8534 - val_recall: 0.7071 - val_fmeasure: 0.7728\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.4824 - acc: 0.8598 - top_k_categorical_accuracy: 0.9810 - precision: 0.9170 - recall: 0.8047 - fmeasure: 0.8566 - val_loss: 0.9047 - val_acc: 0.8043 - val_top_k_categorical_accuracy: 0.9348 - val_precision: 0.8617 - val_recall: 0.7773 - val_fmeasure: 0.8169\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 5s 220us/step - loss: 1.1070 - acc: 0.7047 - top_k_categorical_accuracy: 0.8964 - precision: 0.8564 - recall: 0.6199 - fmeasure: 0.7182 - val_loss: 1.0512 - val_acc: 0.7700 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.8524 - val_recall: 0.7265 - val_fmeasure: 0.7836\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 240us/step - loss: 0.4837 - acc: 0.8583 - top_k_categorical_accuracy: 0.9830 - precision: 0.9133 - recall: 0.8010 - fmeasure: 0.8531 - val_loss: 0.9099 - val_acc: 0.8012 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8603 - val_recall: 0.7770 - val_fmeasure: 0.8162\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.0955 - acc: 0.7059 - top_k_categorical_accuracy: 0.8995 - precision: 0.8496 - recall: 0.6206 - fmeasure: 0.7165 - val_loss: 1.0667 - val_acc: 0.7666 - val_top_k_categorical_accuracy: 0.9208 - val_precision: 0.8507 - val_recall: 0.7209 - val_fmeasure: 0.7799\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 238us/step - loss: 0.4687 - acc: 0.8658 - top_k_categorical_accuracy: 0.9819 - precision: 0.9177 - recall: 0.8126 - fmeasure: 0.8615 - val_loss: 0.9006 - val_acc: 0.8031 - val_top_k_categorical_accuracy: 0.9396 - val_precision: 0.8622 - val_recall: 0.7796 - val_fmeasure: 0.8185\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 223us/step - loss: 1.0632 - acc: 0.7112 - top_k_categorical_accuracy: 0.9037 - precision: 0.8526 - recall: 0.6277 - fmeasure: 0.7223 - val_loss: 1.0551 - val_acc: 0.7666 - val_top_k_categorical_accuracy: 0.9197 - val_precision: 0.8493 - val_recall: 0.7301 - val_fmeasure: 0.7847\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.4507 - acc: 0.8691 - top_k_categorical_accuracy: 0.9844 - precision: 0.9214 - recall: 0.8193 - fmeasure: 0.8670 - val_loss: 0.9048 - val_acc: 0.8031 - val_top_k_categorical_accuracy: 0.9382 - val_precision: 0.8650 - val_recall: 0.7829 - val_fmeasure: 0.8217\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 225us/step - loss: 1.0419 - acc: 0.7165 - top_k_categorical_accuracy: 0.9058 - precision: 0.8561 - recall: 0.6353 - fmeasure: 0.7286 - val_loss: 1.0473 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8582 - val_recall: 0.7464 - val_fmeasure: 0.7978\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.4562 - acc: 0.8673 - top_k_categorical_accuracy: 0.9825 - precision: 0.9196 - recall: 0.8202 - fmeasure: 0.8667 - val_loss: 0.9369 - val_acc: 0.8006 - val_top_k_categorical_accuracy: 0.9371 - val_precision: 0.8616 - val_recall: 0.7790 - val_fmeasure: 0.8178\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 230us/step - loss: 1.0229 - acc: 0.7206 - top_k_categorical_accuracy: 0.9095 - precision: 0.8618 - recall: 0.6400 - fmeasure: 0.7336 - val_loss: 1.0521 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.8509 - val_recall: 0.7304 - val_fmeasure: 0.7855\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 255us/step - loss: 0.4306 - acc: 0.8781 - top_k_categorical_accuracy: 0.9845 - precision: 0.9231 - recall: 0.8288 - fmeasure: 0.8729 - val_loss: 0.9241 - val_acc: 0.8003 - val_top_k_categorical_accuracy: 0.9385 - val_precision: 0.8562 - val_recall: 0.7748 - val_fmeasure: 0.8131\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 6s 230us/step - loss: 1.0180 - acc: 0.7211 - top_k_categorical_accuracy: 0.9105 - precision: 0.8546 - recall: 0.6439 - fmeasure: 0.7336 - val_loss: 1.1207 - val_acc: 0.7627 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8307 - val_recall: 0.7318 - val_fmeasure: 0.7777\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 253us/step - loss: 0.4460 - acc: 0.8690 - top_k_categorical_accuracy: 0.9831 - precision: 0.9177 - recall: 0.8192 - fmeasure: 0.8652 - val_loss: 0.9166 - val_acc: 0.8012 - val_top_k_categorical_accuracy: 0.9402 - val_precision: 0.8567 - val_recall: 0.7739 - val_fmeasure: 0.8129\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.3655 - acc: 0.8896 - top_k_categorical_accuracy: 0.9889 - precision: 0.9262 - recall: 0.8498 - fmeasure: 0.8861 - val_loss: 0.8974 - val_acc: 0.8110 - val_top_k_categorical_accuracy: 0.9424 - val_precision: 0.8581 - val_recall: 0.7922 - val_fmeasure: 0.8235\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.3503 - acc: 0.8958 - top_k_categorical_accuracy: 0.9916 - precision: 0.9297 - recall: 0.8598 - fmeasure: 0.8931 - val_loss: 0.9149 - val_acc: 0.8060 - val_top_k_categorical_accuracy: 0.9396 - val_precision: 0.8581 - val_recall: 0.7843 - val_fmeasure: 0.8193\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 255us/step - loss: 0.3235 - acc: 0.8989 - top_k_categorical_accuracy: 0.9918 - precision: 0.9320 - recall: 0.8683 - fmeasure: 0.8988 - val_loss: 0.9410 - val_acc: 0.8037 - val_top_k_categorical_accuracy: 0.9371 - val_precision: 0.8532 - val_recall: 0.7798 - val_fmeasure: 0.8147\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.3130 - acc: 0.8990 - top_k_categorical_accuracy: 0.9925 - precision: 0.9321 - recall: 0.8697 - fmeasure: 0.8996 - val_loss: 0.9332 - val_acc: 0.8054 - val_top_k_categorical_accuracy: 0.9407 - val_precision: 0.8530 - val_recall: 0.7877 - val_fmeasure: 0.8188\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.2970 - acc: 0.9025 - top_k_categorical_accuracy: 0.9929 - precision: 0.9318 - recall: 0.8781 - fmeasure: 0.9039 - val_loss: 0.9644 - val_acc: 0.8023 - val_top_k_categorical_accuracy: 0.9357 - val_precision: 0.8442 - val_recall: 0.7815 - val_fmeasure: 0.8114\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.2893 - acc: 0.9057 - top_k_categorical_accuracy: 0.9942 - precision: 0.9337 - recall: 0.8791 - fmeasure: 0.9053 - val_loss: 0.9320 - val_acc: 0.7987 - val_top_k_categorical_accuracy: 0.9407 - val_precision: 0.8406 - val_recall: 0.7765 - val_fmeasure: 0.8069\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.2846 - acc: 0.9074 - top_k_categorical_accuracy: 0.9952 - precision: 0.9334 - recall: 0.8832 - fmeasure: 0.9075 - val_loss: 0.9021 - val_acc: 0.8203 - val_top_k_categorical_accuracy: 0.9433 - val_precision: 0.8612 - val_recall: 0.7947 - val_fmeasure: 0.8264\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.2830 - acc: 0.9078 - top_k_categorical_accuracy: 0.9949 - precision: 0.9341 - recall: 0.8825 - fmeasure: 0.9073 - val_loss: 0.9332 - val_acc: 0.8099 - val_top_k_categorical_accuracy: 0.9438 - val_precision: 0.8459 - val_recall: 0.7885 - val_fmeasure: 0.8160\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.2519 - acc: 0.9171 - top_k_categorical_accuracy: 0.9969 - precision: 0.9396 - recall: 0.8929 - fmeasure: 0.9154 - val_loss: 0.9385 - val_acc: 0.8104 - val_top_k_categorical_accuracy: 0.9413 - val_precision: 0.8502 - val_recall: 0.7925 - val_fmeasure: 0.8201\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.2481 - acc: 0.9185 - top_k_categorical_accuracy: 0.9955 - precision: 0.9385 - recall: 0.8964 - fmeasure: 0.9168 - val_loss: 0.9327 - val_acc: 0.8031 - val_top_k_categorical_accuracy: 0.9405 - val_precision: 0.8514 - val_recall: 0.7838 - val_fmeasure: 0.8160\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.2463 - acc: 0.9214 - top_k_categorical_accuracy: 0.9967 - precision: 0.9410 - recall: 0.8965 - fmeasure: 0.9180 - val_loss: 0.9137 - val_acc: 0.8110 - val_top_k_categorical_accuracy: 0.9416 - val_precision: 0.8564 - val_recall: 0.7919 - val_fmeasure: 0.8227\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 259us/step - loss: 0.2344 - acc: 0.9232 - top_k_categorical_accuracy: 0.9974 - precision: 0.9425 - recall: 0.9020 - fmeasure: 0.9216 - val_loss: 0.9437 - val_acc: 0.8074 - val_top_k_categorical_accuracy: 0.9433 - val_precision: 0.8451 - val_recall: 0.7874 - val_fmeasure: 0.8151\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 264us/step - loss: 0.2417 - acc: 0.9201 - top_k_categorical_accuracy: 0.9975 - precision: 0.9379 - recall: 0.8973 - fmeasure: 0.9170 - val_loss: 0.9537 - val_acc: 0.8020 - val_top_k_categorical_accuracy: 0.9438 - val_precision: 0.8449 - val_recall: 0.7846 - val_fmeasure: 0.8135\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 262us/step - loss: 0.2132 - acc: 0.9278 - top_k_categorical_accuracy: 0.9974 - precision: 0.9466 - recall: 0.9086 - fmeasure: 0.9271 - val_loss: 0.9294 - val_acc: 0.8121 - val_top_k_categorical_accuracy: 0.9433 - val_precision: 0.8550 - val_recall: 0.7947 - val_fmeasure: 0.8235\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 261us/step - loss: 0.2181 - acc: 0.9258 - top_k_categorical_accuracy: 0.9981 - precision: 0.9426 - recall: 0.9067 - fmeasure: 0.9242 - val_loss: 0.9628 - val_acc: 0.8048 - val_top_k_categorical_accuracy: 0.9438 - val_precision: 0.8420 - val_recall: 0.7883 - val_fmeasure: 0.8140\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 259us/step - loss: 0.2140 - acc: 0.9256 - top_k_categorical_accuracy: 0.9976 - precision: 0.9442 - recall: 0.9074 - fmeasure: 0.9254 - val_loss: 1.0132 - val_acc: 0.7992 - val_top_k_categorical_accuracy: 0.9388 - val_precision: 0.8393 - val_recall: 0.7855 - val_fmeasure: 0.8113\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.2161 - acc: 0.9281 - top_k_categorical_accuracy: 0.9971 - precision: 0.9464 - recall: 0.9101 - fmeasure: 0.9277 - val_loss: 0.9852 - val_acc: 0.8048 - val_top_k_categorical_accuracy: 0.9391 - val_precision: 0.8495 - val_recall: 0.7919 - val_fmeasure: 0.8195\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.2141 - acc: 0.9260 - top_k_categorical_accuracy: 0.9975 - precision: 0.9416 - recall: 0.9113 - fmeasure: 0.9261 - val_loss: 0.9494 - val_acc: 0.8104 - val_top_k_categorical_accuracy: 0.9469 - val_precision: 0.8435 - val_recall: 0.7972 - val_fmeasure: 0.8195\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.1911 - acc: 0.9350 - top_k_categorical_accuracy: 0.9978 - precision: 0.9505 - recall: 0.9213 - fmeasure: 0.9355 - val_loss: 0.9767 - val_acc: 0.8147 - val_top_k_categorical_accuracy: 0.9455 - val_precision: 0.8491 - val_recall: 0.7995 - val_fmeasure: 0.8234\n",
            "the shape of x_train (8307, 5000)\n",
            "the shape of y_train (8307, 108)\n",
            "the shape of x_test (3561, 5000)\n",
            "the shape of y_test (3561, 108)\n",
            "base_line_now#######################################################################################################################################################################################################\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/100\n",
            "8307/8307 [==============================] - 6s 679us/step - loss: 4.0638 - acc: 0.1138 - top_k_categorical_accuracy: 0.3209 - precision: 0.2116 - recall: 0.0130 - fmeasure: 0.0242 - val_loss: 3.0424 - val_acc: 0.2603 - val_top_k_categorical_accuracy: 0.5920 - val_precision: 0.5948 - val_recall: 0.0716 - val_fmeasure: 0.1262\n",
            "Epoch 2/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 2.9274 - acc: 0.2934 - top_k_categorical_accuracy: 0.6176 - precision: 0.5921 - recall: 0.0944 - fmeasure: 0.1603 - val_loss: 2.2395 - val_acc: 0.4622 - val_top_k_categorical_accuracy: 0.7593 - val_precision: 0.8136 - val_recall: 0.2148 - val_fmeasure: 0.3377\n",
            "Epoch 3/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 2.3259 - acc: 0.4361 - top_k_categorical_accuracy: 0.7421 - precision: 0.7255 - recall: 0.2160 - fmeasure: 0.3298 - val_loss: 2.0842 - val_acc: 0.5102 - val_top_k_categorical_accuracy: 0.7644 - val_precision: 0.7411 - val_recall: 0.3319 - val_fmeasure: 0.4568\n",
            "Epoch 4/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 1.9979 - acc: 0.5168 - top_k_categorical_accuracy: 0.8025 - precision: 0.7480 - recall: 0.3041 - fmeasure: 0.4300 - val_loss: 1.7920 - val_acc: 0.5931 - val_top_k_categorical_accuracy: 0.8194 - val_precision: 0.7501 - val_recall: 0.4664 - val_fmeasure: 0.5738\n",
            "Epoch 5/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 1.7591 - acc: 0.5773 - top_k_categorical_accuracy: 0.8322 - precision: 0.7875 - recall: 0.3942 - fmeasure: 0.5239 - val_loss: 1.8880 - val_acc: 0.5580 - val_top_k_categorical_accuracy: 0.8093 - val_precision: 0.7155 - val_recall: 0.4631 - val_fmeasure: 0.5611\n",
            "Epoch 6/100\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 1.5561 - acc: 0.6261 - top_k_categorical_accuracy: 0.8547 - precision: 0.8106 - recall: 0.4618 - fmeasure: 0.5871 - val_loss: 1.4687 - val_acc: 0.6669 - val_top_k_categorical_accuracy: 0.8596 - val_precision: 0.7979 - val_recall: 0.5788 - val_fmeasure: 0.6702\n",
            "Epoch 7/100\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 1.4137 - acc: 0.6552 - top_k_categorical_accuracy: 0.8718 - precision: 0.8172 - recall: 0.5038 - fmeasure: 0.6218 - val_loss: 1.3844 - val_acc: 0.6877 - val_top_k_categorical_accuracy: 0.8756 - val_precision: 0.8063 - val_recall: 0.6116 - val_fmeasure: 0.6947\n",
            "Epoch 8/100\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 1.3275 - acc: 0.6787 - top_k_categorical_accuracy: 0.8885 - precision: 0.8247 - recall: 0.5435 - fmeasure: 0.6542 - val_loss: 1.5107 - val_acc: 0.6349 - val_top_k_categorical_accuracy: 0.8708 - val_precision: 0.7583 - val_recall: 0.5484 - val_fmeasure: 0.6357\n",
            "Epoch 9/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 1.2139 - acc: 0.7034 - top_k_categorical_accuracy: 0.9008 - precision: 0.8366 - recall: 0.5792 - fmeasure: 0.6835 - val_loss: 1.2656 - val_acc: 0.7133 - val_top_k_categorical_accuracy: 0.8877 - val_precision: 0.8046 - val_recall: 0.6588 - val_fmeasure: 0.7239\n",
            "Epoch 10/100\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 1.1407 - acc: 0.7189 - top_k_categorical_accuracy: 0.9095 - precision: 0.8478 - recall: 0.6073 - fmeasure: 0.7068 - val_loss: 1.4382 - val_acc: 0.6776 - val_top_k_categorical_accuracy: 0.8773 - val_precision: 0.7669 - val_recall: 0.6234 - val_fmeasure: 0.6872\n",
            "Epoch 11/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 1.0691 - acc: 0.7340 - top_k_categorical_accuracy: 0.9173 - precision: 0.8512 - recall: 0.6250 - fmeasure: 0.7200 - val_loss: 1.2972 - val_acc: 0.7057 - val_top_k_categorical_accuracy: 0.8950 - val_precision: 0.7902 - val_recall: 0.6653 - val_fmeasure: 0.7218\n",
            "Epoch 12/100\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 1.0177 - acc: 0.7384 - top_k_categorical_accuracy: 0.9218 - precision: 0.8507 - recall: 0.6476 - fmeasure: 0.7344 - val_loss: 1.2613 - val_acc: 0.7144 - val_top_k_categorical_accuracy: 0.8958 - val_precision: 0.8093 - val_recall: 0.6582 - val_fmeasure: 0.7254\n",
            "Epoch 13/100\n",
            "8307/8307 [==============================] - 2s 266us/step - loss: 0.9569 - acc: 0.7532 - top_k_categorical_accuracy: 0.9321 - precision: 0.8625 - recall: 0.6644 - fmeasure: 0.7498 - val_loss: 1.2562 - val_acc: 0.7085 - val_top_k_categorical_accuracy: 0.8950 - val_precision: 0.7935 - val_recall: 0.6650 - val_fmeasure: 0.7231\n",
            "Epoch 14/100\n",
            "8307/8307 [==============================] - 2s 262us/step - loss: 0.9045 - acc: 0.7655 - top_k_categorical_accuracy: 0.9354 - precision: 0.8711 - recall: 0.6809 - fmeasure: 0.7637 - val_loss: 1.3152 - val_acc: 0.7001 - val_top_k_categorical_accuracy: 0.8905 - val_precision: 0.7945 - val_recall: 0.6509 - val_fmeasure: 0.7150\n",
            "Epoch 15/100\n",
            "8307/8307 [==============================] - 2s 253us/step - loss: 0.8565 - acc: 0.7802 - top_k_categorical_accuracy: 0.9398 - precision: 0.8730 - recall: 0.7012 - fmeasure: 0.7770 - val_loss: 1.2093 - val_acc: 0.7335 - val_top_k_categorical_accuracy: 0.9020 - val_precision: 0.8042 - val_recall: 0.6950 - val_fmeasure: 0.7453\n",
            "Epoch 16/100\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.7903 - acc: 0.7952 - top_k_categorical_accuracy: 0.9512 - precision: 0.8800 - recall: 0.7211 - fmeasure: 0.7921 - val_loss: 1.1663 - val_acc: 0.7386 - val_top_k_categorical_accuracy: 0.9141 - val_precision: 0.8084 - val_recall: 0.6945 - val_fmeasure: 0.7467\n",
            "Epoch 17/100\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.7596 - acc: 0.7997 - top_k_categorical_accuracy: 0.9521 - precision: 0.8791 - recall: 0.7305 - fmeasure: 0.7973 - val_loss: 1.2265 - val_acc: 0.7254 - val_top_k_categorical_accuracy: 0.8997 - val_precision: 0.8085 - val_recall: 0.6675 - val_fmeasure: 0.7308\n",
            "Epoch 18/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.6999 - acc: 0.8153 - top_k_categorical_accuracy: 0.9611 - precision: 0.8922 - recall: 0.7411 - fmeasure: 0.8088 - val_loss: 1.0738 - val_acc: 0.7711 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.8329 - val_recall: 0.7251 - val_fmeasure: 0.7749\n",
            "Epoch 19/100\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.7026 - acc: 0.8086 - top_k_categorical_accuracy: 0.9599 - precision: 0.8856 - recall: 0.7440 - fmeasure: 0.8080 - val_loss: 1.1648 - val_acc: 0.7450 - val_top_k_categorical_accuracy: 0.9107 - val_precision: 0.8186 - val_recall: 0.6917 - val_fmeasure: 0.7493\n",
            "Epoch 20/100\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.6792 - acc: 0.8141 - top_k_categorical_accuracy: 0.9639 - precision: 0.8866 - recall: 0.7484 - fmeasure: 0.8111 - val_loss: 1.3393 - val_acc: 0.7138 - val_top_k_categorical_accuracy: 0.8899 - val_precision: 0.7800 - val_recall: 0.6782 - val_fmeasure: 0.7252\n",
            "Epoch 21/100\n",
            "8307/8307 [==============================] - 2s 255us/step - loss: 0.6238 - acc: 0.8275 - top_k_categorical_accuracy: 0.9647 - precision: 0.8950 - recall: 0.7697 - fmeasure: 0.8271 - val_loss: 1.0399 - val_acc: 0.7784 - val_top_k_categorical_accuracy: 0.9228 - val_precision: 0.8377 - val_recall: 0.7487 - val_fmeasure: 0.7903\n",
            "Epoch 22/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.6065 - acc: 0.8268 - top_k_categorical_accuracy: 0.9685 - precision: 0.8909 - recall: 0.7749 - fmeasure: 0.8284 - val_loss: 1.1498 - val_acc: 0.7453 - val_top_k_categorical_accuracy: 0.9093 - val_precision: 0.8096 - val_recall: 0.7147 - val_fmeasure: 0.7588\n",
            "Epoch 23/100\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.5881 - acc: 0.8334 - top_k_categorical_accuracy: 0.9727 - precision: 0.8976 - recall: 0.7742 - fmeasure: 0.8308 - val_loss: 1.1810 - val_acc: 0.7445 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8000 - val_recall: 0.7141 - val_fmeasure: 0.7544\n",
            "Epoch 24/100\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.5521 - acc: 0.8440 - top_k_categorical_accuracy: 0.9745 - precision: 0.9012 - recall: 0.7938 - fmeasure: 0.8436 - val_loss: 1.2111 - val_acc: 0.7380 - val_top_k_categorical_accuracy: 0.9082 - val_precision: 0.8022 - val_recall: 0.7043 - val_fmeasure: 0.7496\n",
            "Epoch 25/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.5324 - acc: 0.8476 - top_k_categorical_accuracy: 0.9769 - precision: 0.9066 - recall: 0.7939 - fmeasure: 0.8461 - val_loss: 1.1434 - val_acc: 0.7571 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8213 - val_recall: 0.7248 - val_fmeasure: 0.7696\n",
            "Epoch 26/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.5130 - acc: 0.8515 - top_k_categorical_accuracy: 0.9792 - precision: 0.9034 - recall: 0.8053 - fmeasure: 0.8512 - val_loss: 1.1503 - val_acc: 0.7585 - val_top_k_categorical_accuracy: 0.9202 - val_precision: 0.8079 - val_recall: 0.7284 - val_fmeasure: 0.7658\n",
            "Epoch 27/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.5129 - acc: 0.8472 - top_k_categorical_accuracy: 0.9781 - precision: 0.9015 - recall: 0.8055 - fmeasure: 0.8504 - val_loss: 1.1103 - val_acc: 0.7633 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.8123 - val_recall: 0.7321 - val_fmeasure: 0.7698\n",
            "Epoch 28/100\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.4879 - acc: 0.8543 - top_k_categorical_accuracy: 0.9809 - precision: 0.9053 - recall: 0.8063 - fmeasure: 0.8525 - val_loss: 1.2405 - val_acc: 0.7459 - val_top_k_categorical_accuracy: 0.9127 - val_precision: 0.7977 - val_recall: 0.7223 - val_fmeasure: 0.7578\n",
            "Epoch 29/100\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.4512 - acc: 0.8664 - top_k_categorical_accuracy: 0.9823 - precision: 0.9168 - recall: 0.8257 - fmeasure: 0.8685 - val_loss: 1.0419 - val_acc: 0.7871 - val_top_k_categorical_accuracy: 0.9273 - val_precision: 0.8336 - val_recall: 0.7644 - val_fmeasure: 0.7973\n",
            "Epoch 30/100\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.4499 - acc: 0.8665 - top_k_categorical_accuracy: 0.9833 - precision: 0.9115 - recall: 0.8246 - fmeasure: 0.8656 - val_loss: 1.4034 - val_acc: 0.7161 - val_top_k_categorical_accuracy: 0.8936 - val_precision: 0.7773 - val_recall: 0.6883 - val_fmeasure: 0.7297\n",
            "Epoch 31/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.4710 - acc: 0.8605 - top_k_categorical_accuracy: 0.9805 - precision: 0.9084 - recall: 0.8235 - fmeasure: 0.8635 - val_loss: 1.1105 - val_acc: 0.7753 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.8215 - val_recall: 0.7520 - val_fmeasure: 0.7850\n",
            "Epoch 32/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.4156 - acc: 0.8710 - top_k_categorical_accuracy: 0.9876 - precision: 0.9116 - recall: 0.8327 - fmeasure: 0.8700 - val_loss: 1.0836 - val_acc: 0.7734 - val_top_k_categorical_accuracy: 0.9183 - val_precision: 0.8410 - val_recall: 0.7445 - val_fmeasure: 0.7894\n",
            "Epoch 33/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.4112 - acc: 0.8719 - top_k_categorical_accuracy: 0.9875 - precision: 0.9181 - recall: 0.8333 - fmeasure: 0.8733 - val_loss: 1.0997 - val_acc: 0.7787 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.8243 - val_recall: 0.7613 - val_fmeasure: 0.7914\n",
            "Epoch 34/100\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3985 - acc: 0.8783 - top_k_categorical_accuracy: 0.9894 - precision: 0.9190 - recall: 0.8443 - fmeasure: 0.8798 - val_loss: 1.1492 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9222 - val_precision: 0.8067 - val_recall: 0.7489 - val_fmeasure: 0.7765\n",
            "Epoch 35/100\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3977 - acc: 0.8756 - top_k_categorical_accuracy: 0.9890 - precision: 0.9166 - recall: 0.8419 - fmeasure: 0.8774 - val_loss: 1.1412 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8081 - val_recall: 0.7436 - val_fmeasure: 0.7743\n",
            "Epoch 36/100\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3815 - acc: 0.8838 - top_k_categorical_accuracy: 0.9893 - precision: 0.9172 - recall: 0.8530 - fmeasure: 0.8837 - val_loss: 1.1994 - val_acc: 0.7529 - val_top_k_categorical_accuracy: 0.9180 - val_precision: 0.8036 - val_recall: 0.7237 - val_fmeasure: 0.7613\n",
            "Epoch 37/100\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.3549 - acc: 0.8884 - top_k_categorical_accuracy: 0.9890 - precision: 0.9277 - recall: 0.8547 - fmeasure: 0.8894 - val_loss: 1.2321 - val_acc: 0.7616 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.8049 - val_recall: 0.7411 - val_fmeasure: 0.7714\n",
            "Epoch 38/100\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.3617 - acc: 0.8884 - top_k_categorical_accuracy: 0.9900 - precision: 0.9228 - recall: 0.8558 - fmeasure: 0.8878 - val_loss: 1.1677 - val_acc: 0.7762 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8090 - val_recall: 0.7588 - val_fmeasure: 0.7829\n",
            "Epoch 39/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.3409 - acc: 0.8945 - top_k_categorical_accuracy: 0.9912 - precision: 0.9261 - recall: 0.8634 - fmeasure: 0.8934 - val_loss: 1.1144 - val_acc: 0.7683 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8215 - val_recall: 0.7450 - val_fmeasure: 0.7811\n",
            "Epoch 40/100\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.3201 - acc: 0.8990 - top_k_categorical_accuracy: 0.9941 - precision: 0.9320 - recall: 0.8685 - fmeasure: 0.8989 - val_loss: 1.0897 - val_acc: 0.7818 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8204 - val_recall: 0.7661 - val_fmeasure: 0.7921\n",
            "Epoch 41/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.3218 - acc: 0.8989 - top_k_categorical_accuracy: 0.9927 - precision: 0.9299 - recall: 0.8730 - fmeasure: 0.9003 - val_loss: 1.1564 - val_acc: 0.7672 - val_top_k_categorical_accuracy: 0.9281 - val_precision: 0.8102 - val_recall: 0.7512 - val_fmeasure: 0.7793\n",
            "Epoch 42/100\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.3207 - acc: 0.8997 - top_k_categorical_accuracy: 0.9941 - precision: 0.9282 - recall: 0.8710 - fmeasure: 0.8985 - val_loss: 1.1915 - val_acc: 0.7669 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.8085 - val_recall: 0.7419 - val_fmeasure: 0.7736\n",
            "Epoch 43/100\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.3004 - acc: 0.9043 - top_k_categorical_accuracy: 0.9937 - precision: 0.9331 - recall: 0.8758 - fmeasure: 0.9033 - val_loss: 1.2401 - val_acc: 0.7633 - val_top_k_categorical_accuracy: 0.9188 - val_precision: 0.8110 - val_recall: 0.7411 - val_fmeasure: 0.7742\n",
            "Epoch 44/100\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.3058 - acc: 0.9010 - top_k_categorical_accuracy: 0.9937 - precision: 0.9297 - recall: 0.8750 - fmeasure: 0.9013 - val_loss: 1.1978 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8104 - val_recall: 0.7574 - val_fmeasure: 0.7828\n",
            "Epoch 45/100\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.3031 - acc: 0.9001 - top_k_categorical_accuracy: 0.9929 - precision: 0.9318 - recall: 0.8747 - fmeasure: 0.9021 - val_loss: 1.2194 - val_acc: 0.7616 - val_top_k_categorical_accuracy: 0.9160 - val_precision: 0.8054 - val_recall: 0.7428 - val_fmeasure: 0.7726\n",
            "Epoch 46/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2997 - acc: 0.9031 - top_k_categorical_accuracy: 0.9931 - precision: 0.9315 - recall: 0.8788 - fmeasure: 0.9041 - val_loss: 1.1493 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.8209 - val_recall: 0.7571 - val_fmeasure: 0.7874\n",
            "Epoch 47/100\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.2783 - acc: 0.9126 - top_k_categorical_accuracy: 0.9957 - precision: 0.9381 - recall: 0.8868 - fmeasure: 0.9116 - val_loss: 1.2501 - val_acc: 0.7582 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7928 - val_recall: 0.7453 - val_fmeasure: 0.7682\n",
            "Epoch 48/100\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.2704 - acc: 0.9122 - top_k_categorical_accuracy: 0.9955 - precision: 0.9382 - recall: 0.8907 - fmeasure: 0.9136 - val_loss: 1.2022 - val_acc: 0.7804 - val_top_k_categorical_accuracy: 0.9273 - val_precision: 0.8146 - val_recall: 0.7633 - val_fmeasure: 0.7879\n",
            "Epoch 49/100\n",
            "8307/8307 [==============================] - 2s 244us/step - loss: 0.2682 - acc: 0.9122 - top_k_categorical_accuracy: 0.9954 - precision: 0.9361 - recall: 0.8893 - fmeasure: 0.9119 - val_loss: 1.3907 - val_acc: 0.7405 - val_top_k_categorical_accuracy: 0.9121 - val_precision: 0.7805 - val_recall: 0.7270 - val_fmeasure: 0.7526\n",
            "Epoch 50/100\n",
            "8307/8307 [==============================] - 2s 241us/step - loss: 0.2704 - acc: 0.9098 - top_k_categorical_accuracy: 0.9953 - precision: 0.9335 - recall: 0.8886 - fmeasure: 0.9103 - val_loss: 1.2443 - val_acc: 0.7714 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8040 - val_recall: 0.7518 - val_fmeasure: 0.7767\n",
            "Epoch 51/100\n",
            "8307/8307 [==============================] - 2s 242us/step - loss: 0.2571 - acc: 0.9156 - top_k_categorical_accuracy: 0.9954 - precision: 0.9396 - recall: 0.8936 - fmeasure: 0.9158 - val_loss: 1.2500 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.8093 - val_recall: 0.7498 - val_fmeasure: 0.7782\n",
            "Epoch 52/100\n",
            "8307/8307 [==============================] - 2s 245us/step - loss: 0.2734 - acc: 0.9101 - top_k_categorical_accuracy: 0.9949 - precision: 0.9335 - recall: 0.8895 - fmeasure: 0.9108 - val_loss: 1.2090 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9264 - val_precision: 0.8149 - val_recall: 0.7650 - val_fmeasure: 0.7889\n",
            "Epoch 53/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2585 - acc: 0.9147 - top_k_categorical_accuracy: 0.9942 - precision: 0.9383 - recall: 0.8944 - fmeasure: 0.9156 - val_loss: 1.2814 - val_acc: 0.7661 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8009 - val_recall: 0.7515 - val_fmeasure: 0.7752\n",
            "Epoch 54/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2512 - acc: 0.9165 - top_k_categorical_accuracy: 0.9963 - precision: 0.9390 - recall: 0.8971 - fmeasure: 0.9174 - val_loss: 1.2139 - val_acc: 0.7824 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.8177 - val_recall: 0.7624 - val_fmeasure: 0.7889\n",
            "Epoch 55/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2488 - acc: 0.9189 - top_k_categorical_accuracy: 0.9958 - precision: 0.9393 - recall: 0.9013 - fmeasure: 0.9197 - val_loss: 1.2752 - val_acc: 0.7728 - val_top_k_categorical_accuracy: 0.9247 - val_precision: 0.8047 - val_recall: 0.7585 - val_fmeasure: 0.7807\n",
            "Epoch 56/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2303 - acc: 0.9212 - top_k_categorical_accuracy: 0.9967 - precision: 0.9425 - recall: 0.9051 - fmeasure: 0.9233 - val_loss: 1.2676 - val_acc: 0.7675 - val_top_k_categorical_accuracy: 0.9245 - val_precision: 0.8045 - val_recall: 0.7532 - val_fmeasure: 0.7778\n",
            "Epoch 57/100\n",
            "8307/8307 [==============================] - 2s 243us/step - loss: 0.2278 - acc: 0.9262 - top_k_categorical_accuracy: 0.9958 - precision: 0.9428 - recall: 0.9059 - fmeasure: 0.9238 - val_loss: 1.2343 - val_acc: 0.7658 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8017 - val_recall: 0.7523 - val_fmeasure: 0.7760\n",
            "Epoch 58/100\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.2347 - acc: 0.9215 - top_k_categorical_accuracy: 0.9958 - precision: 0.9434 - recall: 0.9054 - fmeasure: 0.9239 - val_loss: 1.4281 - val_acc: 0.7546 - val_top_k_categorical_accuracy: 0.9118 - val_precision: 0.7871 - val_recall: 0.7372 - val_fmeasure: 0.7611\n",
            "Epoch 59/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.2263 - acc: 0.9245 - top_k_categorical_accuracy: 0.9967 - precision: 0.9427 - recall: 0.9090 - fmeasure: 0.9254 - val_loss: 1.2982 - val_acc: 0.7669 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.7974 - val_recall: 0.7532 - val_fmeasure: 0.7745\n",
            "Epoch 60/100\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.2293 - acc: 0.9251 - top_k_categorical_accuracy: 0.9958 - precision: 0.9432 - recall: 0.9100 - fmeasure: 0.9262 - val_loss: 1.3016 - val_acc: 0.7723 - val_top_k_categorical_accuracy: 0.9172 - val_precision: 0.8084 - val_recall: 0.7596 - val_fmeasure: 0.7831\n",
            "Epoch 61/100\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.2156 - acc: 0.9309 - top_k_categorical_accuracy: 0.9978 - precision: 0.9494 - recall: 0.9125 - fmeasure: 0.9304 - val_loss: 1.2592 - val_acc: 0.7748 - val_top_k_categorical_accuracy: 0.9228 - val_precision: 0.8103 - val_recall: 0.7585 - val_fmeasure: 0.7834\n",
            "Epoch 62/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.2206 - acc: 0.9275 - top_k_categorical_accuracy: 0.9958 - precision: 0.9425 - recall: 0.9131 - fmeasure: 0.9274 - val_loss: 1.2555 - val_acc: 0.7852 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.8185 - val_recall: 0.7700 - val_fmeasure: 0.7934\n",
            "Epoch 63/100\n",
            "8307/8307 [==============================] - 2s 257us/step - loss: 0.2113 - acc: 0.9266 - top_k_categorical_accuracy: 0.9983 - precision: 0.9439 - recall: 0.9116 - fmeasure: 0.9274 - val_loss: 1.2665 - val_acc: 0.7793 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8123 - val_recall: 0.7650 - val_fmeasure: 0.7878\n",
            "Epoch 64/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.2180 - acc: 0.9280 - top_k_categorical_accuracy: 0.9966 - precision: 0.9452 - recall: 0.9136 - fmeasure: 0.9290 - val_loss: 1.3310 - val_acc: 0.7759 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.7995 - val_recall: 0.7664 - val_fmeasure: 0.7825\n",
            "Epoch 65/100\n",
            "8307/8307 [==============================] - 2s 262us/step - loss: 0.2104 - acc: 0.9304 - top_k_categorical_accuracy: 0.9975 - precision: 0.9466 - recall: 0.9154 - fmeasure: 0.9306 - val_loss: 1.3267 - val_acc: 0.7751 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8057 - val_recall: 0.7630 - val_fmeasure: 0.7836\n",
            "Epoch 66/100\n",
            "8307/8307 [==============================] - 2s 253us/step - loss: 0.1979 - acc: 0.9346 - top_k_categorical_accuracy: 0.9967 - precision: 0.9496 - recall: 0.9216 - fmeasure: 0.9353 - val_loss: 1.2956 - val_acc: 0.7680 - val_top_k_categorical_accuracy: 0.9233 - val_precision: 0.7990 - val_recall: 0.7554 - val_fmeasure: 0.7764\n",
            "Epoch 67/100\n",
            "8307/8307 [==============================] - 2s 255us/step - loss: 0.2036 - acc: 0.9315 - top_k_categorical_accuracy: 0.9984 - precision: 0.9484 - recall: 0.9179 - fmeasure: 0.9328 - val_loss: 1.3215 - val_acc: 0.7779 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.8092 - val_recall: 0.7661 - val_fmeasure: 0.7869\n",
            "Epoch 68/100\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.1860 - acc: 0.9358 - top_k_categorical_accuracy: 0.9983 - precision: 0.9507 - recall: 0.9207 - fmeasure: 0.9353 - val_loss: 1.4226 - val_acc: 0.7546 - val_top_k_categorical_accuracy: 0.9152 - val_precision: 0.7904 - val_recall: 0.7445 - val_fmeasure: 0.7666\n",
            "Epoch 69/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.1965 - acc: 0.9350 - top_k_categorical_accuracy: 0.9977 - precision: 0.9498 - recall: 0.9234 - fmeasure: 0.9363 - val_loss: 1.3081 - val_acc: 0.7773 - val_top_k_categorical_accuracy: 0.9225 - val_precision: 0.8079 - val_recall: 0.7647 - val_fmeasure: 0.7855\n",
            "Epoch 70/100\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.1892 - acc: 0.9363 - top_k_categorical_accuracy: 0.9983 - precision: 0.9515 - recall: 0.9240 - fmeasure: 0.9375 - val_loss: 1.3671 - val_acc: 0.7633 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7913 - val_recall: 0.7504 - val_fmeasure: 0.7702\n",
            "Epoch 71/100\n",
            "8307/8307 [==============================] - 2s 258us/step - loss: 0.1938 - acc: 0.9354 - top_k_categorical_accuracy: 0.9977 - precision: 0.9491 - recall: 0.9215 - fmeasure: 0.9350 - val_loss: 1.3085 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8086 - val_recall: 0.7666 - val_fmeasure: 0.7869\n",
            "Epoch 72/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.1965 - acc: 0.9340 - top_k_categorical_accuracy: 0.9980 - precision: 0.9462 - recall: 0.9197 - fmeasure: 0.9327 - val_loss: 1.3436 - val_acc: 0.7779 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8010 - val_recall: 0.7686 - val_fmeasure: 0.7843\n",
            "Epoch 73/100\n",
            "8307/8307 [==============================] - 2s 257us/step - loss: 0.1823 - acc: 0.9399 - top_k_categorical_accuracy: 0.9987 - precision: 0.9520 - recall: 0.9274 - fmeasure: 0.9395 - val_loss: 1.3700 - val_acc: 0.7627 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7902 - val_recall: 0.7509 - val_fmeasure: 0.7699\n",
            "Epoch 74/100\n",
            "8307/8307 [==============================] - 2s 248us/step - loss: 0.1756 - acc: 0.9426 - top_k_categorical_accuracy: 0.9981 - precision: 0.9541 - recall: 0.9317 - fmeasure: 0.9427 - val_loss: 1.2696 - val_acc: 0.7933 - val_top_k_categorical_accuracy: 0.9259 - val_precision: 0.8224 - val_recall: 0.7818 - val_fmeasure: 0.8014\n",
            "Epoch 75/100\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.1751 - acc: 0.9403 - top_k_categorical_accuracy: 0.9976 - precision: 0.9523 - recall: 0.9317 - fmeasure: 0.9418 - val_loss: 1.3593 - val_acc: 0.7689 - val_top_k_categorical_accuracy: 0.9158 - val_precision: 0.7976 - val_recall: 0.7562 - val_fmeasure: 0.7762\n",
            "Epoch 76/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.1733 - acc: 0.9407 - top_k_categorical_accuracy: 0.9976 - precision: 0.9531 - recall: 0.9279 - fmeasure: 0.9402 - val_loss: 1.3731 - val_acc: 0.7767 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.8043 - val_recall: 0.7694 - val_fmeasure: 0.7863\n",
            "Epoch 77/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.1823 - acc: 0.9387 - top_k_categorical_accuracy: 0.9981 - precision: 0.9501 - recall: 0.9293 - fmeasure: 0.9395 - val_loss: 1.2964 - val_acc: 0.7832 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.8106 - val_recall: 0.7725 - val_fmeasure: 0.7910\n",
            "Epoch 78/100\n",
            "8307/8307 [==============================] - 2s 246us/step - loss: 0.1796 - acc: 0.9393 - top_k_categorical_accuracy: 0.9978 - precision: 0.9510 - recall: 0.9261 - fmeasure: 0.9382 - val_loss: 1.3149 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9281 - val_precision: 0.8121 - val_recall: 0.7731 - val_fmeasure: 0.7919\n",
            "Epoch 79/100\n",
            "8307/8307 [==============================] - 2s 256us/step - loss: 0.1602 - acc: 0.9443 - top_k_categorical_accuracy: 0.9990 - precision: 0.9548 - recall: 0.9350 - fmeasure: 0.9447 - val_loss: 1.3872 - val_acc: 0.7619 - val_top_k_categorical_accuracy: 0.9186 - val_precision: 0.7877 - val_recall: 0.7520 - val_fmeasure: 0.7693\n",
            "Epoch 80/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.1593 - acc: 0.9485 - top_k_categorical_accuracy: 0.9994 - precision: 0.9585 - recall: 0.9363 - fmeasure: 0.9472 - val_loss: 1.3603 - val_acc: 0.7748 - val_top_k_categorical_accuracy: 0.9228 - val_precision: 0.8035 - val_recall: 0.7616 - val_fmeasure: 0.7818\n",
            "Epoch 81/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.1688 - acc: 0.9438 - top_k_categorical_accuracy: 0.9982 - precision: 0.9571 - recall: 0.9331 - fmeasure: 0.9448 - val_loss: 1.3183 - val_acc: 0.7812 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8112 - val_recall: 0.7723 - val_fmeasure: 0.7911\n",
            "Epoch 82/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.1649 - acc: 0.9434 - top_k_categorical_accuracy: 0.9992 - precision: 0.9556 - recall: 0.9328 - fmeasure: 0.9440 - val_loss: 1.4615 - val_acc: 0.7624 - val_top_k_categorical_accuracy: 0.9278 - val_precision: 0.7833 - val_recall: 0.7526 - val_fmeasure: 0.7675\n",
            "Epoch 83/100\n",
            "8307/8307 [==============================] - 2s 249us/step - loss: 0.1712 - acc: 0.9443 - top_k_categorical_accuracy: 0.9980 - precision: 0.9544 - recall: 0.9364 - fmeasure: 0.9453 - val_loss: 1.3492 - val_acc: 0.7782 - val_top_k_categorical_accuracy: 0.9205 - val_precision: 0.8042 - val_recall: 0.7638 - val_fmeasure: 0.7834\n",
            "Epoch 84/100\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.1534 - acc: 0.9505 - top_k_categorical_accuracy: 0.9990 - precision: 0.9603 - recall: 0.9403 - fmeasure: 0.9501 - val_loss: 1.4203 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.7842 - val_recall: 0.7504 - val_fmeasure: 0.7668\n",
            "Epoch 85/100\n",
            "8307/8307 [==============================] - 2s 255us/step - loss: 0.1572 - acc: 0.9461 - top_k_categorical_accuracy: 0.9990 - precision: 0.9543 - recall: 0.9356 - fmeasure: 0.9448 - val_loss: 1.4039 - val_acc: 0.7804 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.8012 - val_recall: 0.7723 - val_fmeasure: 0.7864\n",
            "Epoch 86/100\n",
            "8307/8307 [==============================] - 2s 247us/step - loss: 0.1475 - acc: 0.9504 - top_k_categorical_accuracy: 0.9993 - precision: 0.9607 - recall: 0.9398 - fmeasure: 0.9501 - val_loss: 1.3444 - val_acc: 0.7815 - val_top_k_categorical_accuracy: 0.9318 - val_precision: 0.8035 - val_recall: 0.7714 - val_fmeasure: 0.7870\n",
            "Epoch 87/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.1637 - acc: 0.9490 - top_k_categorical_accuracy: 0.9975 - precision: 0.9582 - recall: 0.9387 - fmeasure: 0.9483 - val_loss: 1.3555 - val_acc: 0.7863 - val_top_k_categorical_accuracy: 0.9236 - val_precision: 0.8111 - val_recall: 0.7756 - val_fmeasure: 0.7928\n",
            "Epoch 88/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.1515 - acc: 0.9482 - top_k_categorical_accuracy: 0.9989 - precision: 0.9586 - recall: 0.9401 - fmeasure: 0.9491 - val_loss: 1.4205 - val_acc: 0.7759 - val_top_k_categorical_accuracy: 0.9219 - val_precision: 0.7979 - val_recall: 0.7638 - val_fmeasure: 0.7804\n",
            "Epoch 89/100\n",
            "8307/8307 [==============================] - 2s 250us/step - loss: 0.1509 - acc: 0.9510 - top_k_categorical_accuracy: 0.9983 - precision: 0.9589 - recall: 0.9417 - fmeasure: 0.9502 - val_loss: 1.4660 - val_acc: 0.7655 - val_top_k_categorical_accuracy: 0.9214 - val_precision: 0.7929 - val_recall: 0.7551 - val_fmeasure: 0.7734\n",
            "Epoch 90/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.1471 - acc: 0.9522 - top_k_categorical_accuracy: 0.9982 - precision: 0.9615 - recall: 0.9440 - fmeasure: 0.9526 - val_loss: 1.3613 - val_acc: 0.7776 - val_top_k_categorical_accuracy: 0.9250 - val_precision: 0.7984 - val_recall: 0.7680 - val_fmeasure: 0.7828\n",
            "Epoch 91/100\n",
            "8307/8307 [==============================] - 2s 255us/step - loss: 0.1440 - acc: 0.9524 - top_k_categorical_accuracy: 0.9992 - precision: 0.9606 - recall: 0.9440 - fmeasure: 0.9522 - val_loss: 1.4144 - val_acc: 0.7807 - val_top_k_categorical_accuracy: 0.9231 - val_precision: 0.8060 - val_recall: 0.7694 - val_fmeasure: 0.7872\n",
            "Epoch 92/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.1463 - acc: 0.9540 - top_k_categorical_accuracy: 0.9993 - precision: 0.9618 - recall: 0.9457 - fmeasure: 0.9536 - val_loss: 1.5043 - val_acc: 0.7661 - val_top_k_categorical_accuracy: 0.9166 - val_precision: 0.7862 - val_recall: 0.7548 - val_fmeasure: 0.7701\n",
            "Epoch 93/100\n",
            "8307/8307 [==============================] - 3s 376us/step - loss: 0.1440 - acc: 0.9520 - top_k_categorical_accuracy: 0.9986 - precision: 0.9610 - recall: 0.9439 - fmeasure: 0.9523 - val_loss: 1.3782 - val_acc: 0.7835 - val_top_k_categorical_accuracy: 0.9256 - val_precision: 0.8048 - val_recall: 0.7756 - val_fmeasure: 0.7898\n",
            "Epoch 94/100\n",
            "8307/8307 [==============================] - 3s 356us/step - loss: 0.1414 - acc: 0.9512 - top_k_categorical_accuracy: 0.9987 - precision: 0.9599 - recall: 0.9438 - fmeasure: 0.9517 - val_loss: 1.4432 - val_acc: 0.7692 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.7911 - val_recall: 0.7616 - val_fmeasure: 0.7759\n",
            "Epoch 95/100\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.1382 - acc: 0.9543 - top_k_categorical_accuracy: 0.9987 - precision: 0.9612 - recall: 0.9458 - fmeasure: 0.9534 - val_loss: 1.5123 - val_acc: 0.7588 - val_top_k_categorical_accuracy: 0.9163 - val_precision: 0.7852 - val_recall: 0.7506 - val_fmeasure: 0.7674\n",
            "Epoch 96/100\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.1393 - acc: 0.9521 - top_k_categorical_accuracy: 0.9989 - precision: 0.9596 - recall: 0.9445 - fmeasure: 0.9519 - val_loss: 1.3855 - val_acc: 0.7843 - val_top_k_categorical_accuracy: 0.9242 - val_precision: 0.8052 - val_recall: 0.7759 - val_fmeasure: 0.7901\n",
            "Epoch 97/100\n",
            "8307/8307 [==============================] - 2s 251us/step - loss: 0.1297 - acc: 0.9555 - top_k_categorical_accuracy: 0.9990 - precision: 0.9643 - recall: 0.9466 - fmeasure: 0.9553 - val_loss: 1.4070 - val_acc: 0.7810 - val_top_k_categorical_accuracy: 0.9261 - val_precision: 0.7981 - val_recall: 0.7725 - val_fmeasure: 0.7850\n",
            "Epoch 98/100\n",
            "8307/8307 [==============================] - 2s 252us/step - loss: 0.1277 - acc: 0.9582 - top_k_categorical_accuracy: 0.9993 - precision: 0.9648 - recall: 0.9522 - fmeasure: 0.9584 - val_loss: 1.4486 - val_acc: 0.7666 - val_top_k_categorical_accuracy: 0.9239 - val_precision: 0.7885 - val_recall: 0.7582 - val_fmeasure: 0.7729\n",
            "Epoch 99/100\n",
            "8307/8307 [==============================] - 2s 254us/step - loss: 0.1289 - acc: 0.9559 - top_k_categorical_accuracy: 0.9990 - precision: 0.9632 - recall: 0.9488 - fmeasure: 0.9559 - val_loss: 1.4366 - val_acc: 0.7759 - val_top_k_categorical_accuracy: 0.9217 - val_precision: 0.7999 - val_recall: 0.7672 - val_fmeasure: 0.7831\n",
            "Epoch 100/100\n",
            "8307/8307 [==============================] - 2s 256us/step - loss: 0.1319 - acc: 0.9590 - top_k_categorical_accuracy: 0.9990 - precision: 0.9656 - recall: 0.9516 - fmeasure: 0.9585 - val_loss: 1.4336 - val_acc: 0.7756 - val_top_k_categorical_accuracy: 0.9200 - val_precision: 0.7968 - val_recall: 0.7652 - val_fmeasure: 0.7806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Py6svpp1YU",
        "colab_type": "code",
        "outputId": "38b1d8f3-4367-41a1-f25c-044d814118d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#CNN               ############# test for noise adding  , function :: creat_data############\n",
        "\n",
        "\n",
        "history_CNN = []\n",
        "for i in range(NB_TECHS):\n",
        "    his = my_history()\n",
        "    X_temp,y_temp = random_launch(X_train_saved,y_train_saved,i)\n",
        "    X_temp = sequence.pad_sequences(X_temp, maxlen=maxlen,padding='post',truncating='post')\n",
        "    X_temp = X_temp[:,:,np.newaxis]\n",
        "    y_temp = np_utils.to_categorical(y_temp, NB_CLASSES)\n",
        "    X_train = sequence.pad_sequences(X_train_saved, maxlen=maxlen,padding='post',truncating='post')\n",
        "    X_train = X_train[:,:,np.newaxis]\n",
        "    y_train = np_utils.to_categorical(y_train_saved, NB_CLASSES)\n",
        "    X_test = sequence.pad_sequences(X_test_saved, maxlen=maxlen,padding='post',truncating='post')\n",
        "    X_test = X_test[:,:,np.newaxis]\n",
        "    y_test = np_utils.to_categorical(y_test_saved, NB_CLASSES)\n",
        "    model_CNN = CNN(maxlen,NB_CLASSES)\n",
        "    model_CNN.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy','top_k_categorical_accuracy', precision, recall, fmeasure])\n",
        "    run_CNN(X_train,y_train,X_test,y_test,X_temp,y_temp,BATCH_SIZE,history = his)\n",
        "    history_CNN.append(his)\n",
        "\n",
        "print('the shape of x_train',X_train.shape)\n",
        "print('the shape of y_train',y_train.shape)\n",
        "print('the shape of x_test',X_test.shape)\n",
        "print('the shape of y_test',y_test.shape)\n",
        "\n",
        "print('base_line_now#######################################################################################################################################################################################################')\n",
        "model_CNN_org = CNN(maxlen,NB_CLASSES)\n",
        "model_CNN_org.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy','top_k_categorical_accuracy', precision, recall, fmeasure])\n",
        "history_CNN_org = model_CNN_org.fit(X_train,y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCHS,validation_data=(X_test,y_test),verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adding noise......\n",
            "00% data has been dealed\n",
            "10% data has been dealed\n",
            "20% data has been dealed\n",
            "30% data has been dealed\n",
            "40% data has been dealed\n",
            "50% data has been dealed\n",
            "60% data has been dealed\n",
            "70% data has been dealed\n",
            "80% data has been dealed\n",
            "90% data has been dealed\n",
            "100% data has been dealed\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 19s 2ms/step - loss: 4.1638 - acc: 0.1022 - top_k_categorical_accuracy: 0.2860 - precision: 0.2940 - recall: 0.0107 - fmeasure: 0.0205 - val_loss: 2.8823 - val_acc: 0.4049 - val_top_k_categorical_accuracy: 0.7113 - val_precision: 0.7872 - val_recall: 0.0278 - val_fmeasure: 0.0533\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 999us/step - loss: 3.0392 - acc: 0.2831 - top_k_categorical_accuracy: 0.5813 - precision: 0.6951 - recall: 0.0622 - fmeasure: 0.1120 - val_loss: 2.5660 - val_acc: 0.5074 - val_top_k_categorical_accuracy: 0.7638 - val_precision: 0.9337 - val_recall: 0.0601 - val_fmeasure: 0.1113\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 2.4485 - acc: 0.4272 - top_k_categorical_accuracy: 0.7242 - precision: 0.7768 - recall: 0.1547 - fmeasure: 0.2554 - val_loss: 1.9681 - val_acc: 0.6296 - val_top_k_categorical_accuracy: 0.8295 - val_precision: 0.9583 - val_recall: 0.2025 - val_fmeasure: 0.3314\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 2.0422 - acc: 0.5340 - top_k_categorical_accuracy: 0.7956 - precision: 0.8217 - recall: 0.2619 - fmeasure: 0.3949 - val_loss: 1.5075 - val_acc: 0.6950 - val_top_k_categorical_accuracy: 0.8736 - val_precision: 0.9453 - val_recall: 0.4268 - val_fmeasure: 0.5855\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 1.7336 - acc: 0.6076 - top_k_categorical_accuracy: 0.8439 - precision: 0.8532 - recall: 0.3655 - fmeasure: 0.5089 - val_loss: 1.2245 - val_acc: 0.7714 - val_top_k_categorical_accuracy: 0.8961 - val_precision: 0.9344 - val_recall: 0.5726 - val_fmeasure: 0.7086\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 1.5188 - acc: 0.6687 - top_k_categorical_accuracy: 0.8678 - precision: 0.8744 - recall: 0.4517 - fmeasure: 0.5938 - val_loss: 1.1512 - val_acc: 0.7810 - val_top_k_categorical_accuracy: 0.9006 - val_precision: 0.9370 - val_recall: 0.6052 - val_fmeasure: 0.7340\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 997us/step - loss: 1.3589 - acc: 0.6993 - top_k_categorical_accuracy: 0.8874 - precision: 0.8838 - recall: 0.5173 - fmeasure: 0.6510 - val_loss: 0.9896 - val_acc: 0.8020 - val_top_k_categorical_accuracy: 0.9079 - val_precision: 0.9212 - val_recall: 0.7091 - val_fmeasure: 0.8005\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 997us/step - loss: 1.2283 - acc: 0.7322 - top_k_categorical_accuracy: 0.8990 - precision: 0.8843 - recall: 0.5645 - fmeasure: 0.6877 - val_loss: 0.8865 - val_acc: 0.8228 - val_top_k_categorical_accuracy: 0.9211 - val_precision: 0.9148 - val_recall: 0.7467 - val_fmeasure: 0.8216\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 997us/step - loss: 1.1172 - acc: 0.7533 - top_k_categorical_accuracy: 0.9106 - precision: 0.8913 - recall: 0.6103 - fmeasure: 0.7232 - val_loss: 0.8286 - val_acc: 0.8402 - val_top_k_categorical_accuracy: 0.9287 - val_precision: 0.9297 - val_recall: 0.7638 - val_fmeasure: 0.8381\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 998us/step - loss: 1.0345 - acc: 0.7710 - top_k_categorical_accuracy: 0.9198 - precision: 0.8969 - recall: 0.6409 - fmeasure: 0.7466 - val_loss: 0.8038 - val_acc: 0.8498 - val_top_k_categorical_accuracy: 0.9295 - val_precision: 0.9270 - val_recall: 0.7916 - val_fmeasure: 0.8534\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.9620 - acc: 0.7908 - top_k_categorical_accuracy: 0.9268 - precision: 0.8955 - recall: 0.6679 - fmeasure: 0.7643 - val_loss: 0.7791 - val_acc: 0.8529 - val_top_k_categorical_accuracy: 0.9346 - val_precision: 0.9224 - val_recall: 0.7852 - val_fmeasure: 0.8478\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.8983 - acc: 0.8038 - top_k_categorical_accuracy: 0.9351 - precision: 0.8969 - recall: 0.6942 - fmeasure: 0.7818 - val_loss: 0.7423 - val_acc: 0.8655 - val_top_k_categorical_accuracy: 0.9374 - val_precision: 0.9287 - val_recall: 0.8155 - val_fmeasure: 0.8681\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.8394 - acc: 0.8153 - top_k_categorical_accuracy: 0.9397 - precision: 0.9043 - recall: 0.7154 - fmeasure: 0.7982 - val_loss: 0.6916 - val_acc: 0.8700 - val_top_k_categorical_accuracy: 0.9441 - val_precision: 0.9315 - val_recall: 0.8208 - val_fmeasure: 0.8722\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 995us/step - loss: 0.7997 - acc: 0.8185 - top_k_categorical_accuracy: 0.9462 - precision: 0.9053 - recall: 0.7257 - fmeasure: 0.8049 - val_loss: 0.6768 - val_acc: 0.8790 - val_top_k_categorical_accuracy: 0.9452 - val_precision: 0.9318 - val_recall: 0.8335 - val_fmeasure: 0.8795\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.7378 - acc: 0.8326 - top_k_categorical_accuracy: 0.9482 - precision: 0.9099 - recall: 0.7523 - fmeasure: 0.8230 - val_loss: 0.6914 - val_acc: 0.8787 - val_top_k_categorical_accuracy: 0.9447 - val_precision: 0.9263 - val_recall: 0.8455 - val_fmeasure: 0.8837\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.7042 - acc: 0.8434 - top_k_categorical_accuracy: 0.9510 - precision: 0.9152 - recall: 0.7650 - fmeasure: 0.8328 - val_loss: 0.6489 - val_acc: 0.8902 - val_top_k_categorical_accuracy: 0.9492 - val_precision: 0.9348 - val_recall: 0.8568 - val_fmeasure: 0.8938\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.6619 - acc: 0.8472 - top_k_categorical_accuracy: 0.9564 - precision: 0.9186 - recall: 0.7807 - fmeasure: 0.8435 - val_loss: 0.6853 - val_acc: 0.8778 - val_top_k_categorical_accuracy: 0.9469 - val_precision: 0.9254 - val_recall: 0.8534 - val_fmeasure: 0.8876\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.6350 - acc: 0.8581 - top_k_categorical_accuracy: 0.9596 - precision: 0.9178 - recall: 0.7961 - fmeasure: 0.8521 - val_loss: 0.6284 - val_acc: 0.8941 - val_top_k_categorical_accuracy: 0.9514 - val_precision: 0.9325 - val_recall: 0.8677 - val_fmeasure: 0.8987\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.6145 - acc: 0.8587 - top_k_categorical_accuracy: 0.9632 - precision: 0.9189 - recall: 0.7958 - fmeasure: 0.8525 - val_loss: 0.6130 - val_acc: 0.8939 - val_top_k_categorical_accuracy: 0.9528 - val_precision: 0.9291 - val_recall: 0.8739 - val_fmeasure: 0.9005\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 999us/step - loss: 0.5755 - acc: 0.8694 - top_k_categorical_accuracy: 0.9633 - precision: 0.9243 - recall: 0.8099 - fmeasure: 0.8629 - val_loss: 0.6085 - val_acc: 0.8933 - val_top_k_categorical_accuracy: 0.9545 - val_precision: 0.9299 - val_recall: 0.8708 - val_fmeasure: 0.8991\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.5407 - acc: 0.8726 - top_k_categorical_accuracy: 0.9687 - precision: 0.9273 - recall: 0.8221 - fmeasure: 0.8711 - val_loss: 0.5862 - val_acc: 0.8967 - val_top_k_categorical_accuracy: 0.9570 - val_precision: 0.9293 - val_recall: 0.8790 - val_fmeasure: 0.9032\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 923us/step - loss: 1.6084 - acc: 0.6234 - top_k_categorical_accuracy: 0.8482 - precision: 0.7594 - recall: 0.5168 - fmeasure: 0.6124 - val_loss: 2.4760 - val_acc: 0.3934 - val_top_k_categorical_accuracy: 0.7327 - val_precision: 0.5343 - val_recall: 0.2412 - val_fmeasure: 0.3317\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.7733 - acc: 0.8187 - top_k_categorical_accuracy: 0.9478 - precision: 0.8880 - recall: 0.7390 - fmeasure: 0.8048 - val_loss: 0.6592 - val_acc: 0.8703 - val_top_k_categorical_accuracy: 0.9520 - val_precision: 0.9345 - val_recall: 0.8113 - val_fmeasure: 0.8680\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 921us/step - loss: 1.0111 - acc: 0.7524 - top_k_categorical_accuracy: 0.9259 - precision: 0.8605 - recall: 0.6610 - fmeasure: 0.7465 - val_loss: 2.1719 - val_acc: 0.4471 - val_top_k_categorical_accuracy: 0.7796 - val_precision: 0.6159 - val_recall: 0.3215 - val_fmeasure: 0.4214\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.6959 - acc: 0.8339 - top_k_categorical_accuracy: 0.9549 - precision: 0.9012 - recall: 0.7636 - fmeasure: 0.8252 - val_loss: 0.6077 - val_acc: 0.8798 - val_top_k_categorical_accuracy: 0.9531 - val_precision: 0.9338 - val_recall: 0.8405 - val_fmeasure: 0.8843\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 920us/step - loss: 0.8542 - acc: 0.7864 - top_k_categorical_accuracy: 0.9425 - precision: 0.8758 - recall: 0.7060 - fmeasure: 0.7810 - val_loss: 1.9073 - val_acc: 0.5156 - val_top_k_categorical_accuracy: 0.8293 - val_precision: 0.6783 - val_recall: 0.3668 - val_fmeasure: 0.4747\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 998us/step - loss: 0.6724 - acc: 0.8381 - top_k_categorical_accuracy: 0.9590 - precision: 0.9006 - recall: 0.7714 - fmeasure: 0.8300 - val_loss: 0.6236 - val_acc: 0.8745 - val_top_k_categorical_accuracy: 0.9539 - val_precision: 0.9322 - val_recall: 0.8293 - val_fmeasure: 0.8772\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 921us/step - loss: 0.7310 - acc: 0.8173 - top_k_categorical_accuracy: 0.9559 - precision: 0.8910 - recall: 0.7450 - fmeasure: 0.8108 - val_loss: 2.0075 - val_acc: 0.4850 - val_top_k_categorical_accuracy: 0.8124 - val_precision: 0.6310 - val_recall: 0.3319 - val_fmeasure: 0.4334\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1000us/step - loss: 0.6228 - acc: 0.8489 - top_k_categorical_accuracy: 0.9615 - precision: 0.9035 - recall: 0.7944 - fmeasure: 0.8444 - val_loss: 0.7012 - val_acc: 0.8492 - val_top_k_categorical_accuracy: 0.9509 - val_precision: 0.9176 - val_recall: 0.7869 - val_fmeasure: 0.8465\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 922us/step - loss: 0.6438 - acc: 0.8319 - top_k_categorical_accuracy: 0.9654 - precision: 0.8954 - recall: 0.7710 - fmeasure: 0.8279 - val_loss: 1.9239 - val_acc: 0.5041 - val_top_k_categorical_accuracy: 0.8166 - val_precision: 0.6827 - val_recall: 0.3395 - val_fmeasure: 0.4517\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.5840 - acc: 0.8563 - top_k_categorical_accuracy: 0.9688 - precision: 0.9095 - recall: 0.8045 - fmeasure: 0.8531 - val_loss: 0.6375 - val_acc: 0.8703 - val_top_k_categorical_accuracy: 0.9545 - val_precision: 0.9308 - val_recall: 0.8127 - val_fmeasure: 0.8671\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 924us/step - loss: 0.5880 - acc: 0.8447 - top_k_categorical_accuracy: 0.9695 - precision: 0.9039 - recall: 0.7902 - fmeasure: 0.8428 - val_loss: 1.7837 - val_acc: 0.5442 - val_top_k_categorical_accuracy: 0.8402 - val_precision: 0.7073 - val_recall: 0.3707 - val_fmeasure: 0.4851\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.5343 - acc: 0.8660 - top_k_categorical_accuracy: 0.9711 - precision: 0.9136 - recall: 0.8195 - fmeasure: 0.8635 - val_loss: 0.6082 - val_acc: 0.8756 - val_top_k_categorical_accuracy: 0.9562 - val_precision: 0.9240 - val_recall: 0.8318 - val_fmeasure: 0.8751\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 921us/step - loss: 0.5223 - acc: 0.8594 - top_k_categorical_accuracy: 0.9762 - precision: 0.9114 - recall: 0.8107 - fmeasure: 0.8577 - val_loss: 1.4922 - val_acc: 0.6113 - val_top_k_categorical_accuracy: 0.8941 - val_precision: 0.7395 - val_recall: 0.4895 - val_fmeasure: 0.5882\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1000us/step - loss: 0.4999 - acc: 0.8719 - top_k_categorical_accuracy: 0.9758 - precision: 0.9154 - recall: 0.8287 - fmeasure: 0.8695 - val_loss: 0.6229 - val_acc: 0.8705 - val_top_k_categorical_accuracy: 0.9565 - val_precision: 0.9228 - val_recall: 0.8220 - val_fmeasure: 0.8690\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 927us/step - loss: 0.4820 - acc: 0.8668 - top_k_categorical_accuracy: 0.9789 - precision: 0.9167 - recall: 0.8238 - fmeasure: 0.8674 - val_loss: 1.4818 - val_acc: 0.6212 - val_top_k_categorical_accuracy: 0.8958 - val_precision: 0.7710 - val_recall: 0.4628 - val_fmeasure: 0.5768\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.4675 - acc: 0.8799 - top_k_categorical_accuracy: 0.9781 - precision: 0.9206 - recall: 0.8412 - fmeasure: 0.8787 - val_loss: 0.5621 - val_acc: 0.8837 - val_top_k_categorical_accuracy: 0.9629 - val_precision: 0.9262 - val_recall: 0.8481 - val_fmeasure: 0.8852\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 928us/step - loss: 0.4485 - acc: 0.8733 - top_k_categorical_accuracy: 0.9823 - precision: 0.9168 - recall: 0.8322 - fmeasure: 0.8722 - val_loss: 1.6403 - val_acc: 0.5717 - val_top_k_categorical_accuracy: 0.8778 - val_precision: 0.7038 - val_recall: 0.4530 - val_fmeasure: 0.5500\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.4439 - acc: 0.8832 - top_k_categorical_accuracy: 0.9811 - precision: 0.9187 - recall: 0.8486 - fmeasure: 0.8820 - val_loss: 0.6201 - val_acc: 0.8722 - val_top_k_categorical_accuracy: 0.9562 - val_precision: 0.9275 - val_recall: 0.8231 - val_fmeasure: 0.8718\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 923us/step - loss: 0.4169 - acc: 0.8789 - top_k_categorical_accuracy: 0.9844 - precision: 0.9218 - recall: 0.8417 - fmeasure: 0.8796 - val_loss: 1.4122 - val_acc: 0.6310 - val_top_k_categorical_accuracy: 0.8947 - val_precision: 0.7827 - val_recall: 0.5063 - val_fmeasure: 0.6136\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.4207 - acc: 0.8906 - top_k_categorical_accuracy: 0.9835 - precision: 0.9260 - recall: 0.8586 - fmeasure: 0.8907 - val_loss: 0.6344 - val_acc: 0.8610 - val_top_k_categorical_accuracy: 0.9582 - val_precision: 0.9145 - val_recall: 0.8124 - val_fmeasure: 0.8601\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 921us/step - loss: 0.4010 - acc: 0.8834 - top_k_categorical_accuracy: 0.9862 - precision: 0.9217 - recall: 0.8496 - fmeasure: 0.8839 - val_loss: 1.5770 - val_acc: 0.5937 - val_top_k_categorical_accuracy: 0.8756 - val_precision: 0.7288 - val_recall: 0.4824 - val_fmeasure: 0.5789\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.4248 - acc: 0.8882 - top_k_categorical_accuracy: 0.9839 - precision: 0.9212 - recall: 0.8535 - fmeasure: 0.8858 - val_loss: 0.5662 - val_acc: 0.8767 - val_top_k_categorical_accuracy: 0.9660 - val_precision: 0.9216 - val_recall: 0.8470 - val_fmeasure: 0.8824\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "24921/24921 [==============================] - 23s 921us/step - loss: 0.3725 - acc: 0.8915 - top_k_categorical_accuracy: 0.9873 - precision: 0.9263 - recall: 0.8572 - fmeasure: 0.8902 - val_loss: 1.4135 - val_acc: 0.6304 - val_top_k_categorical_accuracy: 0.9026 - val_precision: 0.7782 - val_recall: 0.4999 - val_fmeasure: 0.6074\n",
            "Train on 8307 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "8307/8307 [==============================] - 8s 1ms/step - loss: 0.3854 - acc: 0.8991 - top_k_categorical_accuracy: 0.9869 - precision: 0.9279 - recall: 0.8685 - fmeasure: 0.8970 - val_loss: 0.5622 - val_acc: 0.8840 - val_top_k_categorical_accuracy: 0.9643 - val_precision: 0.9286 - val_recall: 0.8447 - val_fmeasure: 0.8844\n",
            "Train on 24921 samples, validate on 3561 samples\n",
            "Epoch 1/1\n",
            "12800/24921 [==============>...............] - ETA: 10s - loss: 0.3608 - acc: 0.8952 - top_k_categorical_accuracy: 0.9865 - precision: 0.9292 - recall: 0.8641 - fmeasure: 0.8953"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O2d8d6NhXhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt  \n",
        "\n",
        "LIST_label = ['noise','delete','shuffle','transplant','mixup']\n",
        "LIST_index = ['val_loss','val_acc','val_top_k_categorical_accuracy','val_precision','val_recall','val_fmeasure']\n",
        "NB_index = len(LIST_index)\n",
        "\n",
        "def my_plot(history_org,history_after): #\n",
        "    fig,axs = plt.subplots(NB_index,1,figsize=(30,100))\n",
        "    for j,index in zip(range(NB_index),LIST_index):  #for each index like: loss....acc ....top5\n",
        "        alpha = 1\n",
        "        axs[j].plot(range(NB_EPOCHS),history_org.history[index],label='before')\n",
        "        #axs[j].annotate('before'+str(round(sum(history_org.history[index][-6:-1])/5,2)),(NB_EPOCHS,sum(history_org.history[index][-6:-1])/5),xytext=(NB_EPOCHS*alpha,sum(history_org.history[index][-6:-1])*alpha/5),arrowprops=dict(arrowstyle='->'))\n",
        "        before = round(sum(history_org.history[index][-11:-1])/10,3)\n",
        "        print(\"############################################## split line for index####################################################################\")\n",
        "        for i in range(NB_TECHS): #for each techs i.e. each line with different color\n",
        "            alpha = alpha*0.6\n",
        "            axs[j].plot(range(NB_EPOCHS),history_after[i].history[index],label=LIST_label[i])\n",
        "            #axs[j].annotate(LIST_label[i]+str(round(sum(history_after[i].history[index][-6:-1])/5,2)),(NB_EPOCHS,sum(history_after[i].history[index][-6:-1])/5),xytext=(NB_EPOCHS*alpha,sum(history_after[i].history[index][-6:-1])*alpha/5),arrowprops=dict(arrowstyle='->'))\n",
        "            after = round(sum(history_after[i].history[index][-11:-1])/10,3)\n",
        "            t = LIST_label[i] + str(round(100*(after - before)/before,3)) + '% improved'\n",
        "            #h_max = max(history_after[i].history[index])\n",
        "            #axs[j].text(NB_EPOCHS*alpha, h_max, t, ha='left', wrap=True,  bbox=dict(boxstyle='round,pad=0.5', fc='yellow', ec='k',lw=1))\n",
        "            print(\"############################################## split line for techs ####################################################################\")\n",
        "            print(LIST_label[i])\n",
        "            print(str() + str(index) + \" before \"+ str(before))\n",
        "            print(str(index) + \" after \" + str(after))\n",
        "            print(str(index) + \" changed \"+ str(t) + \"% \")\n",
        "        #axs[j].text(NB_EPOCHS, history_DNN_org.history['val_precision'][-1]*1.1, t, ha='left', wrap=True,  bbox=dict(boxstyle='round,pad=0.5', fc='yellow', ec='k',lw=1))\n",
        "        axs[j].set_title(LIST_index[j])\n",
        "        axs[j].legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah_JCMAUj_Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_plot(history_MLP_org,history_MLP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4LB3Lhv9AyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_plot(history_DNN_org,history_DNN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu_1frh_-lO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_plot(history_CNN_org,history_CNN)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}